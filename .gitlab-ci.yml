workflow:
  # Allows jobs in this workflow to be interrupted:
  # https://gitlab.jatic.net/help/ci/yaml/index.md#workflowauto_cancelon_new_commit
  auto_cancel:
    on_new_commit: interruptible
  rules:
    # Release Workflow
    - if: $CI_PIPELINE_SOURCE == 'schedule' && $CREATE_NEW_RELEASE
    # Merge Request Workflow
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    # Skip CHANGELOG.md updates
    - if: $CI_COMMIT_BRANCH == 'main'
      changes: ["CHANGELOG.md"]
      when: never
    # Commit Main Branch Workflow
    - if: $CI_COMMIT_BRANCH == 'main'
    - if: $CI_PIPELINE_SOURCE == 'web'

default:
  # This should allow pipelines to auto-cancel when redundant:
  # https://gitlab.jatic.net/help/ci/pipelines/settings.md#auto-cancel-redundant-pipelines
  # https://gitlab.jatic.net/help/ci/yaml/index.md#interruptible
  interruptible: true
  tags:
    - autoscaler

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PYTHON_LATEST_SUPPORTED_VERSION: "3.11"
  DOCKER_DRIVER: overlay2
  PIP_ROOT_USER_ACTION: ignore
  PIP_DISABLE_PIP_VERSION_CHECK: 1

image: python:$PYTHON_LATEST_SUPPORTED_VERSION

cache:
  paths:
    - .cache/pip
    - venv/

stages:
  - build
  - test
  - docs
  - release

### RULE ANCHORS ###

.on_release: &on_release
  - if: $CREATE_NEW_RELEASE

.on_run: &on_run
  - if: $CREATE_NEW_RELEASE
    when: never
  - if: $CI_PIPELINE_SOURCE == 'merge_request_event' || $CI_COMMIT_BRANCH == 'main' || $CI_PIPELINE_SOURCE == 'web'

.on_run_with_docs: &on_run_with_docs
  - if: $CREATE_NEW_RELEASE
    when: never
  - if: $CI_PIPELINE_SOURCE == 'merge_request_event' || $CI_PIPELINE_SOURCE == 'web'
    changes:
      paths:
        - src/**/*
        - docs/**/*
        - environment/*
        - README.md
  - if: $CI_COMMIT_BRANCH == 'main' 

.on_merge_request_only: &on_merge_request_only
  - if: $CREATE_NEW_RELEASE
    when: never
  - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

.on_commit_main_only: &on_commit_main_only
  - if: $CREATE_NEW_RELEASE
    when: never
  - if: $CI_COMMIT_BRANCH == 'main'

### PYTHON_VERSION PARALLEL MATRIX TEMPLATE ###

.python_version_matrix:
  parallel:
    matrix:
      - PYTHON_VERSION: ["3.9", "3.10", "3.11"]

### DOCKER TEMPLATES ###

.docker:
  image: docker:25.0.5-git
  before_script:
    - if [[ ! $(which bash) ]]; then apk add --no-cache bash; fi

.harbor:
  extends: .docker
  before_script:
    - if [[ ! $(which bash) ]]; then apk add --no-cache bash; fi
    - echo ${DATAEVAL_HARBOR_TOKEN} | docker login harbor.jatic.net -u 'robot$dataeval+dataeval-build' --password-stdin || echo "Failed to login to Harbor..."
  after_script:
    - docker logout harbor.jatic.net|| echo "Failed to logout from Harbor..."

.build_task:
  extends: [.harbor, .python_version_matrix]
  needs: [build]
  script:
    - ./build --push ${PYTHON_VERSION} ${TASK}
  artifacts:
    paths:
      - output/*
  rules: *on_run

### NO DOCKER TEMPLATE ###

.build_task_no_docker:
  image: python:${PYTHON_VERSION}
  extends: [.python_version_matrix]
  needs: []
  before_script:
    - |
      if [[ ${TASK} == lint ]]; then
        pip install poetry
        poetry run pip install -e . ruff codespell[toml]
      elif [[ ${TASK} == unit || ${TASK} == type ]]; then
        pip install poetry
        poetry install --all-extras --with dev
      fi
  script:
    - ./run ${TASK}
  artifacts:
    paths:
      - output/*
  rules: *on_run

### BUILD ###

build:
  stage: build
  extends: [.harbor, .python_version_matrix]
  script:
    - apk add --no-cache parallel
    - ./build --build-only --push ${PYTHON_VERSION}
  rules: *on_run

verify lock:
  stage: build
  before_script:
    - pip install poetry
  script:
    - poetry check
    - poetry config warnings.export false
    - poetry export --all-extras --without-hashes -o environment/requirements.check
    - cmp -s environment/requirements.txt environment/requirements.check
    - poetry export --only=dev --without-hashes -o environment/requirements-dev.check
    - cmp -s environment/requirements-dev.txt environment/requirements-dev.check
  rules: *on_run

docker info:
  stage: build
  extends: .docker
  script:
    - echo ===========================================================
    - |
      docker info
      echo ===========================================================
    - |
      docker version
      echo ===========================================================
    - |
      docker buildx ls
      echo ===========================================================
  rules: *on_run

### TEST ###

linting:
  extends: .build_task
  variables:
    TASK: lint

dependency tests:
  extends: .build_task
  variables:
    TASK: deps

tests:
  extends: .build_task
  variables:
    TASK: unit
  artifacts:
    reports:
      junit: output/junit.*.xml

type checks:
  extends: .build_task
  variables:
    TASK: type

coverage:
  needs: [tests]
  before_script:
    - pip install coverage
  script:
    # TODO: Move coverage report generation in to build script (and/or resolve issue with using symlinks instead of a full recursive copy)
    - cp --recursive $(pwd) /dataeval
    - coverage combine ./output
    - coverage report -m --skip-empty
    - coverage xml --skip-empty
    - coverage html --skip-empty
  coverage: "/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/"
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - coverage.xml
      - htmlcov/
  rules: *on_run

### DOCS ###

docs:
  stage: docs
  extends: .harbor
  needs: [build]
  tags: [multi-gpu]
  script:
    - ./build --push docs --gpu
  artifacts:
    paths:
      - output/docs/.jupyter_cache/
      - output/docs/html/
  rules: *on_run_with_docs

pages:
  stage: docs
  needs:
    - job: docs
      artifacts: true
    - job: coverage
      artifacts: true
  script:
    - mv output/docs/html/ ./public/
    - mv htmlcov/ ./public/coverage/
  artifacts:
    paths:
      - public
  rules: *on_commit_main_only

### RELEASE ###

update merge request:
  stage: release
  before_script:
    - pip install requests
  script:
    - .gitlab/scripts/update_merge_request.py $CI_MERGE_REQUEST_IID $CI_PIPELINE_ID
  rules: *on_merge_request_only

# This job will only run if all previous stages have succeeded,
# and it creates a tag that signifies that all testing has passed.
tag release candidate:
  stage: release
  before_script:
    - pip install requests
  script:
    - .gitlab/scripts/update_latest_known_good.py
  rules: *on_commit_main_only

# This job cleans up the image tags from the harbor registry
# associated with the last merged branch.
remove image tags:
  stage: release
  needs: []
  before_script:
    - pip install requests
  script:
    - .gitlab/scripts/remove_image_tags.py
  rules: *on_commit_main_only

# This job updates the changelog and tags the commit hash with a
# new version tag, which gets picked up and published from a GitHub
# action defined in .github/workflows/publish.yml
create release:
  stage: release
  needs: []
  before_script:
    - pip install requests
  script:
    - .gitlab/scripts/create_release.py
  rules: *on_release

export-merged-sbom:
  stage: release
  image: docker:stable
  before_script:
    - apk add --update jq curl
  script:
    - >
      curl --header "Authorization: Bearer $DATAEVAL_BUILD_PAT"
      --output export.sh --url "https://gitlab.jatic.net/api/v4/snippets/7/raw"
    - /bin/sh export.sh
  artifacts:
    paths:
      - "gl-sbom-merged-*.cdx.json"
  rules: *on_release

### SECURITY ###

include:
  - template: Security/Secret-Detection.gitlab-ci.yml
#  - template: Security/Dependency-Scanning.gitlab-ci.yml
#  - template: Security/SAST.gitlab-ci.yml

secret_detection:
  needs: []
  rules: *on_run

# generate shipped dependencies:
#   needs: []
#   before_script:
#     - pip install poetry
#     - poetry check
#     - poetry self add poetry-lock-groups-plugin
#   script:
#     - poetry lock --without dev
#   artifacts:
#     paths:
#       - poetry.lock
#   rules: *on_run

# gemnasium-python-dependency_scanning:
#   needs:
#     - job: generate shipped dependencies
#       artifacts: true
#   # Both `needs` and `dependencies` are used due to a quirk of gitlab.
#   # `gemnasium-python-dependency_scanning` specifies an empty list of
#   # dependencies, which means that unless you explicitly add the dependency,
#   # all artifacts will be filtered out and removed from this job.
#   dependencies:
#     - generate shipped dependencies
#   rules: *on_run

# semgrep-sast:
#   needs: []
#   rules: *on_run
