{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bdd5407",
   "metadata": {},
   "source": [
    "# How to determine image classification feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb1cff",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "For classification machine learning tasks, there is an _inherent difficulty_ associated with signal to noise ratio in\n",
    "the images. One way of quantifying this difficulty is the [Bayes Error Rate](../concepts/BER.md), or irreducable error.\n",
    "This metric tells you if it would be _feasible_ to use a given feature set to predict a target variable.\n",
    "\n",
    "DataEval has introduced a method of calculating this error rate that uses image embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ec598",
   "metadata": {},
   "source": [
    "### When to use\n",
    "\n",
    "The `BER` metric should be used when you would like to measure the feasibility of a machine learning task. For example,\n",
    "if you have an operational accuracy requirement of 80%, and would like to know if this is feasibly achievable given the\n",
    "imagery. A low feasibility score will tell you that the problem you are trying to score cannot be solved with the\n",
    "existing data at the accuracy you desire. This in turn implies that your question does not follow a learnable pattern or\n",
    "that your data is noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126151f6",
   "metadata": {},
   "source": [
    "### What you will need\n",
    "\n",
    "1. A set of image [embeddings](../concepts/Embeddings.md) and their corresponding class labels. This requires training\n",
    "   an autoencoder to compress the images.\n",
    "1. A Python environment with the following packages installed:\n",
    "   - `dataeval`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cc9bf",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9998f",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Google Colab Only\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aae7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maite_datasets.image_classification import MNIST\n",
    "\n",
    "from dataeval import Embeddings, Metadata\n",
    "from dataeval.config import set_seed\n",
    "from dataeval.core import ber_mst\n",
    "from dataeval.extractors import FlattenExtractor\n",
    "from dataeval.selection import ClassBalance, ClassFilter, Limit, Select\n",
    "\n",
    "set_seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f4014",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "While you can use your own dataset, for this example we imported the `MNIST` dataset and will use it going forward. It\n",
    "was imported from the DataEval utils package.\n",
    "\n",
    "To highlight the effects of modifying the dataset on its Bayes Error Rate, we will only include a subset of 6,000 images\n",
    "and their labels for digits 1, 4, and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a755969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the dataset transforms\n",
    "transforms = [\n",
    "    lambda x: x / 255.0,  # scale to [0, 1]\n",
    "    lambda x: x.astype(np.float32),  # convert to float32\n",
    "]\n",
    "\n",
    "# Load the train set of the MNIST dataset and apply transforms\n",
    "train_ds = MNIST(root=\"./data/\", image_set=\"train\", transforms=transforms, download=True)\n",
    "\n",
    "# Get the indices of the first 2000 samples for labels 1, 4, and 9\n",
    "train_ds = Select(train_ds, selections=[Limit(6000), ClassFilter((1, 4, 9)), ClassBalance(\"interclass\")])\n",
    "\n",
    "# Split out the embeddings and labels\n",
    "extractor = FlattenExtractor()\n",
    "embeddings = Embeddings(train_ds, extractor=extractor, batch_size=64)\n",
    "labels = Metadata(train_ds).class_labels\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: \", len(embeddings))\n",
    "print(\"Image shape:\", embeddings.shape)\n",
    "print(\"Label counts: \", np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2568434",
   "metadata": {},
   "source": [
    "We have taken a subset of the data that is only the digits 1, 4, and 9. The BER estimate requires 1 dimension, that's\n",
    "why we have flattened images. This is ok since MNIST images are small, in practice we would need to do some dimension\n",
    "reduction (autoencoder) here.\n",
    "\n",
    "We now have 6,000 flattened images of size 784. Next we can move on to evaluation of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd0867",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Suppose we would like to build a classifier that differentiates between the handwritten digits 1, 4, and 9 with\n",
    "predetermined accuracy requirement of 99%.\n",
    "\n",
    "We will use BER to check the feasibility of the task. As the images are small, we can simple use the flattened raw pixel\n",
    "intensities to calculate BER (no embedding necessary). _Note_: This will not be the case in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f37aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the BER metric for the MNIST data with digits 1, 4, 9.\n",
    "# One minus the value of this metric gives our estimate of the upper bound on accuracy.\n",
    "ber_result = ber_mst(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e601c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The bayes error rate estimation:\", ber_result[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb6d28",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert 0.93 < 1 - ber_result[\"upper_bound\"] < 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354ff24",
   "metadata": {},
   "source": [
    "The estimate of the maximum achievable accuracy is one minus the BER estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c710da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum achievable accuracy:\", 1 - ber_result[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d163275",
   "metadata": {},
   "source": [
    "### Initial results\n",
    "\n",
    "The maximum achievable accuracy on a dataset of 1, 4, and 9 is about 94%. This _does not_ meet our requirement of 99%\n",
    "accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032a4c8",
   "metadata": {},
   "source": [
    "## Modify dataset classification\n",
    "\n",
    "To address insufficient accuracy, lets modify the dataset to classify an image as \"1\" or \"Not a 1\". By combining\n",
    "classes, we can hopefully achieve the desired level of attainable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a binary mask where current label == 1 that can be used as the new labels\n",
    "labels_merged = labels == 1\n",
    "print(\"New label counts:\", np.unique(labels_merged, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the BER metric for the MNIST data with updated labels\n",
    "new_result = ber_mst(embeddings, labels_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The bayes error rate estimation:\", new_result[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b1101",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert 0.99 < 1 - new_result[\"upper_bound\"] < 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7917230",
   "metadata": {},
   "source": [
    "The estimate of the maximum achievable accuracy is one minus the BER estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum achievable accuracy:\", 1 - new_result[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e1592",
   "metadata": {},
   "source": [
    "### Modified results\n",
    "\n",
    "The maximum achievable accuracy on a dataset of 1 and not 1 (4, 9) is about 99%. This _does_ meet our accuracy\n",
    "requirement.\n",
    "\n",
    "By using BER to check for feasibility early on, we were able to reformulate the problem such that it is feasible under\n",
    "our specifications"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
