{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded7e76c",
   "metadata": {},
   "source": [
    "# How to measure label independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113059c",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "For machine learning tasks, a discrepancy in label frequencies between train and test datasets can result in poor model\n",
    "performance.\n",
    "\n",
    "To help with this, DataEval has a [label parity](../concepts/LabelParity.md) tool that compares the label distributions\n",
    "of two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbedb7",
   "metadata": {},
   "source": [
    "### When to use\n",
    "\n",
    "DataEval provides a {func}`.label_parity` function to use when you would like to determine if two datasets have\n",
    "statistically independent labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40240f33",
   "metadata": {},
   "source": [
    "### What you will need\n",
    "\n",
    "1. A Python environment with the following packages installed:\n",
    "   - dataeval\n",
    "1. A labeled training image dataset\n",
    "1. A labeled test image dataset to evaluate the label distribution of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48adb3",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959a61d",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Google Colab Only\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maite_datasets.image_classification import MNIST\n",
    "\n",
    "from dataeval import Metadata\n",
    "from dataeval.core import label_parity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb06e0e",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "While you can use your own dataset, for this example we imported the `MNIST` dataset and will use it going forward. It\n",
    "was imported from the DataEval utils package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNIST(\"./data\", image_set=\"train\", download=True)\n",
    "test_ds = MNIST(\"./data\", image_set=\"test\", download=True)\n",
    "\n",
    "train_md = Metadata(train_ds)\n",
    "test_md = Metadata(test_ds)\n",
    "\n",
    "# Get the labels from the collated dataset targets\n",
    "train_labels = train_md.class_labels\n",
    "test_labels = test_md.class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d268a",
   "metadata": {},
   "source": [
    "## Evaluate label statistical independence\n",
    "\n",
    "Now, let's look at how to use DataEval's label statistics analyzer. Using the {func}`.label_parity` function, compute\n",
    "the chi-squared value of hypothesis that test_ds has the same class distribution as train_ds by specifying the labels of\n",
    "the two datasets to be compared. It also returns the p-value of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = label_parity(train_labels, test_labels)\n",
    "print(\n",
    "    f\"The chi-squared value for the two label distributions is {results['chi_squared']}, \"\n",
    "    f\"with p-value {results['p_value']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12873668",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert 0 <= results[\"chi_squared\"] < 4\n",
    "assert 0.9 < results[\"p_value\"] <= 1.0"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
