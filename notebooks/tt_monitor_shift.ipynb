{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108ea7eb",
   "metadata": {},
   "source": [
    "# Monitor shifts in operational data\n",
    "\n",
    "This guide provides a beginner friendly introduction on monitoring post deployment data shifts.\n",
    "\n",
    "Estimated time to complete: 5 minutes\n",
    "\n",
    "Relevant ML stages: [Monitoring](../concepts/users/ML_Lifecycle.md#monitoring)\n",
    "\n",
    "Relevant personas: Machine Learning Engineer, T&E Engineer\n",
    "\n",
    "## What you'll do\n",
    "\n",
    "- Construct [embeddings](../concepts/Embeddings.md) by training a simple neural network\n",
    "- Compare different drift detectors and understand their strengths\n",
    "- Inspect detector-specific outputs for root-cause analysis\n",
    "- Use chunked drift detection to monitor drift across data segments\n",
    "- Compare the label distributions between a training and operational set\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "- Learn the strengths and trade-offs of each drift detector\n",
    "- Learn how to analyze embeddings for operational drift\n",
    "- Learn how to inspect per-feature and per-detector statistics\n",
    "- Learn how to use chunked drift detection for temporal monitoring\n",
    "- Learn how to analyze label distributions\n",
    "\n",
    "## What you'll need\n",
    "\n",
    "- Knowledge of Python\n",
    "- Beginner knowledge of PyTorch or neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fe9dd",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Monitoring is a critical step in the [AI/ML lifecycle](../concepts/users/ML_Lifecycle.md). When a model is deployed,\n",
    "data can, and generally will, [drift](../concepts/Drift.md) from the distribution on which the model was originally\n",
    "trained. One critical step in AI T&E is the detection of changes in the operational distribution so that they may be\n",
    "proactively addressed. While some change might not affect performance, significant deviation is often associated with\n",
    "model degradation.\n",
    "\n",
    "For this tutorial, you will use the popular\n",
    "[2012 VOC](https://huggingface.co/datasets/HuggingFaceM4/pascal_voc/tree/main) computer vision dataset to detect drift\n",
    "between the image distribution of the `train` split and the `val` split, which will represent an operational dataset in\n",
    "this guide. You will then determine if the labels within these two datasets has high\n",
    "[parity](../concepts/LabelParity.md), or equivalent label distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533e88d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You'll begin by importing the necessary libraries for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d5841",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from IPython.display import display  # noqa: A004\n",
    "from maite_datasets.object_detection import VOCDetection\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "from torchvision.transforms.v2 import GaussianNoise\n",
    "\n",
    "from dataeval import Embeddings, Metadata\n",
    "from dataeval.core import label_parity\n",
    "from dataeval.extractors import TorchExtractor\n",
    "from dataeval.shift import DriftDomainClassifier, DriftKNeighbors, DriftMMD, DriftUnivariate\n",
    "\n",
    "# Set a random seed\n",
    "rng = np.random.default_rng(213)\n",
    "\n",
    "# Set default torch device for notebook\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f0364",
   "metadata": {},
   "source": [
    "> **More on device**\n",
    ">\n",
    "> The device is set above as it will be used in subsequent steps. The device is the piece of hardware where the model,\n",
    "> data, and other related objects are stored in memory. If a GPU is available, this notebook will use that hardware\n",
    "> rather than the CPU. To force running only on the CPU, change `device` to `\"cpu\"` For more information, see the\n",
    "> [PyTorch device page](https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfa316",
   "metadata": {},
   "source": [
    "## Constructing embeddings\n",
    "\n",
    "An important concept in many aspects of machine learning is {term}`Dimensionality Reduction`. While this step is not\n",
    "always necessary, it is good practice to use embeddings over raw images to improve the speed and memory efficiency of\n",
    "many workflows without sacrificing downstream performance.\n",
    "\n",
    "### Define model architecture\n",
    "\n",
    "In this section, you will use a\n",
    "[pretrained ResNet18 model](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html) from\n",
    "Torchvision to reduce the dimensionality of the VOC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f83974",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT, progress=False)\n",
    "\n",
    "# Replace the final fully connected layer with a Linear layer\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b2e59",
   "metadata": {},
   "source": [
    "### Download VOC dataset\n",
    "\n",
    "With the model created on the device set at the beginning, you will download the train and validation splits of the 2012\n",
    "VOC Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"train\", download=True)\n",
    "print(train_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"operational\" dataset\n",
    "operational_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"val\", download=True)\n",
    "print(operational_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858ea0b",
   "metadata": {},
   "source": [
    "It is good to notice a few points about each dataset:\n",
    "\n",
    "- Number of datapoints\n",
    "- Resize size\n",
    "\n",
    "These two values give an estimate of the memory impact that each dataset has. The following step will modify the resize\n",
    "size by creating model embeddings for each image to reduce this impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817243d",
   "metadata": {},
   "source": [
    "### Extract embeddings\n",
    "\n",
    "Now it is time to process the datasets through your model. Aggregating the model outputs gives you the embeddings of the\n",
    "data. This will be helpful in determining drift between the training and operational splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6d85d",
   "metadata": {},
   "source": [
    "Below you will call the helper function and create embeddings for both the train and operational splits. The labels will\n",
    "also be saved so they can be used in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained model transformations\n",
    "transforms = ResNet18_Weights.DEFAULT.transforms()\n",
    "\n",
    "# Create extractor with model and transforms\n",
    "extractor = TorchExtractor(resnet, transforms=transforms)\n",
    "\n",
    "# Create training batches and targets\n",
    "train_embs = Embeddings(train_ds, extractor=extractor, batch_size=64)\n",
    "\n",
    "# Create operational batches and targets\n",
    "operational_embs = Embeddings(operational_ds, extractor=extractor, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f8cf0",
   "metadata": {},
   "source": [
    "Notice that the shape of embeddings is different than before.\n",
    "\n",
    "#### Previously\n",
    "\n",
    "Training shape - (5717, 3, 442, 500)\\\n",
    "Operational shape - (5823, 3, 442, 500)\n",
    "\n",
    "#### After embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a87d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"({len(train_embs)}, {train_embs[0].shape})\")  # (5717, shape)\n",
    "print(f\"({len(operational_embs)}, {operational_embs[0].shape})\")  # (5823, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac677eb",
   "metadata": {},
   "source": [
    "The reduced shape of both the training and operational datasets will improve the performance of the upcoming drift\n",
    "algorithms without impacting the accuracy of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e894815",
   "metadata": {},
   "source": [
    "## Understanding drift detectors\n",
    "\n",
    "Before testing for drift, it helps to understand the different approaches available. Each detector has distinct\n",
    "strengths that make it better suited for certain scenarios. This tutorial uses four detectors that represent\n",
    "fundamentally different strategies for detecting distributional change.\n",
    "\n",
    "| Detector                        | Approach                                         | Strengths                                   | Best For                              |\n",
    "| ------------------------------- | ------------------------------------------------ | ------------------------------------------- | ------------------------------------- |\n",
    "| {class}`.DriftUnivariate` (CVM) | Statistical test per feature                     | Fast, interpretable per-feature results     | Identifying _which_ features drifted  |\n",
    "| {class}`.DriftMMD`              | Kernel-based multivariate test                   | Captures feature dependencies               | High-dimensional data, complex shifts |\n",
    "| {class}`.DriftDomainClassifier` | Trains a classifier to distinguish distributions | Feature importances for root-cause analysis | Understanding _why_ drift occurred    |\n",
    "| {class}`.DriftKNeighbors`       | Compares k-NN distances                          | Lightweight and fast                        | Quick monitoring checks               |\n",
    "\n",
    "> **Other univariate methods**\n",
    ">\n",
    "> `DriftUnivariate` supports several statistical tests beyond CVM, including Kolmogorov-Smirnov (`ks`), Mann-Whitney U\n",
    "> (`mwu`), Anderson-Darling (`anderson`), and Baumgartner-Weiss-Schindler (`bws`). Each has different sensitivity\n",
    "> characteristics — see the [drift concept page](../concepts/Drift.md#understanding-the-drift-detectors) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec63919",
   "metadata": {},
   "source": [
    "## Test for drift\n",
    "\n",
    "In this step, you will be checking for drift between the training embeddings and the operational embeddings from before.\n",
    "If drift is detected, a model trained on this training data should be retrained with new operational data. This can help\n",
    "mitigate performance degradation in a deployed model. Visit our [About Drift](../concepts/Drift.md) page to learn more.\n",
    "\n",
    "### Drift detectors\n",
    "\n",
    "DataEval offers several drift detectors. This tutorial demonstrates four that each take a different approach:\n",
    "{class}`.DriftUnivariate`, {class}`.DriftMMD`, {class}`.DriftDomainClassifier`, and {class}`.DriftKNeighbors`.\n",
    "\n",
    "Since each detector outputs a binary decision on whether drift is detected, a **majority vote** can be used to make the\n",
    "determination of drift.\\\n",
    "To learn more about these algorithms, see the [theory behind drift detection](../concepts/Drift.md#what-is-drift)\n",
    "concept page.\n",
    "\n",
    "### Fit the detectors\n",
    "\n",
    "Each drift detector needs a reference set that the operational set will be compared against. In the following code, you\n",
    "will set the reference data to the training embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A type alias for all of the drift detectors\n",
    "DriftDetector = DriftUnivariate | DriftMMD | DriftDomainClassifier | DriftKNeighbors\n",
    "\n",
    "# Create a mapping for the detectors to iterate over\n",
    "detectors: dict[str, DriftDetector] = {\n",
    "    \"CVM\": DriftUnivariate(method=\"cvm\").fit(train_embs),\n",
    "    \"MMD\": DriftMMD().fit(train_embs),\n",
    "    \"MVDC\": DriftDomainClassifier().fit(train_embs),\n",
    "    \"KNN\": DriftKNeighbors().fit(train_embs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9764e5",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "\n",
    "Now that the detectors are setup, predictions can be made against the operational embeddings you made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b141e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(operational_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa14895",
   "metadata": {},
   "source": [
    "Did you expect these results?\n",
    "\n",
    "There is no drift detected between the train and operational embeddings because they come from very similar\n",
    "distributions.\\\n",
    "Ideally, your training data and your validation data, which we used as operational, come from the same distribution.\n",
    "This is the purpose of [data splitters](https://scikit-learn.org/stable/api/sklearn.model_selection.html#splitters).\n",
    "\n",
    "So how do we know if the detectors can detect drift?\n",
    "\n",
    "Well, add some random Gaussian noise to the operational embeddings and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cae6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform with added gaussian noise\n",
    "noisy_transforms = [transforms, GaussianNoise()]\n",
    "\n",
    "# Create extractor with noisy transforms\n",
    "noisy_extractor = TorchExtractor(resnet, transforms=noisy_transforms)\n",
    "\n",
    "# Applies gaussian noise to images before processing\n",
    "noisy_embs = Embeddings(operational_ds, extractor=noisy_extractor, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(noisy_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be703f7",
   "metadata": {},
   "source": [
    "Now drift is detected!\n",
    "\n",
    "Adding Gaussian noise was enough to cause a noticeable change in the drift detectors, but this is not always the case.\n",
    "There are many [types of drift](../concepts/Drift.md#formal-definition-and-types-of-drift) that data can and will\n",
    "experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed3054",
   "metadata": {},
   "source": [
    "### Inspecting detector outputs\n",
    "\n",
    "Each detector doesn't just report whether drift occurred — it provides statistics that reveal _different things_ about\n",
    "the drift. Let's look at what each detector tells us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for inspection\n",
    "results = {name: detector.predict(noisy_embs) for name, detector in detectors.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fa239",
   "metadata": {},
   "source": [
    "#### DriftUnivariate: per-feature analysis\n",
    "\n",
    "The univariate detector tests each feature independently and reports which features drifted and their p-values. This is\n",
    "useful for identifying _which_ dimensions of the embedding space shifted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d11d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm_result = results[\"CVM\"]\n",
    "cvm_details = cvm_result.details\n",
    "\n",
    "n_drifted = sum(cvm_details[\"feature_drift\"])\n",
    "n_features = len(cvm_details[\"feature_drift\"])\n",
    "print(f\"Features drifted: {n_drifted}/{n_features}\")\n",
    "print(f\"Corrected p-value threshold: {cvm_details['feature_threshold']:.6f}\")\n",
    "print(f\"Min feature p-value: {min(cvm_details['p_vals']):.6f}\")\n",
    "print(f\"Max feature p-value: {max(cvm_details['p_vals']):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf7358",
   "metadata": {},
   "source": [
    "#### DriftDomainClassifier: feature importances\n",
    "\n",
    "The domain classifier trains a model to distinguish reference from test data and reports how important each feature was\n",
    "in making that distinction. High AUROC means the distributions are easily separable — a strong signal of drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56221a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvdc_result = results[\"MVDC\"]\n",
    "mvdc_details = mvdc_result.details\n",
    "\n",
    "print(f\"AUROC: {mvdc_result.distance:.4f} (threshold: {mvdc_result.threshold})\")\n",
    "print(f\"Per-fold AUROCs: {[round(a, 4) for a in mvdc_details['fold_aurocs']]}\")\n",
    "\n",
    "# Show top 5 most important features\n",
    "importances = np.array(mvdc_details[\"feature_importances\"])\n",
    "top_indices = np.argsort(importances)[::-1][:5]\n",
    "print(\"\\nTop 5 features driving drift:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"  Feature {idx}: importance = {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48236b03",
   "metadata": {},
   "source": [
    "#### DriftKNeighbors: distance comparison\n",
    "\n",
    "The k-NN detector compares how far test samples are from their nearest neighbors in the reference set versus the\n",
    "expected baseline distance. A large increase signals that test data occupies different regions of feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690120a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_result = results[\"KNN\"]\n",
    "knn_details = knn_result.details\n",
    "\n",
    "print(f\"Mean reference k-NN distance: {knn_details['mean_ref_distance']:.4f}\")\n",
    "print(f\"Mean test k-NN distance:      {knn_details['mean_test_distance']:.4f}\")\n",
    "print(f\"Distance increase:             {knn_details['mean_test_distance'] - knn_details['mean_ref_distance']:.4f}\")\n",
    "print(f\"P-value: {knn_details['p_val']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23f365",
   "metadata": {},
   "source": [
    "#### DriftMMD: multivariate distribution distance\n",
    "\n",
    "MMD measures the overall distance between two distributions in a kernel feature space. It captures both marginal and\n",
    "joint distributional changes that univariate tests might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_result = results[\"MMD\"]\n",
    "mmd_details = mmd_result.details\n",
    "\n",
    "print(f\"MMD² distance:   {mmd_result.distance:.6f}\")\n",
    "print(f\"MMD² threshold:  {mmd_details['distance_threshold']:.6f}\")\n",
    "print(f\"P-value:         {mmd_details['p_val']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e9455",
   "metadata": {},
   "source": [
    "Each detector reveals a different facet of drift: the univariate detector pinpoints _which_ features changed, the domain\n",
    "classifier shows _which features matter most_ for distinguishing the distributions, the k-NN detector quantifies _how\n",
    "far_ the data moved, and MMD provides a single _multivariate distance_ between the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b08c6d",
   "metadata": {},
   "source": [
    "### Choosing the right detector\n",
    "\n",
    "The best detector depends on what you need to know:\n",
    "\n",
    "- **Which features drifted?** Use {class}`.DriftUnivariate` — it provides per-feature p-values and drift flags\n",
    "- **Why did drift occur?** Use {class}`.DriftDomainClassifier` — its feature importances show what drives the shift\n",
    "- **How sensitive to multivariate changes?** Use {class}`.DriftMMD` — it captures complex dependencies between features\n",
    "- **Need fast, lightweight checks?** Use {class}`.DriftKNeighbors` — simple distance comparison with minimal overhead\n",
    "- **Want robust detection?** Use multiple detectors with a **majority vote** to reduce false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17087ff",
   "metadata": {},
   "source": [
    "### Monitor drift over time with chunking\n",
    "\n",
    "In real deployments, operational data arrives in batches over time. Rather than comparing all operational data at once,\n",
    "you can use **chunking** to split the data into segments and monitor how drift evolves across each chunk. This helps\n",
    "identify _when_ drift begins to appear.\n",
    "\n",
    "DataEval's drift detectors support chunking through the `chunk_count` or `chunk_size` parameters on `fit()`. During\n",
    "fitting, the detector establishes a baseline by computing the metric across chunks of the reference data. During\n",
    "prediction, each chunk of test data is compared against this baseline, returning a {class}`.DriftOutput` with a\n",
    "`polars.DataFrame` in the `details` field containing per-chunk results.\n",
    "\n",
    "#### Simulate gradual drift onset\n",
    "\n",
    "To illustrate how chunking reveals _when_ drift begins, you will build a combined dataset where the first 40% of samples\n",
    "are clean operational embeddings and the remaining 60% are noisy. This simulates a scenario where data quality degrades\n",
    "partway through a monitoring window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a combined array: first 40% clean, last 60% noisy\n",
    "n_operational = len(operational_embs)\n",
    "split_idx = int(n_operational * 0.4)\n",
    "\n",
    "combined_embs = np.concatenate([operational_embs[:split_idx], noisy_embs[split_idx:]])\n",
    "print(f\"Combined shape: {combined_embs.shape} (clean: {split_idx}, noisy: {n_operational - split_idx})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6eec2",
   "metadata": {},
   "source": [
    "#### Fit detectors with chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03353dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit detectors with chunking enabled (5 chunks each)\n",
    "chunked_detectors: dict[str, DriftDetector] = {\n",
    "    \"CVM\": DriftUnivariate(method=\"cvm\").fit(train_embs, chunk_count=5),\n",
    "    \"MMD\": DriftMMD().fit(train_embs, chunk_count=5),\n",
    "    \"MVDC\": DriftDomainClassifier(threshold=(0.45, 0.65)).fit(train_embs, chunk_count=5),\n",
    "    \"KNN\": DriftKNeighbors().fit(train_embs, chunk_count=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77cb17",
   "metadata": {},
   "source": [
    "#### Predict on combined data and display chunk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdf18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, detector in chunked_detectors.items():\n",
    "    result = detector.predict(combined_embs)\n",
    "    print(f\"\\n{name} - Overall drift detected: {result.drifted} (metric: {result.metric_name})\")\n",
    "    if isinstance(result.details, pl.DataFrame):\n",
    "        display(result.details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571cdf22",
   "metadata": {},
   "source": [
    "The first two chunks (covering the clean 40%) should show no drift, while the later chunks (covering the noisy 60%)\n",
    "should trigger drift alerts. This chunk-level view makes it easy to pinpoint _when_ in a data stream drift begins.\n",
    "\n",
    "Next you will look at the labels' distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d444f93",
   "metadata": {},
   "source": [
    "## Evaluate parity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e21620",
   "metadata": {},
   "source": [
    "Instead of looking at the images, you can compare the distributions of the labels using a method called\n",
    "[label parity](../concepts/LabelParity.md).\\\n",
    "There is parity between two sets of labels if the label frequencies are approximately equal.\n",
    "\n",
    "You will now compare the label distributions using the `label_parity` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata for each dataset\n",
    "train_md = Metadata(train_ds)\n",
    "operational_md = Metadata(operational_ds)\n",
    "\n",
    "# The VOC dataset has 20 classes\n",
    "label_parity(train_md.class_labels, operational_md.class_labels, num_classes=20)[\"p_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc5880",
   "metadata": {},
   "source": [
    "From the {func}`.label_parity` function, you can see that it calculated a p_value of ~**0.95**. Since this is close to\n",
    "1.0, it can be said that the two distributions **have** class label parity, or similar distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa3b98",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you have learned to create embeddings from the VOC dataset, compare different drift detectors and\n",
    "their unique outputs, use chunked monitoring to identify when drift begins, and calculate the parity of label\n",
    "distributions.\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "- **DriftUnivariate** reveals _which_ features drifted through per-feature statistical tests\n",
    "- **DriftDomainClassifier** explains _why_ drift occurred through feature importances\n",
    "- **DriftMMD** provides a single multivariate distance that captures complex distributional changes\n",
    "- **DriftKNeighbors** offers fast, lightweight detection based on distance comparisons\n",
    "- **Chunked monitoring** helps pinpoint _when_ drift begins in a data stream\n",
    "\n",
    "These are important steps when monitoring data, as drift and lack of parity can affect a model's ability to achieve\n",
    "performance recorded during model training. When data drift is detected or the label distributions lack parity, it is a\n",
    "good idea to consider retraining the model and incorporating operational data into the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2d99e",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "DataEval plays a small, but impactful role in data monitoring as a metrics library.\\\n",
    "Visit these additional resources for more information on other aspects:\n",
    "\n",
    "- Read about the entire [monitoring in AI/ML](../concepts/users/ML_Lifecycle.md#monitoring) stage\n",
    "- Explore DataEval's [API reference](../reference/autoapi/dataeval/index.rst) for drift and other monitoring tools"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
