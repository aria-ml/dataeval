{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ab5983",
   "metadata": {},
   "source": [
    "# Monitor shifts in operational data\n",
    "\n",
    "This guide provides a beginner friendly introduction on monitoring post deployment data shifts.\n",
    "\n",
    "Estimated time to complete: 5 minutes\n",
    "\n",
    "Relevant ML stages: [Monitoring](../concepts/users/ML_Lifecycle.md#monitoring)\n",
    "\n",
    "Relevant personas: Machine Learning Engineer, T&E Engineer\n",
    "\n",
    "## What you'll do\n",
    "\n",
    "- Construct [embeddings](../concepts/Embeddings.md) by training a simple neural network\n",
    "- Compare the embeddings between a training and operational set\n",
    "- Compare the label distributions between a training and operational set\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "- Learn how to analyze embeddings for operational drift\n",
    "- Learn how to analyze label distributions\n",
    "\n",
    "## What you'll need\n",
    "\n",
    "- Knowledge of Python\n",
    "- Beginner knowledge of PyTorch or neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e62ed",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Monitoring is a critical step in the [AI/ML lifecycle](../concepts/users/ML_Lifecycle.md). When a model is deployed,\n",
    "data can, and generally will, [drift](../concepts/Drift.md) from the distribution on which the model was originally\n",
    "trained. One critical step\n",
    "in AI T&E is the detection of changes in the operational distribution so that they may be proactively addressed. While\n",
    "some change might not affect performance, significant deviation is often associated with model degradation.\n",
    "\n",
    "For this tutorial, you will use the popular\n",
    "[2012 VOC](https://huggingface.co/datasets/HuggingFaceM4/pascal_voc/tree/main) computer vision dataset to detect drift\n",
    "between the image distribution of the `train` split and the `val` split, which will represent an operational dataset in\n",
    "this guide. You will then determine if the labels within these two datasets has high\n",
    "[parity](../concepts/LabelParity.md), or equivalent label\n",
    "distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77e550",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You'll begin by importing the necessary libraries for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb78a7",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aed739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from maite_datasets.object_detection import VOCDetection\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "from torchvision.transforms.v2 import GaussianNoise\n",
    "\n",
    "from dataeval import Embeddings, Metadata\n",
    "from dataeval.core import label_parity\n",
    "from dataeval.extractors import TorchExtractor\n",
    "from dataeval.shift import DriftMMD, DriftUnivariate\n",
    "\n",
    "# Set a random seed\n",
    "rng = np.random.default_rng(213)\n",
    "\n",
    "# Set default torch device for notebook\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee3b79",
   "metadata": {},
   "source": [
    "> **More on device**\n",
    ">\n",
    "> The device is set above as it will be used in subsequent steps. The device is the piece of hardware where the model,\n",
    "> data, and other related objects are stored in memory. If a GPU is available, this notebook will use that hardware\n",
    "> rather than the CPU. To force running only on the CPU, change `device` to `\"cpu\"` For more information, see the\n",
    "> [PyTorch device page](https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded4e82",
   "metadata": {},
   "source": [
    "## Constructing embeddings\n",
    "\n",
    "An important concept in many aspects of machine learning is {term}`Dimensionality Reduction`. While this step is not\n",
    "always necessary, it is good practice to use embeddings over raw images to improve the speed and memory efficiency of\n",
    "many workflows without sacrificing downstream performance.\n",
    "\n",
    "### Define model architecture\n",
    "\n",
    "In this section, you will use a\n",
    "[pretrained ResNet18 model](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html) from\n",
    "Torchvision to reduce the dimensionality of the VOC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018be29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT, progress=False)\n",
    "\n",
    "# Replace the final fully connected layer with a Linear layer\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fe9b5",
   "metadata": {},
   "source": [
    "### Download VOC dataset\n",
    "\n",
    "With the model created on the device set at the beginning, you will download the train and validation splits of the 2012\n",
    "VOC Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"train\", download=True)\n",
    "print(train_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"operational\" dataset\n",
    "operational_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"val\", download=True)\n",
    "print(operational_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd517962",
   "metadata": {},
   "source": [
    "It is good to notice a few points about each dataset:\n",
    "\n",
    "- Number of datapoints\n",
    "- Resize size\n",
    "\n",
    "These two values give an estimate of the memory impact that each dataset has. The following step will modify the resize\n",
    "size by creating model embeddings for each image to reduce this impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93700a",
   "metadata": {},
   "source": [
    "### Extract embeddings\n",
    "\n",
    "Now it is time to process the datasets through your model. Aggregating the model outputs gives you the embeddings of the\n",
    "data. This will be helpful in determining drift between the training and operational splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6224d4",
   "metadata": {},
   "source": [
    "Below you will call the helper function and create embeddings for both the train and operational splits. The labels will\n",
    "also be saved so they can be used in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained model transformations\n",
    "transforms = ResNet18_Weights.DEFAULT.transforms()\n",
    "\n",
    "# Create extractor with model and transforms\n",
    "extractor = TorchExtractor(resnet, transforms=transforms)\n",
    "\n",
    "# Create training batches and targets\n",
    "train_embs = Embeddings(train_ds, extractor=extractor, batch_size=64)\n",
    "\n",
    "# Create operational batches and targets\n",
    "operational_embs = Embeddings(operational_ds, extractor=extractor, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68597dc7",
   "metadata": {},
   "source": [
    "Notice that the shape of embeddings is different than before.\n",
    "\n",
    "#### Previously\n",
    "\n",
    "Training shape - (5717, 3, 442, 500)\\\n",
    "Operational shape - (5823, 3, 442, 500)\n",
    "\n",
    "#### After embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"({len(train_embs)}, {train_embs[0].shape})\")  # (5717, shape)\n",
    "print(f\"({len(operational_embs)}, {operational_embs[0].shape})\")  # (5823, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa5614",
   "metadata": {},
   "source": [
    "The reduced shape of both the training and operational datasets will improve the performance of the upcoming drift\n",
    "algorithms without impacting the accuracy of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf68a65",
   "metadata": {},
   "source": [
    "## Test for drift\n",
    "\n",
    "In this step, you will be checking for drift between the training embeddings and the operational embeddings from before.\n",
    "If drift is detected, a model trained on this training data should be retrained with new operational data. This can help\n",
    "mitigate performance degradation in a deployed model. Visit our [About Drift](../concepts/Drift.md) page to learn more.\n",
    "\n",
    "### Drift detectors\n",
    "\n",
    "DataEval offers a few drift detectors: {class}`.DriftMMD`, {class}`.DriftUnivariate`\n",
    "\n",
    "Since each detector outputs a binary decision on whether drift is detected, a **majority vote** will be used to make the\n",
    "determination of drift.\\\n",
    "To learn more about these algorithms, see the [theory behind drift detection](../concepts/Drift.md#what-is-drift)\n",
    "concept page.\n",
    "\n",
    "### Fit the detectors\n",
    "\n",
    "Each drift detector needs a reference set that the operational set will be compared against. In the following code, you\n",
    "will set the reference data to the training embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15731f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A type alias for all of the drift detectors\n",
    "DriftDetector = DriftMMD | DriftUnivariate\n",
    "\n",
    "# Create a mapping for the detectors to iterate over\n",
    "detectors: dict[str, DriftDetector] = {\n",
    "    \"MMD\": DriftMMD(train_embs),\n",
    "    \"CVM\": DriftUnivariate(train_embs, method=\"cvm\"),\n",
    "    \"KS\": DriftUnivariate(train_embs, method=\"ks\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c3ccb",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "\n",
    "Now that the detectors are setup, predictions can be made against the operational embeddings you made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267bcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(operational_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc77dc3",
   "metadata": {},
   "source": [
    "Did you expect these results?\n",
    "\n",
    "There is no drift detected between the train and operational embeddings because they come from very similar\n",
    "distributions.\\\n",
    "Ideally, your training data and your validation data, which we used as operational, come from the same distribution.\n",
    "This is the purpose of [data splitters](https://scikit-learn.org/stable/api/sklearn.model_selection.html#splitters).\n",
    "\n",
    "So how do we know if the detectors can detect drift?\n",
    "\n",
    "Well, add some random Gaussian noise to the operational embeddings and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform with added gaussian noise\n",
    "noisy_transforms = [transforms, GaussianNoise()]\n",
    "\n",
    "# Create extractor with noisy transforms\n",
    "noisy_extractor = TorchExtractor(resnet, transforms=noisy_transforms)\n",
    "\n",
    "# Applies gaussian noise to images before processing\n",
    "noisy_embs = Embeddings(operational_ds, extractor=noisy_extractor, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(noisy_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d364e1",
   "metadata": {},
   "source": [
    "Now drift is detected!\n",
    "\n",
    "Adding Gaussian noise was enough to cause a noticeable change in the drift detectors, but this is not always the case.\n",
    "There are many [types of drift](../concepts/Drift.md#formal-definition-and-types-of-drift) that data can and will\n",
    "experience.\n",
    "\n",
    "In this step, you learned how to take your generated embeddings and detect drift between the training and operational\n",
    "image data. While there was no drift originally, you were able to add small perturbations to the data that did affect\n",
    "the data distributions and cause drift.\n",
    "\n",
    "Next you will look at the labels' distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ee14e",
   "metadata": {},
   "source": [
    "## Evaluate parity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bda6b",
   "metadata": {},
   "source": [
    "Instead of looking at the images, you can compare the distributions of the labels using a method called\n",
    "[label parity](../concepts/LabelParity.md).\\\n",
    "There is parity between two sets of labels if the label frequencies are approximately equal.\n",
    "\n",
    "You will now compare the label distributions using the `label_parity` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata for each dataset\n",
    "train_md = Metadata(train_ds)\n",
    "operational_md = Metadata(operational_ds)\n",
    "\n",
    "# The VOC dataset has 20 classes\n",
    "label_parity(train_md.class_labels, operational_md.class_labels, num_classes=20)[\"p_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bc069",
   "metadata": {},
   "source": [
    "From the {class}`.ParityOutput` class, you can see that it calculated a p_value of ~**0.95**. Since this is close to\n",
    "1.0, it can be said that the two distributions **have** parity, or similar distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd6a4e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you have learned to create embeddings from the VOC dataset, look for drift between two sets of data,\n",
    "and calculate the parity of two label distributions. These are important steps when monitoring data as drift and lack of\n",
    "parity can affect a model's ability to achieve performance recorded during model training. When data drift is detected\n",
    "or the label distributions lack parity, it is a good idea to consider retraining the model and incorporating operational\n",
    "data into the dataset.\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "## What's next\n",
    "\n",
    "DataEval plays a small, but impactful role in data monitoring as a metrics library.\\\n",
    "Visit these additional resources for more information on other aspects:\n",
    "\n",
    "- Read about the entire [monitoring in AI/ML](../concepts/users/ML_Lifecycle.md#monitoring) stage\n",
    "- Explore DataEval's [API reference](../reference/autoapi/dataeval/index.rst) for drift and other monitoring tools"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
