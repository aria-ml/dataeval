{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af1c558",
   "metadata": {},
   "source": [
    "# How to run clustering analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd5061",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "Data does not typically come labeled and labeling/verifying labels is a time and resource intensive process. Exploratory\n",
    "data analysis (EDA) can often be enhanced by splitting data into similar groups.\n",
    "\n",
    "[Clustering](../concepts/Clustering.md) is a method which groups data in the format of (samples, features). This can be\n",
    "used with images or image embeddings as long as the arrays are flattened to only contain 2 dimensions.\n",
    "\n",
    "The `cluster` function utilizes a clustering algorithm based on the HDBSCAN algorithm. The `Outliers` and `Duplicates`\n",
    "detectors can then analyze the cluster results to identify outliers and duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1f0c0",
   "metadata": {},
   "source": [
    "### When to use\n",
    "\n",
    "The clustering workflow can be used during the EDA process to perform the following:\n",
    "\n",
    "- group a dataset into clusters\n",
    "- verify labeling as a quality control\n",
    "- identify [outliers](../concepts/Outliers.md) in your dataset using the `Outliers` detector\n",
    "- identify duplicates in your dataset using the `Duplicates` detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f3f13",
   "metadata": {},
   "source": [
    "### What you will need\n",
    "\n",
    "1. A 2 dimensional dataset (samples, features)\n",
    "1. A Python environment with the following packages installed:\n",
    "   - `dataeval`\n",
    "   - `matplotlib`\n",
    "\n",
    "This could be a set of flattened images or image embeddings. We recommend using image embeddings (with the feature\n",
    "dimension being \\<=1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc9389",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f13b4",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets as dsets\n",
    "\n",
    "from dataeval.core import cluster\n",
    "from dataeval.quality import Duplicates, Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca40783",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "For the purposes of this demonstration, we are just going to create a generic set of blobs for clustering.\n",
    "\n",
    "This is to help show all of the clustering functionality in one how-to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 5 clusters\n",
    "test_data, labels = dsets.make_blobs(\n",
    "    n_samples=100,\n",
    "    centers=[(-1.5, 1.8), (-1, 3), (0.8, 2.1), (2.8, 1.5), (2.5, 3.5)],\n",
    "    cluster_std=0.3,\n",
    "    random_state=33,\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1a904",
   "metadata": {},
   "source": [
    "Because the clustering result can be used to detect duplicate and outlier data, we are going to modify the dataset to\n",
    "contain a few duplicate datapoints and an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d742d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[71] = [1, 5]\n",
    "test_data[79] = test_data[24]\n",
    "test_data[63] = test_data[58] + 1e-5\n",
    "labels[79] = labels[24]\n",
    "labels[63] = labels[58]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c042b80",
   "metadata": {},
   "source": [
    "## Visualizing the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2671527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from labels to colors\n",
    "label_to_color = np.array([\"b\", \"r\", \"g\", \"y\", \"m\", \"gray\"])\n",
    "\n",
    "# Translate labels to colors using vectorized operation\n",
    "color_array = label_to_color[labels]\n",
    "\n",
    "# Set plotting parameters\n",
    "plot_kwds = {\"alpha\": 0.5, \"s\": 50, \"linewidths\": 0}\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(test_data.T[0], test_data.T[1], c=color_array, **plot_kwds)\n",
    "\n",
    "# Annotate each point in the scatter plot\n",
    "for i, (x, y) in enumerate(test_data):\n",
    "    plt.annotate(str(i), (x, y), textcoords=\"offset points\", xytext=(0, 1), ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340849a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the number of datapoints and that the shape is 2 dimensional\n",
    "print(\"Number of samples: \", len(test_data))\n",
    "print(\"Array shape:\", test_data.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4640e53",
   "metadata": {},
   "source": [
    "## Cluster the data\n",
    "\n",
    "We are now ready to cluster the data and inspect the results.\\\n",
    "There are two different clustering methods, \"kmeans\" and \"hdbscan\". These are selected via the _algorithm_ parameter,\n",
    "with \"hdbscan\" being the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the clusters\n",
    "clusters = cluster(test_data, algorithm=\"hdbscan\", n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters[\"clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb503db",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert clusters[\"clusters\"].max() == 4\n",
    "assert clusters[\"clusters\"].min() == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc27012",
   "metadata": {},
   "source": [
    "### Visualize the resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ebf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same plotting as above\n",
    "color_array = label_to_color[clusters[\"clusters\"]]\n",
    "plt.scatter(test_data.T[0], test_data.T[1], c=color_array, **plot_kwds)\n",
    "\n",
    "# Annotate each point in the scatter plot\n",
    "for i, (x, y) in enumerate(test_data):\n",
    "    plt.annotate(str(i), (x, y), textcoords=\"offset points\", xytext=(0, 1), ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f508651",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We can list out each category followed by the number of items in the category and then display those items on the line\n",
    "below.\n",
    "\n",
    "For the outlier results, the clusterer provides a list of all points that it found to be an outlier.\n",
    "\n",
    "For the duplicates results, the clusterer provides a list of sets of points which it identified as near duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6769e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results using the new detector classes\n",
    "duplicates_detector = Duplicates(cluster_threshold=0.1)\n",
    "duplicates_result = duplicates_detector.from_clusters(clusters)\n",
    "print(\"near image duplicates: \", duplicates_result.items.near)\n",
    "\n",
    "outliers_detector = Outliers()\n",
    "outliers_result = outliers_detector.from_clusters(test_data, clusters, threshold=3)\n",
    "print(\"outliers: \", outliers_result.issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980ef1d",
   "metadata": {},
   "source": [
    "We can see that there was one outlier and there are also 2 sets of near duplicates (the intentionally duplicated\n",
    "points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b8e98",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert len(outliers_result.issues) == 1\n",
    "assert duplicates_result.items.near is not None\n",
    "assert len(duplicates_result.items.near) == 2"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
