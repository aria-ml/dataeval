{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f9c64a",
   "metadata": {},
   "source": [
    "# Identify bias and correlations\n",
    "\n",
    "This guide provides a beginner friendly introduction to dataset bias, including [balance](../concepts/Balance.md),\n",
    "[diversity](../concepts/Diversity.md) and [parity](../concepts/Parity.md).\n",
    "\n",
    "Estimated time to complete: 15 minutes\n",
    "\n",
    "Relevant ML stages: [Data Engineering](../concepts/users/ML_Lifecycle.md#data-engineering)\n",
    "\n",
    "Relevant personas: Data Engineer, T&E Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191eaec",
   "metadata": {},
   "source": [
    "## What you'll do\n",
    "\n",
    "- Use DataEval to identify bias and correlations in the 2012 VOC dataset\n",
    "- Analyze the results using plots and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d4151",
   "metadata": {},
   "source": [
    "## What you'll learn\n",
    "\n",
    "- You will see how to identify bias and correlations present in a dataset.\n",
    "- You will understand the potential impact on your data and ways to mitigate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67b11b",
   "metadata": {},
   "source": [
    "## What you'll need\n",
    "\n",
    "- Basic familiarity with Python\n",
    "- Basic understanding of your dataset structure, including but not limited to its [metadata](../concepts/Metadata.md)\n",
    "- An environment with DataEval installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd53cc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Identifying any biases or correlations present in a dataset is essential to accurately interpreting your model's\n",
    "performance and its ability to generalize to new data. A common cause of poor generalization is shortcut learning —\n",
    "where a model uses secondary or background information to make predictions — which is enabled or exacerbated by dataset\n",
    "sampling biases.\n",
    "\n",
    "### Bias and correlations\n",
    "\n",
    "Understanding biases or correlations present in your dataset is a key component to creating meaningful data splits. Bias\n",
    "in data can lead to misleading conclusions and poor model performance on operational data. There are many different\n",
    "[types of bias](https://arxiv.org/abs/1908.09635). A few of these biases occur during data collection, others occur\n",
    "during dataset development, others occur during model development, while others are a result of the user.\n",
    "\n",
    "Not all forms of bias directly affect the dataset and in order to address the biases that do, you have to make a few\n",
    "assumptions:\n",
    "\n",
    "1. All desired classes are present.\n",
    "1. All available metadata is provided.\n",
    "1. The metadata has been recorded correctly.\n",
    "\n",
    "If any of the above assumptions are violated, then the analysis will not be accurate. When using your own data, you\n",
    "should verify the above assumptions.\n",
    "\n",
    "This guide does not focus on eliminating all bias, rather it focuses on identifying the bias that can be found when\n",
    "developing a dataset.\n",
    "\n",
    "### DataEval metrics\n",
    "\n",
    "DataEval has three dedicated classes for identifying and understanding the bias or correlations that may be present in a\n",
    "dataset: {class}`.Balance`, {class}`.Diversity` and {class}`.Parity`.\n",
    "\n",
    "The `Balance` evaluator measures correlational relationships between metadata factors and classes by calculating the\n",
    "mutual information between the metadata factors and the labels.\n",
    "\n",
    "The `Diversity` evaluator measures the evenness or uniformity of the sampling of metadata factors over a dataset using\n",
    "the inverse Simpson index or Shannon index.\n",
    "\n",
    "The `Parity` evaluator measures the relationship between metadata factors and classes using a chi-squared test.\n",
    "\n",
    "These techniques help ensure that when you split the data for your projects, you minimize things like shortcut learning\n",
    "and leakage between training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9b4b7",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "\n",
    "You'll begin by importing the necessary libraries to walk through this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb75a7",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval dataeval-plots[plotly] maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09067853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataeval_plots as dep\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "from maite_datasets.object_detection import VOCDetection\n",
    "\n",
    "# Load the functions from DataEval that are helpful for bias\n",
    "# as well as the VOCDetection dataset for the tutorial\n",
    "from dataeval import Metadata\n",
    "from dataeval.bias import Balance, Diversity, Parity\n",
    "\n",
    "# Use plotly to render plots\n",
    "dep.set_default_backend(\"plotly\")\n",
    "\n",
    "# Use the notebook renderer so JS is embedded\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6076b92",
   "metadata": {},
   "source": [
    "## Step 1: Load the data\n",
    "\n",
    "You are going to work with the PASCAL VOC 2012 dataset. This dataset is a small curated dataset that was used for a\n",
    "computer vision competition. The images were used for classification, object detection, and segmentation. This dataset\n",
    "was chosen because it has multiple classes and a variety of images and metadata.\n",
    "\n",
    "If this data is already on your computer you can change the file location from `\"./data\"` to wherever the data is\n",
    "stored. Remember to also change the download value from `True` to `False`.\n",
    "\n",
    "For the sake of ensuring that this tutorial runs quickly on most computers, you are going to analyze only the training\n",
    "dataset, which is a little under 6000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the 2012 train dataset and verify the size of the loaded dataset\n",
    "ds = VOCDetection(root=\"./data\", download=True, image_set=\"train\", year=\"2012\")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f61f72",
   "metadata": {},
   "source": [
    "Before moving on, verify that the above code cell printed out 5717 for the size of the\n",
    "[dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2011/dbstats.html).\n",
    "\n",
    "This ensures that everything is working as needed for the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e3477",
   "metadata": {},
   "source": [
    "## Step 2: Structure the metadata\n",
    "\n",
    "This guide focuses on evaluating labels and metadata of the dataset rather than the images themselves. As each dataset\n",
    "has its own image and metadata formats, you will need to understand how your particular metadata is structured.\n",
    "\n",
    "Start by taking a look at the metadata structure of the VOC 2012 dataset by creating a `Metadata` class from the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc71e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Metadata from the dataset\n",
    "metadata = Metadata(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7de2d",
   "metadata": {},
   "source": [
    "The metadata in the dataset is provided as a dictionary entry for each datum, such that the aggregated data is a\n",
    "collection of _N_ metadata dictionaries each with a nested list of _M_ objects in the image. Start by inspecting the raw\n",
    "metadata of the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a71718",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cd7cd",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "`Metadata` is unable to process nested lists. For this dataset, _part_ is a factor that describes certain\n",
    "parts of a _person_ object (such as _head_, _foot_ and _hand_), each with separate bounding box coordinates. You will\n",
    "ignore this information for this example.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0727a",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The nested objects _horse_ and _person_ from the first metadata entry will be expanded to a complete metadata\n",
    "entry for each object.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2a5b5",
   "metadata": {},
   "source": [
    "Next you will want to select the factors to include for bias analysis as well as the continuous factor bins for any\n",
    "continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.include = [\n",
    "    \"image_width\",\n",
    "    \"image_height\",\n",
    "    \"segmented\",\n",
    "    \"pose\",\n",
    "    \"truncated\",\n",
    "    \"difficult\",\n",
    "]\n",
    "\n",
    "metadata.continuous_factor_bins = {\n",
    "    \"image_width\": 5,\n",
    "    \"image_height\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e0ccf",
   "metadata": {},
   "source": [
    "Now that the `Metadata` is ready to go, you can begin analyzing the dataset for bias!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6648a",
   "metadata": {},
   "source": [
    "## Step 3: Assess dataset balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf52e8",
   "metadata": {},
   "source": [
    "The {class}`.Balance` class measures correlational relationships between metadata factors and classes in a dataset. It\n",
    "analyzes the metadata factors against both the classes and other factors to identify relationships.\n",
    "\n",
    "The results can be retrieved using the _balance_ and _factors_ attributes of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal = Balance().evaluate(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee5eda",
   "metadata": {},
   "source": [
    "The information provided by `Balance` may be visually understood with a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae71c9",
   "metadata": {},
   "source": [
    "The heatmap shows that the greatest correlations are in the bounding box locations (_xmin_ with _xmax_ and _ymin_ with\n",
    "_ymax_) and the image dimensions (_height_ and _width_).\n",
    "\n",
    "Also the _ymax_ of the bounding box location is correlated with the _height_ of the image. It is not surprising that\n",
    "_height_ and _width_ have correlation since many of the images are similarly sized.\n",
    "\n",
    "The correlations between _xmin_ and _xmax_ and between _ymin_ and _ymax_ suggests that there is repetition in bounding\n",
    "box width and height across the objects. However, the fact that _pose_ has a value of 0.08 with _class_ means that a few\n",
    "of the classes have specific poses across a fair percentage of the images for that class. An example of this would be\n",
    "most _pottedplant_ images having the same _pose_ value.\n",
    "\n",
    "In addition to analyzing class and other factors, the balance function also analyzes metadata factors with individual\n",
    "classes to identify relationships between only one class and secondary factors.\n",
    "\n",
    "You can visualize the classwise results for balance by setting the _plot_classwise_ parameter to _True_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(bal, plot_classwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd21b7",
   "metadata": {},
   "source": [
    "The classwise heatmap shows that factors other than _class_ do not have any significant correlation with a specific\n",
    "class.\n",
    "\n",
    "Classwise balance shows correlation of individual classes with all class labels, indicating relative class imbalance. In\n",
    "this case the _person_ class is over-represented relative to most other classes.\n",
    "\n",
    "This means that a model might learn a bias towards the _person_ class label due to its frequency in the training set,\n",
    "which becomes a problem if the test/operational dataset doesn't have the same imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9086f4",
   "metadata": {},
   "source": [
    "## Step 4: Assess dataset diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26e487",
   "metadata": {},
   "source": [
    "The {class}`.Diversity` evaluator measures the evenness or uniformity of the sampling of metadata factors over a\n",
    "dataset. Values near 1 indicate uniform sampling, while values near 0 indicate imbalanced sampling, e.g. all values\n",
    "taking a single value. For more information see the [Diversity](../concepts/Diversity.md) concept page.\n",
    "\n",
    "The results can be retrieved using the _diversity_index_ attribute of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fae97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = Diversity().evaluate(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54504a40",
   "metadata": {},
   "source": [
    "Again, it's often easiest to see the differences between the different factors when visualizing them using a bar chart\n",
    "to show the factor-class analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c25d7a",
   "metadata": {},
   "source": [
    "In the results above, the factors _truncated_ and _occluded_ have values near 1, meaning that there is relatively little\n",
    "or no bias in these factors.\n",
    "\n",
    "The categories of most interest are those that are between 0.4 and 0.1 because this region represents skewed value\n",
    "distributions for the factor.\n",
    "\n",
    "The following factors fall into this category:\n",
    "\n",
    "- _class_\n",
    "- _width_\n",
    "- _height_\n",
    "- _segmented_\n",
    "- _difficult_\n",
    "\n",
    "These factors contain bias that should be addressed either by adding or removing data to even out the sampling. For\n",
    "instance, the _class_ factor highlights that there is unevenness in the number of data points per class.\n",
    "\n",
    "In addition to analyzing class, the diversity function also analyzes metadata factors with individual classes to assess\n",
    "uniformity of metadata factors within a class. You can visualize the classwise results by setting the `plot_classwise`\n",
    "parameter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(div, plot_classwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4eeeb",
   "metadata": {},
   "source": [
    "These results expand the above results on a classwise basis.\n",
    "\n",
    "Things to look for here are large variances for a given factor across the different classes. For example, _pose_ has\n",
    "values ranging from 0.01 to 0.84, which means that a few classes have almost uniform selection of the different _pose_\n",
    "values while other classes essentially only have one _pose_ value. This makes sense as the _bottle_ or _pottedplant_\n",
    "class does not have multiple _pose_ directions, while the _person_ class does.\n",
    "\n",
    "What needs to be further investigated are things like whether the _sofa_ class should have a _pose_ direction, because a\n",
    "diversity value of 0.4 means that a few of the images do while others do not.\n",
    "\n",
    "Also, the _cat_ class has a low score signifying that most of the images fall into one or two categories rather than\n",
    "being spread even across the categories. This highlights an error in the data collection process — the value was not\n",
    "specified for most _cat_ images and therefore defaulted to \"Unspecified\".\n",
    "\n",
    "An alternative error would be a dataset in which the _cat_ images have most cats facing a specific direction, which\n",
    "would require additional data to overcome the bias, but that is not the case for this dataset. It has plenty of cats\n",
    "facing each direction, but only a few of them contain a _pose_ value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae0474",
   "metadata": {},
   "source": [
    "## Step 5: Assess dataset parity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7653e2f",
   "metadata": {},
   "source": [
    "The {class}`.Parity` evaluator measures the relationship between metadata factors and classes using a chi-squared test.\n",
    "A high score with a low p-value suggests that a metadata factor is strongly correlated with a class label.\n",
    "\n",
    "The results can be retrieved using the _score_ and _p_value_ attributes of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = Parity().evaluate(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16a841",
   "metadata": {},
   "source": [
    "The warning above states that the metric works best when there are more than 5 samples in each value-label combination.\n",
    "However, because of the large number of total samples, the difference between 1 and 5 samples does not significantly\n",
    "affect the results.\n",
    "\n",
    "When evaluating the results of parity for a large number of factors, it may be easier to understand the results in a\n",
    "DataFrame.\n",
    "\n",
    "The {class}`.ParityOutput` class contains a `to_dataframe` function to format the results of the diversity function as a\n",
    "DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(par.factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86429db",
   "metadata": {},
   "source": [
    "According to the results, all metadata are correlated with _class_ labels. However, `parity` is based on the idea of an\n",
    "expected frequency and how the observed differs from what is expected. The expected frequencies are determined by sums\n",
    "of the values for each metadata category.\n",
    "\n",
    "This function works best when the expected frequencies for a given factor for each individual class are known _a\n",
    "priori_. For the case above, the expected frequency for the _pose_ metadata category shouldn't be the same for all\n",
    "classes. The _diningtable_, _pottedplant_, and _bottle_ classes only have a single value for _pose_ which automatically\n",
    "throws off the metric because not all of the classes have an identical expected frequency for _pose_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7f19f",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b19e14",
   "metadata": {},
   "source": [
    "Having analyzed the dataset for bias with multiple metrics, the conclusion is that this dataset has bias. Training a\n",
    "model on this dataset has the potential to learn shortcuts and underperform on operational data if the biases are not\n",
    "representative of biases in the operational dataset.\n",
    "\n",
    "The metadata categories identified by the `Balance`, `Diversity` and `Parity` evaluators contain issues such as\n",
    "imbalanced classes and imbalanced parameters per class. DataEval isn't able to tell you exactly why they are imbalanced,\n",
    "but it highlights the categories that you need to check.\n",
    "\n",
    "As you can see, the DataEval methods are here to help you gain a deep understanding of your dataset and all of its\n",
    "strengths and limitations. It is designed to help you create representative and reliable datasets.\n",
    "\n",
    "Good luck with your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7256d6",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "In addition to identifying bias and correlations in a dataset, DataEval offers additional tutorials to help you learn\n",
    "about dataset analysis:\n",
    "\n",
    "- To clean a dataset use the [Data Cleaning Guide](tt_clean_dataset.md).\n",
    "- To identify coverage gaps and outliers use the [Assessing the Data Space Guide](tt_assess_data_space.md).\n",
    "- To monitor data for shifts during operation use the [Data Monitoring Guide](tt_monitor_shift.md).\n",
    "\n",
    "To learn more about the balance, diversity and parity evaluators, see the [Balance](../concepts/Balance.md),\n",
    "[Diversity](../concepts/Diversity.md) and [Parity](../concepts/Parity.md) concept pages.\n",
    "\n",
    "## On your own\n",
    "\n",
    "Once you are familiar with DataEval and dataset analysis, you will want to run this analysis on your own dataset. When\n",
    "you do, make sure that you analyze all of your data and not just the training set."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
