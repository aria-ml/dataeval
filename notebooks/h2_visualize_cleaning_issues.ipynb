{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95657b39",
   "metadata": {},
   "source": [
    "# How to visualize cleaning issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4afed1",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "Exploratory data analysis (EDA) can be overwhelming. There are so many things to check. Duplicates in your dataset,\n",
    "bad/corrupted images in the set, blurred or bright/dark images, the list goes on.\n",
    "\n",
    "DataEval created a [data cleaning](../concepts/DataCleaning.md) class to assist you with your EDA so you can start\n",
    "training your models on high quality\n",
    "data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c31eb7",
   "metadata": {},
   "source": [
    "### When to use\n",
    "\n",
    "The cleaning class should be used during the initial EDA process or if you are trying to verify that you have the right\n",
    "data in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9752f8",
   "metadata": {},
   "source": [
    "### What you will need\n",
    "\n",
    "1. A dataset to analyze\n",
    "1. A Python environment with the following packages installed:\n",
    "   - `dataeval`\n",
    "   - `maite-datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f46a76",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162bddd",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1db23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from maite_datasets.image_classification import CIFAR10\n",
    "\n",
    "from dataeval import Metadata\n",
    "from dataeval.quality import Outliers\n",
    "\n",
    "_ = pl.Config.set_tbl_rows(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d90a7b",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "We are going to start by loading in the CIFAR-10 dataset.\n",
    "\n",
    "The CIFAR-10 dataset contains 60,000 images - 50,000 in the train set and 10,000 in the test set. For the purposes of\n",
    "this demonstration, we are just going to use the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the CIFAR10 dataset\n",
    "testing_dataset = CIFAR10(\"./data\", image_set=\"test\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32063d9",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "\n",
    "Now we can begin finding those images which are significantly different from the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Duplicates class\n",
    "outliers = Outliers(outlier_method=\"zscore\", outlier_threshold=3.5)\n",
    "\n",
    "# Evaluate the data\n",
    "results = outliers.evaluate(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d2f1f",
   "metadata": {},
   "source": [
    "The results are a dictionary with the keys being the image that has an issue in one of the listed properties below:\n",
    "\n",
    "- Brightness\n",
    "- Blurriness\n",
    "- Missing\n",
    "- Zero\n",
    "- Width\n",
    "- Height\n",
    "- Size\n",
    "- Aspect Ratio\n",
    "- Channels\n",
    "- Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of images with an issue: {len(results.aggregate_by_item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62fc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View issues by metric\n",
    "results.aggregate_by_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View issues by class\n",
    "results.aggregate_by_class(Metadata(testing_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0bfdb",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert results.issues.shape[0] == 499"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
