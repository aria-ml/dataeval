{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Deduplication Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "One of the first steps in Exploratory Data Analysis (EDA) is to check for duplicates. Duplicates add no new information and can distort model training by over-emphasizing features that in appear in the duplicates.\n",
    "\n",
    "DataEval provides a Duplicates class to assist you in removing duplicates so you can start training your models on high quality data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "The Duplicates class should be used if you need to find duplicate images in your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A python envornment with following packages installed:\n",
    "   - dataeval or dataeval[all]\n",
    "2. A dataset to analyze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Getting Started_\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Google Colab Only\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from dataeval.detectors.linters import Duplicates\n",
    "from dataeval.utils.data import Metadata\n",
    "from dataeval.utils.data.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "Load the MNIST data and create the dataset.\n",
    "\n",
    "The MNIST dataset contains 70,000 images - 60,000 in the train set and 10,000 in the test set.\n",
    "For the purposes of this demonstration, we are just going to use the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset\n",
    "testing_dataset = MNIST(root=\"./data/\", image_set=\"test\")\n",
    "\n",
    "# Get the labels\n",
    "labels = Metadata(testing_dataset).targets.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the MNIST dataset does not contain any exact duplicates we are going to adjust the dataset to include some.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some indices to duplicate\n",
    "print(\"Exact duplicates\")\n",
    "duplicates = {}\n",
    "for i in [1, 2, 5, 9]:\n",
    "    matching_indices = np.where(labels == i)[0]\n",
    "    print(f\"\\t{i} - ({matching_indices[23]}, {matching_indices[78]})\")\n",
    "    duplicates[int(matching_indices[78])] = int(matching_indices[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset with the identified duplicate indices swapped\n",
    "indices_with_duplicates = [duplicates.get(i, i) for i in range(len(testing_dataset))]\n",
    "duplicates_ds = Subset(testing_dataset, indices_with_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Duplicates\n",
    "\n",
    "Now we are asking our Duplicates class to find the needle in the haystack.\n",
    "There are only 4 exact duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Duplicates class to begin to identify duplicate images.\n",
    "identifyDuplicates = Duplicates()\n",
    "\n",
    "# Evaluate the data\n",
    "results = identifyDuplicates.evaluate(duplicates_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be returned as a dictionary with exact and near as the keys. So we will extract those to view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in results.dict().items():\n",
    "    print(f\"{category} - {len(images)}\")\n",
    "    print(f\"\\t{images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Duplicates` class was able to find all 4 exact duplicates out of the 10,000 samples.\n",
    "\n",
    "It also found several sets of images that are very closely related to each other, and since we are using hand written digits we would expect it to find some images that were nearly identical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION CELL ###\n",
    "assert len(results.exact) == len(duplicates)\n",
    "for k, v in duplicates.items():\n",
    "    assert [v, k] in results.exact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
