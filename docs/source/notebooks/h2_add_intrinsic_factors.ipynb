{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add intrinsic factors to Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "When performing analysis on datasets, metadata may sometimes be sparse or unavailable. Adding metadata to a dataset for\n",
    "analysis may be necessary at times, and can come in the forms of calculated intrinsic values or additional information\n",
    "originally unavailable on the source dataset.\n",
    "\n",
    "This guide will show you how to add in the calculated statistics from DataEval's {func}`.calculate` function to the\n",
    "metadata for bias analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "Adding metadata factors should be done when little or no metadata is available on the dataset, or to gain insights\n",
    "specific to metadata of interest that is not present natively in the dataset metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A dataset to analyze\n",
    "1. A Python environment with the following packages installed:\n",
    "   - `dataeval`\n",
    "   - `dataeval-plots[plotly]`\n",
    "   - `maite-datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Getting Started_\n",
    "\n",
    "First import the required libraries needed to set up the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval dataeval-plots[plotly] maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataeval_plots as dep\n",
    "import plotly.io as pio\n",
    "import polars as pl\n",
    "from maite_datasets.image_classification import CIFAR10\n",
    "\n",
    "from dataeval import Metadata\n",
    "from dataeval.bias import Balance, Diversity, Parity\n",
    "from dataeval.core import calculate\n",
    "from dataeval.flags import ImageStats\n",
    "from dataeval.selection import Limit, Select, Shuffle\n",
    "\n",
    "_ = pl.Config.set_tbl_rows(-1)\n",
    "# Use plotly to render plots\n",
    "dep.set_default_backend(\"plotly\")\n",
    "dep.set_default_backend(\"matplotlib\")  # LOL BUMP BUMP\n",
    "\n",
    "# Use the notebook renderer so JS is embedded\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Begin by loading in the CIFAR-10 dataset.\n",
    "\n",
    "The CIFAR-10 dataset contains 60,000 images - 50,000 in the train set and 10,000 in the test set. We will use a shuffled\n",
    "sample of 20,000 images from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the CIFAR10 dataset and limit to 20,000 images with random shuffling\n",
    "cifar10 = Select(CIFAR10(\"data\", image_set=\"base\", download=True), [Limit(20000), Shuffle(seed=0)])\n",
    "print(cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the metadata\n",
    "\n",
    "You can begin by inspecting the available factor names in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Metadata(cifar10)\n",
    "print(f\"Factor names: {metadata.factor_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check of the {func}`.balance` of the single factor will show no mutual information between the classes and the\n",
    "`batch_num` which indicates the on-disk binary file the image was extracted from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance at index 0 is always class\n",
    "Balance().evaluate(metadata).balance[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add image statistics to the metadata\n",
    "\n",
    "In order to perform additional bias analysis on the dataset when no meaningful metadata are provided, you will augment\n",
    "the metadata with statistics of the images using the {func}`.calculate` function.\n",
    "\n",
    "Begin by running `calculate` for the `PIXEL` and `VISUAL` image stats for the dataset and adding the stats factors to\n",
    "the `Metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixel and visual statistics\n",
    "calc_results = calculate(cifar10, stats=ImageStats.PIXEL | ImageStats.VISUAL)\n",
    "\n",
    "# Append the factors to the metadata\n",
    "metadata.add_factors(calc_results[\"stats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will add the `calculate` output to the metadata as factors, and exclude factors that are uniform or without\n",
    "significance.\n",
    "\n",
    "Additionally, you will specify a binning strategy for continuous statistical factors, which are, for our purposes,\n",
    "continuous. For this example, bin everything into 10 uniform-width bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the id and batch_num as it is not a relevant factor for bias analysis\n",
    "metadata.exclude = [\"id\", \"batch_num\"]\n",
    "\n",
    "# Provide binning for the continuous statistical factors using 5 uniform-width bins for each factor\n",
    "keys = (\"mean\", \"std\", \"var\", \"skew\", \"kurtosis\", \"entropy\", \"brightness\", \"darkness\", \"sharpness\", \"contrast\", \"zeros\")\n",
    "metadata.continuous_factor_bins = dict.fromkeys(keys, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform bias analysis\n",
    "\n",
    "Now you can run the bias analysis evaluators {class}`.Balance`, {class}`.Diversity` and {class}`.Parity` on the dataset\n",
    "metadata augmented with intrinsic statistical factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_output = Balance().evaluate(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(balance_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the very high mutual information between the variance and standard deviation of image intensities, which is\n",
    "expected. Mean image intensity correlates with brightness, darkness, and contrast. However, none of the intrinsic\n",
    "factors correlate strongly with class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.plot(balance_output, plot_classwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classwise balance also indicates minimal correlation of image statistics and individual classes. Uniform mutual\n",
    "information between individual classes and all class labels indicates balanced class representation in the subsampled\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_output = Diversity().evaluate(metadata)\n",
    "dep.plot(diversity_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diversity index also indicates uniform sampling of classes within the dataset. The apparently low diversity of\n",
    "kurtosis across the dataset may indicate an inadequate binning strategy (for metric computation) given that the other\n",
    "statistical moments appear to be more evenly distributed. Further investigation and iteration could be done to assess\n",
    "sensitivity to binning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_output = Parity().evaluate(metadata)\n",
    "parity_output.factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now augment your datasets with additional metadata information, either from additional sources or using\n",
    "`dataeval` statistical functions for insights into your data."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "dataeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
