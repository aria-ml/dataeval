{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q dataeval maite-datasets\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from maite_datasets.object_detection import VOCDetection\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "from torchvision.transforms.v2 import GaussianNoise\n",
    "\n",
    "from dataeval import Embeddings, Metadata\n",
    "from dataeval.core import label_parity\n",
    "from dataeval.encoders import TorchEmbeddingEncoder\n",
    "from dataeval.shift import DriftMMD, DriftUnivariate\n",
    "\n",
    "# Set a random seed\n",
    "rng = np.random.default_rng(213)\n",
    "\n",
    "# Set default torch device for notebook\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT, progress=False)\n",
    "\n",
    "# Replace the final fully connected layer with a Linear layer\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCDetection Dataset\n",
      "--------------------\n",
      "    Year: 2012\n",
      "    Transforms: []\n",
      "    Image Set: train\n",
      "    Metadata: {'id': 'VOCDetection_train', 'index2label': {0: 'aeroplane', 1: 'bicycle', 2: 'bird', 3: 'boat', 4: 'bottle', 5: 'bus', 6: 'car', 7: 'cat', 8: 'chair', 9: 'cow', 10: 'diningtable', 11: 'dog', 12: 'horse', 13: 'motorbike', 14: 'person', 15: 'pottedplant', 16: 'sheep', 17: 'sofa', 18: 'train', 19: 'tvmonitor'}, 'split': 'train'}\n",
      "    Path: /builds/jatic/aria/dataeval/docs/source/notebooks/data/vocdataset/VOCdevkit/VOC2012\n",
      "    Size: 5717\n",
      "Image 0 shape: (3, 442, 500)\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"train\", download=True)\n",
    "print(train_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCDetection Dataset\n",
      "--------------------\n",
      "    Year: 2012\n",
      "    Transforms: []\n",
      "    Image Set: val\n",
      "    Metadata: {'id': 'VOCDetection_val', 'index2label': {0: 'aeroplane', 1: 'bicycle', 2: 'bird', 3: 'boat', 4: 'bottle', 5: 'bus', 6: 'car', 7: 'cat', 8: 'chair', 9: 'cow', 10: 'diningtable', 11: 'dog', 12: 'horse', 13: 'motorbike', 14: 'person', 15: 'pottedplant', 16: 'sheep', 17: 'sofa', 18: 'train', 19: 'tvmonitor'}, 'split': 'val'}\n",
      "    Path: /builds/jatic/aria/dataeval/docs/source/notebooks/data/vocdataset/VOCdevkit/VOC2012\n",
      "    Size: 5823\n",
      "Image 0 shape: (3, 442, 500)\n"
     ]
    }
   ],
   "source": [
    "# Load the \"operational\" dataset\n",
    "operational_ds = VOCDetection(\"./data\", year=\"2012\", image_set=\"val\", download=True)\n",
    "print(operational_ds)\n",
    "print(f\"Image 0 shape: {train_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained model transformations\n",
    "transforms = ResNet18_Weights.DEFAULT.transforms()\n",
    "\n",
    "# Create encoder with model and transforms\n",
    "encoder = TorchEmbeddingEncoder(resnet, batch_size=64, transforms=transforms)\n",
    "\n",
    "# Create training batches and targets\n",
    "train_embs = Embeddings(train_ds, encoder=encoder)\n",
    "\n",
    "# Create operational batches and targets\n",
    "operational_embs = Embeddings(operational_ds, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5717, (128,))\n",
      "(5823, (128,))\n"
     ]
    }
   ],
   "source": [
    "print(f\"({len(train_embs)}, {train_embs[0].shape})\")  # (5717, shape)\n",
    "print(f\"({len(operational_embs)}, {operational_embs[0].shape})\")  # (5823, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A type alias for all of the drift detectors\n",
    "DriftDetector = DriftMMD | DriftUnivariate\n",
    "\n",
    "# Create a mapping for the detectors to iterate over\n",
    "detectors: dict[str, DriftDetector] = {\n",
    "    \"MMD\": DriftMMD(train_embs),\n",
    "    \"CVM\": DriftUnivariate(train_embs, method=\"cvm\"),\n",
    "    \"KS\": DriftUnivariate(train_embs, method=\"ks\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD detected drift? False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVM detected drift? False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS detected drift? False\n"
     ]
    }
   ],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(operational_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform with added gaussian noise\n",
    "noisy_transforms = [transforms, GaussianNoise()]\n",
    "\n",
    "# Create encoder with noisy transforms\n",
    "noisy_encoder = TorchEmbeddingEncoder(resnet, batch_size=64, transforms=noisy_transforms)\n",
    "\n",
    "# Applies gaussian noise to images before processing\n",
    "noisy_embs = Embeddings(operational_ds, encoder=noisy_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD detected drift? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVM detected drift? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS detected drift? True\n"
     ]
    }
   ],
   "source": [
    "# Iterate and print the name of the detector class and its boolean drift prediction\n",
    "for name, detector in detectors.items():\n",
    "    print(f\"{name} detected drift? {detector.predict(noisy_embs).drifted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949856067521638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the metadata for each dataset\n",
    "train_md = Metadata(train_ds)\n",
    "operational_md = Metadata(operational_ds)\n",
    "\n",
    "# The VOC dataset has 20 classes\n",
    "label_parity(train_md.class_labels, operational_md.class_labels, num_classes=20)[\"p_value\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}