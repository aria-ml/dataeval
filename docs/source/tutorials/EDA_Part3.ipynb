{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify bias and correlations\n",
    "\n",
    "This guide provides a beginner friendly introduction to dataset bias, including balance, diversity and parity.\n",
    "\n",
    "Estimated time to complete: 15 minutes\n",
    "\n",
    "Relevant ML stages: Data Engineering\n",
    "\n",
    "Relevant personas: Data Engineer, T&E Engineer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you'll do\n",
    "\n",
    "- Use DataEval to identify bias and correlations in the 2011 VOC dataset\n",
    "- Analyze the results using plots and tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you'll learn\n",
    "\n",
    "- You will see how to identify bias and correlations present in a dataset.\n",
    "- You will understand the potential impact on your data and ways to mitigate them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you'll need\n",
    "\n",
    "- Basic familiarity with Python\n",
    "- Basic understanding of your dataset structure, including but not limited to its metadata\n",
    "- An environment with DataEval installed with the `all` extra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Identifying any biases or correlations present in a dataset is essential to\n",
    "accurately interpreting your model's performance and its ability to generalize\n",
    "to new data. A common cause of poor generalization is shortcut learning &mdash;\n",
    "where a model uses secondary or background information to make predictions\n",
    "&mdash; which is enabled or exacerbated by dataset sampling biases.\n",
    "\n",
    "### Bias and correlations\n",
    "\n",
    "Understanding biases or correlations present in your dataset is a key component\n",
    "to creating meaningful data splits. Bias in data can lead to misleading\n",
    "conclusions and poor model performance on operational data. There are many\n",
    "different [types of bias](https://arxiv.org/abs/1908.09635). A few of these\n",
    "biases occur during data collection, others occur during dataset development,\n",
    "others occur during model development, while others are a result of the user.\n",
    "\n",
    "Not all forms of bias directly affect the dataset and in order to address the\n",
    "biases that do, you have to make a few assumptions:\n",
    "\n",
    "1. All desired classes are present.\n",
    "2. All available metadata is provided.\n",
    "3. The metadata has been recorded correctly.\n",
    "\n",
    "If any of the above assumptions are violated, then the analysis will not be\n",
    "accurate. When using your own data, you should verify the above assumptions.\n",
    "\n",
    "This guide does not focus on eliminating all bias, rather it focuses on\n",
    "identifying the bias that can be found when developing a dataset.\n",
    "\n",
    "### DataEval metrics\n",
    "\n",
    "DataEval has three dedicated functions for identifying and understanding the\n",
    "bias or correlations that may be present in a dataset: {func}`.balance`,\n",
    "{func}`.diversity` and {func}`.parity`.\n",
    "\n",
    "The `balance` function measures correlational relationships between metadata\n",
    "factors and classes by calculating the mutual information between the metadata\n",
    "factors and the labels.\n",
    "\n",
    "The `diversity` function measures the evenness or uniformity of the sampling\n",
    "of metadata factors over a dataset using the inverse Simpson index or Shannon\n",
    "index.\n",
    "\n",
    "The `parity` function measures the relationship between metadata factors\n",
    "and classes using a chi-squared test.\n",
    "\n",
    "These techniques help ensure that when you split the data for your projects,\n",
    "you minimize things like shortcut learning and leakage between training and\n",
    "testing sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "\n",
    "You'll begin by importing the necessary libraries to walk through this guide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    # specify the version of DataEval (==X.XX.X) for versions other than the latest\n",
    "    %pip install -q dataeval\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the functions from DataEval that are helpful for bias\n",
    "# as well as the VOCDetection dataset for the tutorial\n",
    "from dataeval.metrics.bias import balance, diversity, parity\n",
    "from dataeval.utils.data.datasets import VOCDetection\n",
    "from dataeval.utils.metadata import merge, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data\n",
    "\n",
    "You are going to work with the PASCAL VOC 2011 dataset.\n",
    "This dataset is a small curated dataset that was used for a computer vision competition.\n",
    "The images were used for classification, object detection, and segmentation.\n",
    "This dataset was chosen because it has multiple classes and a variety of images and metadata.\n",
    "\n",
    "If this data is already on your computer you can change the file location from `\"./data\"` to wherever the data is stored.\n",
    "Remember to also change the download value from `True` to `False`.\n",
    "\n",
    "For the sake of ensuring that this tutorial runs quickly on most computers, you are going to analyze only the training dataset, which is a little under 6000 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the 2011 train dataset and verify the size of the loaded dataset\n",
    "ds = VOCDetection(root=\"./data\", year=\"2011\", image_set=\"train\", download=True)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, verify that the above code cell printed out 5717 for the size of the [dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2011/dbstats.html).\n",
    "\n",
    "This ensures that everything is working as needed for the tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Structure the metadata\n",
    "\n",
    "This guide focuses on evaluating labels and metadata of the dataset rather than\n",
    "the images themselves. As each dataset has its own image and metadata formats, you\n",
    "will need to understand how your particular metadata is structured.\n",
    "\n",
    "Start by taking a look at the metadata structure of the VOC 2011 dataset on the first\n",
    "dataset item. Each dataset item is composed of an (image, metadata) tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the label structure\n",
    "ds[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata is provided as a dictionary entry for each datum, such that the\n",
    "aggregated data is a collection of _N_ metadata dictionaries each with a nested\n",
    "list of _M_ objects in the image. In the example above, the first image contains\n",
    "2 objects; a _horse_ and a _person_ defined in the _annotation_/_object_ list.\n",
    "\n",
    "In order to use this information with DataEval, we will show how we can use\n",
    "{func}`.merge` and {func}`.preprocess` to prepare the metadata for use.\n",
    "\n",
    "Begin by running `merge` on the aggregated metadata dictionaries to process the\n",
    "collection into a single dictionary of metadata keys, each with a flattened list\n",
    "of all object metadata values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataset metadata entries into a single metadata dictionary\n",
    "merged = merge(metadata=(d[1] for d in ds), image_index_key=\"filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `merge` was unable to process _annotation | object | part_ keys as it\n",
    "is a nested list. For this dataset, _part_ describes certain parts of a _person_\n",
    "object (such as _head_, _foot_ and _hand_), each with separate bounding box\n",
    "coordinates. You can ignore this information for this example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the same first two objects in the merged metadata dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v[:2] for k, v in merged.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the nested _horse_ and _person_ objects from the first metadata\n",
    "entry have been expanded to complete metadata entries for each object.\n",
    "\n",
    "Next you will run {func}`.preprocess` on the metadata to create the\n",
    "{class}`.Metadata` object DataEval will use for the bias functions.\n",
    "\n",
    "The primary functions performed by `preprocess` are extracting class labels\n",
    "(identifiable through the key _name_), discretization of continuous data\n",
    "(like _xmin_) into bins, and selecting keys of interest to include.\n",
    "\n",
    "In this example, you will want to include image information (_width_,\n",
    "_height_) as well as object information (_name_, _pose_,\n",
    "_truncated_, _occluded_, _xmin_, _ymin_, _xmax_, _ymax_, _difficult_)\n",
    "to use for bias analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = preprocess(\n",
    "    metadata=merged,\n",
    "    class_labels=\"name\",\n",
    "    continuous_factor_bins={\"width\": 5, \"height\": 5, \"xmin\": 5, \"ymin\": 5, \"xmax\": 5, \"ymax\": 5},\n",
    "    exclude=[\"folder\", \"filename\", \"database\", \"annotation\", \"image\", \"depth\"],\n",
    "    image_index_key=\"filename\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `Metadata` is ready to go, you can begin analyzing the dataset for bias!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assess dataset balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The {func}`.balance` function measures correlational relationships between metadata\n",
    "factors and classes in a dataset. It analyzes the metadata factors against both the\n",
    "classes and other factors to identify relationships.\n",
    "\n",
    "The results can be retrieved using the _balance_ and _factors_ attributes of the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal = balance(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information provided by the `balance` function may be visually understood with a\n",
    "heat map. The {class}`.BalanceOutput` class contains a plot function to plot the results as\n",
    "a heat map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap shows that the greatest correlations are in the bounding box locations\n",
    "(_xmin_ with _xmax_ and _ymin_ with _ymax_) and the image dimensions (_height_ and\n",
    "_width_).\n",
    "\n",
    "Also the _ymax_ of the bounding box location is correlated with the _height_ of the\n",
    "image. It is not surprising that _height_ and _width_ have correlation since many\n",
    "of the images are similarly sized.\n",
    "\n",
    "The correlations between _xmin_ and _xmax_ and between _ymin_ and _ymax_ suggests\n",
    "that there is repetition in bounding box width and height across the objects.\n",
    "However, the fact that _pose_ has a value of 0.08 with _class_ means that a few of\n",
    "the classes have specific poses across a fair percentage of the images for that\n",
    "class. An example of this would be most _pottedplant_ images having the same _pose_\n",
    "value.\n",
    "\n",
    "In addition to analyzing class and other factors, the balance function also analyzes\n",
    "metadata factors with individual classes to identify relationships between only one\n",
    "class and secondary factors.\n",
    "\n",
    "Again, the plot function of the balance output class can plot a heatmap of the\n",
    "classwise results for visualizing. The _plot_classwise_ parameter needs to be set to\n",
    "_True_ to use the classwise results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bal.plot(plot_classwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classwise heatmap shows that factors other than _class_ do not have any significant\n",
    "correlation with a specific class.\n",
    "\n",
    "Classwise balance shows correlation of individual classes with all class labels,\n",
    "indicating relative class imbalance. In this case the _person_ class is over-represented\n",
    "relative to most other classes.\n",
    "\n",
    "This means that a model might learn a bias towards the _person_ class label due to its\n",
    "frequency in the training set, which becomes a problem if the test/operational dataset\n",
    "doesn't have the same imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assess dataset diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The {func}`.diversity` function measures the evenness or uniformity of the sampling\n",
    "of metadata factors over a dataset. Values near 1 indicate uniform sampling, while\n",
    "values near 0 indicate imbalanced sampling, e.g. all values taking a single value.\n",
    "For more information see the [Diversity](../concepts/Diversity.md) concept page.\n",
    "\n",
    "The results can be retrieved using the _diversity_index_ attribute of the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = diversity(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it's often easiest to see the differences between the different factors when\n",
    "visualizing them. The {class}`.DiversityOutput` class contains a plot function to plot the\n",
    "results of the diversity function. It uses a bar chart to plot the factor-class analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = div.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, the factors _truncated_ and _occluded_ have values near\n",
    "1, meaning that there is relatively little or no bias in these factors.\n",
    "\n",
    "The categories of most interest are those that are between 0.4 and 0.1 because\n",
    "this region represents skewed value distributions for the factor.\n",
    "\n",
    "The following factors fall into this category:\n",
    "\n",
    "- _class_\n",
    "- _width_\n",
    "- _height_\n",
    "- _segmented_\n",
    "- _difficult_\n",
    "\n",
    "These factors contain bias that should be addressed either by adding or removing\n",
    "data to even out the sampling. For instance, the _class_ factor highlights that\n",
    "there is unevenness in the number of data points per class.\n",
    "\n",
    "In addition to analyzing class, the diversity function also analyzes metadata\n",
    "factors with individual classes to assess uniformity of metadata factors within\n",
    "a class. As above, the plot function of the diversity output class can plot a\n",
    "heatmap of the classwise results for visualizing. The `plot_classwise` parameter\n",
    "needs to be set to True to use the classwise results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = div.plot(plot_classwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results expand the above results on a classwise basis.\n",
    "\n",
    "Things to look for here are large variances for a given factor across the\n",
    "different classes. For example, _pose_ has values ranging from 0.01 to 0.84,\n",
    "which means that a few classes have almost uniform selection of the different\n",
    "_pose_ values while other classes essentially only have one _pose_ value.\n",
    "This makes sense as the _bottle_ or _pottedplant_ class does not have multiple\n",
    "_pose_ directions, while the _person_ class does.\n",
    "\n",
    "What needs to be further investigated are things like whether the _sofa_ class\n",
    "should have a _pose_ direction, because a diversity value of 0.4 means that a\n",
    "few of the images do while others do not.\n",
    "\n",
    "Also, the _cat_ class has a low score signifying that most of the images fall\n",
    "into one or two categories rather than being spread even across the categories.\n",
    "This highlights an error in the data collection process &mdash; the value was\n",
    "not specified for most _cat_ images and therefore defaulted to \"Unspecified\".\n",
    "\n",
    "An alternative error would be a dataset in which the _cat_ images have most\n",
    "cats facing a specific direction, which would require additional data to\n",
    "overcome the bias, but that is not the case for this dataset. It has plenty of\n",
    "cats facing each direction, but only a few of them contain a _pose_ value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Assess dataset parity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The {func}`.parity` function measures the relationship between metadata factors\n",
    "and classes using a chi-squared test. A high score with a low p-value suggests\n",
    "that a metadata factor is strongly correlated with a class label.\n",
    "\n",
    "The results can be retrieved using the _score_ and _p_value_ attributes of the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = parity(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning above states that the metric works best when there are\n",
    "more than 5 samples in each value-label combination. However,\n",
    "because of the large number of total samples, the difference between\n",
    "1 and 5 samples does not significantly affect the results.\n",
    "\n",
    "When evaluating the results of parity for a large number of factors,\n",
    "it may be easier to understand the results in a DataFrame.\n",
    "\n",
    "The {class}`.ParityOutput` class contains a `to_dataframe` function to format\n",
    "the results of the diversity function as a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, all metadata are correlated with _class_ labels,\n",
    "except for _image_ and _depth_. However, `parity` is based on the idea of\n",
    "an expected frequency and how the observed differs from what is expected.\n",
    "The expected frequencies are determined by sums of the values for each\n",
    "metadata category.\n",
    "\n",
    "This function works best when the expected frequencies for a given factor\n",
    "for each individual class are known a priori. For the case above, the\n",
    "expected frequency for the _pose_ metadata category shouldn't be the same\n",
    "for all classes. The _diningtable_, _pottedplant_, and _bottle_ classes\n",
    "only have a single value for _pose_ which automatically throws off the\n",
    "metric because not all of the classes have an identical expected frequency\n",
    "for _pose_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having analyzed the dataset for bias with multiple metrics, the conclusion is that\n",
    "this dataset has bias. Training a model on this dataset has the potential to learn\n",
    "shortcuts and underperform on operational data if the biases are not representative\n",
    "of biases in the operational dataset.\n",
    "\n",
    "The metadata categories identified by the `balance`, `diversity` and `parity`\n",
    "functions contain issues such as imbalanced classes and imbalanced parameters per\n",
    "class. DataEval isn't able to tell you exactly why they are imbalanced, but it\n",
    "highlights the categories that you need to check.\n",
    "\n",
    "As you can see, the DataEval methods are here to help you gain a deep understanding\n",
    "of your dataset and all of its strengths and limitations. It is designed to help you\n",
    "create representative and reliable datasets.\n",
    "\n",
    "Good luck with your data!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "In addition to identifying bias and correlations in a dataset, DataEval offers additional tutorials to help you learn about dataset analysis:\n",
    "\n",
    "- To clean a dataset use the [Data Cleaning Guide](EDA_Part1.ipynb).\n",
    "- To identify coverage gaps and outliers use the [Assessing the Data Space Guide](EDA_Part2.ipynb).\n",
    "- To monitor data for shifts during operation use the [Data Monitoring Guide](Data_Monitoring.ipynb).\n",
    "\n",
    "To learn more about the balance, diversity and parity functions, see the [Balance](../concepts/Balance.md), [Diversity](../concepts/Diversity.md) and [Parity](../concepts/Parity.md) concept pages.\n",
    "\n",
    "## On your own\n",
    "\n",
    "Once you are familiar with DataEval and dataset analysis, you will want to run this analysis on your own dataset.\n",
    "When you do, make sure that you analyze all of your data and not just the training set.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
