{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Distribution (OOD) Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Problem Statement_\n",
    "\n",
    "For most computer vision tasks like **image classification** and **object detection**, out-of-distribution (OOD) detection can provide insight into operational drift, or training problems. A way to identify these is through autoencoding reconstruction error.\n",
    "\n",
    "To help with this, DAML has an OOD detector that allows a user to identify these images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "The `OOD_AE` class and similar should be used when you would like to find individual images in a dataset which are the most different from the others in the provided set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A training image dataset with the approximate percentage of known OOD images.\n",
    "2. A test image dataset to evaluate for OOD images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setting up_\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q daml[tensorflow]\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import os\n",
    "\n",
    "# from pytest import approx\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from daml.detectors import OOD_AE, OOD_VAEGMM\n",
    "from daml.models.tensorflow import AE, VAEGMM, create_model\n",
    "\n",
    "tf.random.set_seed(108)\n",
    "tf.keras.utils.set_random_seed(408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We will use the tensorflow mnist dataset for this tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "(images, ds_info) = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"train[:2000]\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "images = images.shuffle(images.cardinality())\n",
    "tfds.visualization.show_examples(images, ds_info)\n",
    "images = np.array([i[\"image\"] for i in images], dtype=np.float32) / 255.0\n",
    "input_shape = images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "\n",
    "Now, lets look at how to use DAML's OOD detection methods.  \n",
    "We will focus on a simple autoencoder network from our Alibi Detect provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = [\n",
    "    OOD_AE(create_model(AE, input_shape)),\n",
    "    OOD_VAEGMM(create_model(VAEGMM, input_shape)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Next we will train a model on the dataset.\n",
    "For better results, the epochs can be increased.\n",
    "We set the threshold to detect the most extreme 1% of training data as out-of-distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detector in detectors:\n",
    "    print(f\"Training {detector.__class__.__name__}...\")\n",
    "    detector.fit(images, threshold_perc=99, epochs=20, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for OOD\n",
    "\n",
    "We have trained our detector on a dataset of digits.  \n",
    "What happens when we give it corrupted images of digits (which we expect to be \"OOD\")?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_images, ds_info = tfds.load(\n",
    "    \"mnist_corrupted/translate\",\n",
    "    split=\"train[:2000]\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "corr_images = corr_images.shuffle(corr_images.cardinality())\n",
    "tfds.visualization.show_examples(corr_images, ds_info)\n",
    "corr_images = np.array([i[\"image\"] for i in corr_images], dtype=np.float32) / 255.0\n",
    "# corr_images = corr_images.ravel().reshape((corr_images.shape[0], -1))\n",
    "print(corr_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the two datasets using the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(type(detector).__name__, np.mean(detector.predict(images)[\"is_ood\"])) for detector in detectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(type(detector).__name__, np.mean(detector.predict(corr_images)[\"is_ood\"])) for detector in detectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION ###\n",
    "# print(np.mean(preds_in))\n",
    "# print(np.mean(preds_corr))\n",
    "# assert np.mean(preds_in) == approx(0.02, abs=0.02)\n",
    "# assert np.mean(preds_corr) == approx(0.8, abs=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We can see that the Autoencoder based OOD detector was able to identify most of the translated images as outliers, while the AEGMM was resilient to the perturbation.\n",
    "\n",
    "Depending on your needs, certain outlier detectors will work better under specific conditions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
