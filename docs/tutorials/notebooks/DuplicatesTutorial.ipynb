{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Deduplication Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Exploratory data analysis (EDA) can be overwhelming. There are so many things to check.\n",
    "Duplicates in your dataset, bad/corrupted images in the set, blurred or bright/dark images, the list goes on.\n",
    "\n",
    "DAML created a Duplicates class to assist you with your EDA so you can start training your models on high quality data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "The Duplicates class should be used if you need to check for duplicates in your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A dataset to analyze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Getting Started_\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q daml\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from daml.detectors import Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "Let's start by loading in TensorFlow's MNIST dataset, then we will examine it\n",
    "\n",
    "The MNIST dataset contains 70,000 images - 60,000 in the train set and 10,000 in the test set.\n",
    "For the purposes of this demonstration, we are just going to use the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "dataset, ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"test\",\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "tfds.visualization.show_examples(dataset, ds_info)  # type: ignore\n",
    "\n",
    "# Translate the dataset from tensorflow to numpy for use with the duplicates class\n",
    "labels = np.array([i[\"label\"] for i in dataset])  # type: ignore\n",
    "test_data = [i[\"image\"] for i in dataset]  # type: ignore\n",
    "test_data = np.squeeze(np.array(test_data, dtype=np.float32).transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the MNIST dataset does not contain any exact duplicates we are going to adjust the dataset to include some.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some duplicates\n",
    "print(\"Exact duplicates\")\n",
    "duplicates = {}\n",
    "for i in [1, 2, 5, 9]:\n",
    "    matching_indices = np.where(labels == i)[0]\n",
    "    test_data[matching_indices[78]] = test_data[matching_indices[23]]\n",
    "    print(f\"\\t{i} - ({matching_indices[23]}, {matching_indices[78]})\")\n",
    "    duplicates[i] = (matching_indices[23], matching_indices[78], matching_indices[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples: \", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Duplicates\n",
    "\n",
    "Now we are asking our Duplicates class to find the needle in the haystack.\n",
    "There are only 4 exact duplicates and then there are 3 shifted exact duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Duplicates class\n",
    "duplicator = Duplicates(test_data)  # type: ignore\n",
    "\n",
    "# Evaluate the data\n",
    "results = duplicator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are a dictionary with exact and near as the keys. So we will extract those to view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in results.items():\n",
    "    print(f\"{category} - {len(images)}\")\n",
    "    print(f\"\\t{images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we recall from above, our exact duplicates were:\n",
    "\n",
    "(274, 706), (210, 648), (285, 887), (193, 825)\n",
    "\n",
    "Which exactly matches what the Duplicates class was able to find.\n",
    "\n",
    "It also found several sets of images that are very closely related to each other, and since we are using hand written digits we would expect it to find some images that were nearly identical.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
