{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Sufficiency Analysis for Object Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "For machine learning tasks, often we would like to evaluate the performance of a model on a small, preliminary dataset. In situations where data collection is expensive, we would like to extrapolate hypothetical performance out to a larger dataset.\n",
    "\n",
    "DataEval has introduced a method projecting performance via _sufficiency curves_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use\n",
    "\n",
    "The `Sufficiency` class should be used when you would like to extrapolate hypothetical performance.\n",
    "For example, if you have a small dataset, and would like to know if it is worthwhile to collect more data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will need\n",
    "\n",
    "1. A particular model architecture.\n",
    "2. Metric(s) that we would like to evaluate.\n",
    "3. A dataset of interest.\n",
    "4. A python environment with the following packages installed:\n",
    "   - `dataeval[torch]` or `dataeval[all]`\n",
    "   - `val`\n",
    "   - `pytest`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example.\n",
    "Note that this tutorial will be run in the `yolov5` directory, which is a tool for object detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Google Colab Only\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    %pip install -q dataeval[torch]==v0.67.0
",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "%pip install val\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import val\n",
    "\n",
    "from dataeval.workflows import Sufficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to run this notebook, you will need to either download the [VisDrone dataset](https://github.com/VisDrone/VisDrone-Dataset) or adjust the pointer to your dataset of choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = os.listdir(\"./data/VisDrone/VisDrone2019-DET-train/full_labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloMdelWrapper:\n",
    "    def __init__(self):\n",
    "        self.trained = 0\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.trained = 0\n",
    "        return self\n",
    "\n",
    "    def apply(self, fn):\n",
    "        self.trained = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define two utility functions to subset the data in yolo so our model can train only on data which we allow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_labels():\n",
    "    folder = \"./data/VisDrone/VisDrone2019-DET-train/labels/\"\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "\n",
    "def copy_labels(names):\n",
    "    for i in names:\n",
    "        shutil.copy(\n",
    "            \"./data/VisDrone/VisDrone2019-DET-train/full_labels/\" + i,\n",
    "            \"./data/VisDrone/VisDrone2019-DET-train/labels/\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "\n",
    "Use only the first 500 images for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = trains[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this example, we will use subsets of the training and test data.\n",
    "\n",
    "Finally, we define our custom training and evaluation functions.\n",
    "Sufficiency requires that the evaluation function returns a dictionary of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train(model, dataset, indices):\n",
    "    # Defined only for this testing scenario\n",
    "    delete_labels()\n",
    "    copy_labels([dataset[i] for i in indices])\n",
    "    # ruff: noqa: E501\n",
    "    if len(indices) == 5:\n",
    "        !python train.py --data VisDrone.yaml --epochs 10 --weights '' --cfg yolov5n.yaml --img 640 --noval --exist-ok\n",
    "    else:\n",
    "        !python train.py --epochs 10 --data VisDrone.yaml --weights 'runs/train/exp/weights/last.pt' --cfg yolov5n.yaml --img 640 --noval --exist-ok\n",
    "\n",
    "\n",
    "def custom_eval(model, dataset) -> Dict[str, float]:\n",
    "    metrics = val.run(\"./data/VisDrone.yaml\", \"./runs/train/exp/weights/last.pt\")\n",
    "    print(metrics[0][2])\n",
    "    return {\"mAP\": metrics[0][2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize sufficiency metric\n",
    "\n",
    "Attach the custom training and evaluation functions to the Sufficiency metric and define the number of models to train in parallel (stability), as well as the number of steps along the learning curve to evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = YoloMdelWrapper()\n",
    "# Instantiate sufficiency metric\n",
    "suff = Sufficiency(\n",
    "    model=mymodel,\n",
    "    train_ds=trains,\n",
    "    test_ds=np.array([0]),\n",
    "    train_fn=custom_train,\n",
    "    eval_fn=custom_eval,\n",
    "    runs=1,\n",
    "    substeps=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Sufficiency\n",
    "\n",
    "Now we can evaluate the metric to train the models and produce the learning curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & test model\n",
    "output = suff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out sufficiency output in a table format\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(output.dict(), headers=list(output.dict()), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out projected output values\n",
    "projection = Sufficiency.project(output, [1000, 2000, 4000])\n",
    "print(tabulate(projection.dict(), list(projection.dict()), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output using the convenience function\n",
    "%matplotlib inline\n",
    "_ = Sufficiency.plot(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Using this learning curve, we can project performance under much larger datasets (with the same model).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
