from collections.abc import Generator
from pathlib import Path
from typing import Any, Literal

import numpy as np
import pytest
import torch
from numpy.typing import NDArray

from dataeval.data import Embeddings

NP_MAJOR_VERSION = tuple(int(x) for x in np.__version__.split("."))[0]


class SimpleDataset:
    """Simple dataset that returns random images for testing."""

    def __init__(self, size: int, image_shape: tuple[int, ...] = (3, 32, 32)):
        self.size = size
        self.image_shape = image_shape
        # Pre-generate data for consistency
        self.data = [np.random.randn(*image_shape).astype(np.float32) for _ in range(size)]

    def __len__(self):
        return self.size

    def __getitem__(self, idx):
        # Return as tuple to match expected dataset format
        return (self.data[idx], 0, {})  # (image, label, metadata)


class IdentityModel(torch.nn.Module):
    """Model that flattens input to a fixed embedding dimension."""

    def __init__(self, embedding_dim: int = 128):
        super().__init__()
        self.flatten = torch.nn.Flatten()
        self.embedding_dim = embedding_dim

    def forward(self, x):
        # Flatten and project to embedding dimension
        flat = self.flatten(x)
        # Use a simple linear projection
        if not hasattr(self, "proj"):
            input_dim = flat.shape[1]
            self.proj = torch.nn.Linear(input_dim, self.embedding_dim).to(x.device)
            # Initialize deterministically for consistent tests
            torch.nn.init.xavier_uniform_(self.proj.weight)
            torch.nn.init.zeros_(self.proj.bias)
        return self.proj(flat)


@pytest.fixture
def simple_dataset() -> SimpleDataset:
    """Create a simple dataset for testing."""
    return SimpleDataset(size=50, image_shape=(3, 32, 32))


@pytest.fixture
def memmap_embeddings(tmp_path) -> Generator[tuple[Embeddings, NDArray[Any]], None, None]:
    """Create temporary memmap-backed embeddings for testing."""
    cache_path = tmp_path / "test_embeddings.npy"
    shape = (1000, 128)
    dtype = np.float32

    # Create data and save as proper .npy file
    data = np.random.randn(*shape).astype(dtype)
    np.save(cache_path, data)

    # Load as memmap from the .npy file
    loaded_memmap = np.load(cache_path, mmap_mode="r")

    # Create embeddings-only instance from memmap
    emb = Embeddings.from_array(loaded_memmap)

    # Verify it's actually memmap backed
    assert isinstance(emb._embeddings, np.memmap), "Fixture should create memmap-backed embeddings"

    yield emb, data


@pytest.fixture
def lazy_embeddings(simple_dataset, tmp_path) -> Generator[tuple[Embeddings, SimpleDataset, Path], None, None]:
    """Create embeddings with lazy evaluation for testing compute()."""
    cache_path = tmp_path / "lazy_embeddings.npy"
    model = IdentityModel(embedding_dim=128)

    emb = Embeddings(simple_dataset, batch_size=16, model=model, device="cpu", path=cache_path, verbose=False)

    yield emb, simple_dataset, cache_path


@pytest.fixture
def in_memory_embeddings(simple_dataset) -> Generator[tuple[Embeddings, SimpleDataset], None, None]:
    """Create in-memory embeddings (no path) for testing."""
    model = IdentityModel(embedding_dim=128)

    emb = Embeddings(
        simple_dataset,
        batch_size=16,
        model=model,
        device="cpu",
        path=None,  # In-memory only
        verbose=False,
    )

    yield emb, simple_dataset


class TestMemmapPreservation:
    """Test suite for memmap preservation in Embeddings.__array__()."""

    def test_array_protocol_on_memmap(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """__array__() should return memmap directly for embeddings-only instances."""
        emb, _ = memmap_embeddings

        # Call __array__ directly
        arr = emb.__array__()

        assert isinstance(arr, np.memmap), "Expected __array__() to return memmap"

    def test_asarray_converts_memmap_to_ndarray(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """np.asarray() converts memmap to ndarray (expected numpy behavior)."""
        emb, _ = memmap_embeddings

        # np.asarray() loads memmap into memory
        arr = np.asarray(emb)

        # This is expected behavior - np.asarray doesn't preserve memmap
        assert isinstance(arr, np.ndarray), "Expected ndarray"
        assert not isinstance(arr, np.memmap), "np.asarray() should not preserve memmap"

    def test_direct_access_preserves_memmap(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Direct access to _embeddings preserves memmap."""
        emb, _ = memmap_embeddings

        # Direct access should preserve memmap
        arr = emb._embeddings

        assert isinstance(arr, np.memmap), "Direct access should preserve memmap"

    def test_getitem_on_memmap_preserves_type(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Slicing memmap-backed embeddings returns memmap views."""
        emb, _ = memmap_embeddings

        # Access underlying memmap directly via _embeddings
        sliced = emb._embeddings[0:100]

        assert isinstance(sliced, np.memmap), "Slicing memmap should return memmap view"

    def test_explicit_copy_loads_to_memory(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Explicit copy=True should load memmap into memory."""
        emb, _ = memmap_embeddings
        arr = np.array(emb, copy=True)

        assert not isinstance(arr, np.memmap), "Expected in-memory array"
        assert isinstance(arr, np.ndarray), "Expected ndarray"

    def test_dtype_conversion_loads_to_memory(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Dtype conversion should load memmap into memory."""
        emb, _ = memmap_embeddings
        arr = np.asarray(emb, dtype=np.float16)

        assert not isinstance(arr, np.memmap), "Expected in-memory array after dtype conversion"
        assert arr.dtype == np.float16, "Expected float64 dtype"

    @pytest.mark.xfail(
        NP_MAJOR_VERSION < 2,
        reason="numpy < 2 changes memmap/dtype/copy behavior; test expected to fail",
        strict=False,
    )
    def test_dtype_conversion_with_copy_false_raises(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Dtype conversion with copy=False should raise ValueError."""
        emb, _ = memmap_embeddings

        with pytest.raises(ValueError, match="Cannot avoid copy when converting dtype"):
            np.array(emb, dtype=np.float64, copy=False)

    def test_operations_work_on_memmap_directly(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Operations on underlying memmap work without loading all data."""
        emb, original_data = memmap_embeddings

        # Access underlying memmap directly
        arr = emb._embeddings

        # Compute statistics on memmap (doesn't load all into memory)
        mean_val = arr.mean()
        sum_val = arr.sum()

        # Verify against original data
        assert np.isclose(mean_val, original_data.mean()), "Mean computation incorrect"
        assert np.isclose(sum_val, original_data.sum()), "Sum computation incorrect"
        assert isinstance(arr, np.memmap), "Direct access still memmap"

    def test_memory_footprint_difference(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Memmap has minimal memory footprint vs. in-memory copy."""
        emb, original_data = memmap_embeddings

        # Get memmap reference (minimal memory)
        arr_memmap = emb._embeddings

        # Get in-memory copy via np.asarray
        arr_memory = np.asarray(emb)

        # Both should have same data size
        assert arr_memmap.nbytes == arr_memory.nbytes
        assert arr_memmap.nbytes == original_data.nbytes

        # Verify they're different types
        assert isinstance(arr_memmap, np.memmap)
        assert not isinstance(arr_memory, np.memmap)

    def test_readonly_access_preserves_memmap(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Read-only operations on underlying memmap don't change type."""
        emb, _ = memmap_embeddings
        arr = emb._embeddings  # Direct access

        # Multiple read operations
        _ = arr[0]
        _ = arr.shape
        _ = arr.dtype
        _ = arr.mean()
        _ = arr[100:200]

        # Should still be memmap after all read operations
        assert isinstance(arr, np.memmap)

    def test_data_integrity(self, memmap_embeddings: tuple[Embeddings, NDArray[Any]]):
        """Data should be identical whether memmap or in-memory."""
        emb, original_data = memmap_embeddings

        # Get both versions
        arr_memmap = emb._embeddings  # Memmap
        arr_memory = np.asarray(emb)  # Loaded into memory

        # All should be equal
        np.testing.assert_array_equal(arr_memmap, original_data)
        np.testing.assert_array_equal(arr_memory, original_data)
        np.testing.assert_array_equal(arr_memmap, arr_memory)


class TestEdgeCases:
    """Test edge cases and error conditions."""

    def test_empty_dataset(self):
        """Test handling of empty datasets."""
        empty_dataset = SimpleDataset(size=0)
        model = IdentityModel()

        emb = Embeddings(empty_dataset, batch_size=16, model=model, device="cpu", path=None, verbose=False)

        arr = np.asarray(emb)
        assert arr.shape[0] == 0
        assert isinstance(arr, np.ndarray)

    def test_single_sample(self):
        """Test with single sample dataset."""
        single_dataset = SimpleDataset(size=1)
        model = IdentityModel()

        emb = Embeddings(single_dataset, batch_size=16, model=model, device="cpu", path=None, verbose=False)

        arr = np.asarray(emb)
        assert arr.shape[0] == 1
        assert len(arr.shape) == 2  # (1, embedding_dim)


class TestComputeMethod:
    """Test suite for the compute() method."""

    def test_compute_lazy_embeddings(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """compute() should compute all embeddings and cache them."""
        emb, dataset, _ = lazy_embeddings

        # Initially no embeddings cached
        assert len(emb._cached_idx) == 0

        # Compute all embeddings
        result = emb.compute()

        # All embeddings should now be cached
        assert len(emb._cached_idx) == len(dataset)
        assert emb._embeddings.shape[0] == len(dataset)

        # Should return self for chaining
        assert result is emb

    def test_compute_returns_self(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """compute() should return self for method chaining."""
        emb, _, _ = lazy_embeddings

        result = emb.compute()
        assert result is emb

    def test_compute_no_op_on_embeddings_only(self):
        """compute() should be a no-op on embeddings-only instances."""
        # Create embeddings-only instance
        data = np.random.randn(100, 128).astype(np.float32)
        emb = Embeddings.from_array(data)

        original_data = emb._embeddings.copy()

        # Should return immediately without error
        result = emb.compute()
        assert result is emb
        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_compute_force_recomputes(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """compute(force=True) should recompute all embeddings."""
        emb, dataset, _ = lazy_embeddings

        # Compute embeddings once
        emb.compute()
        first_shape = emb._embeddings.shape

        # Force recompute
        emb.compute(force=True)

        # Should have recomputed
        assert len(emb._cached_idx) == len(dataset)
        assert emb._embeddings.shape == first_shape

    def test_compute_partial_then_complete(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """Accessing partial data then compute() should complete caching."""
        emb, dataset, _ = lazy_embeddings

        # Access first 10 embeddings
        _ = emb[0:10]
        assert len(emb._cached_idx) == 10

        # Compute remaining
        emb.compute()
        assert len(emb._cached_idx) == len(dataset)

    def test_compute_idempotent(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """compute() called multiple times should be idempotent."""
        emb, _, _ = lazy_embeddings

        # First compute
        emb.compute()
        first_embeddings = emb._embeddings.copy()
        first_cached = emb._cached_idx.copy()

        # Second compute (without force)
        emb.compute()

        # Should be unchanged
        assert emb._cached_idx == first_cached
        np.testing.assert_array_equal(emb._embeddings, first_embeddings)

    def test_compute_then_access(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """Accessing embeddings after compute() should be fast (no recompute)."""
        emb, dataset, _ = lazy_embeddings

        # Compute all
        emb.compute()
        cached_after_compute = len(emb._cached_idx)

        # Access some embeddings
        sample = emb[10:20]

        # Should not trigger additional caching
        assert len(emb._cached_idx) == cached_after_compute
        assert sample.shape[0] == 10

    def test_compute_force_clears_cache(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """compute(force=True) should clear cache before recomputing."""
        emb, _, _ = lazy_embeddings

        # Compute and verify cached
        emb.compute()
        assert len(emb._cached_idx) > 0
        original_size = emb._embeddings.size

        # Force recompute
        emb.compute(force=True)

        # Should have same final state
        assert len(emb._cached_idx) == len(emb._dataset)
        assert emb._embeddings.size == original_size


class TestArrayProtocol:
    """Test suite for __array__ protocol with lazy embeddings."""

    def test_asarray_triggers_computation(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """np.asarray() on lazy embeddings should trigger computation."""
        emb, dataset, _ = lazy_embeddings

        # Initially no embeddings cached
        assert len(emb._cached_idx) == 0

        # Call np.asarray - should trigger computation
        arr = np.asarray(emb)

        # Should have computed all embeddings
        assert len(emb._cached_idx) == len(dataset)
        assert arr.shape[0] == len(dataset)

    def test_asarray_equals_getitem_slice(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """np.asarray(emb) should equal emb[:]."""
        emb, _, _ = lazy_embeddings

        arr1 = np.asarray(emb)
        arr2 = emb[:]

        np.testing.assert_array_equal(arr1, arr2)

    def test_asarray_on_computed_embeddings(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """np.asarray() on already-computed embeddings should not recompute."""
        emb, _, _ = lazy_embeddings

        # Pre-compute
        emb.compute()
        first_arr = emb._embeddings.copy()

        # Call asarray
        arr = np.asarray(emb)

        # Should be same array (not recomputed)
        np.testing.assert_array_equal(arr, first_arr)

    def test_asarray_empty_lazy_embeddings(self):
        """np.asarray() on empty lazy embeddings should work."""
        empty_dataset = SimpleDataset(size=0)
        model = IdentityModel()

        emb = Embeddings(empty_dataset, batch_size=16, model=model, device="cpu", path=None, verbose=False)

        arr = np.asarray(emb)

        assert arr.shape[0] == 0
        assert isinstance(arr, np.ndarray)

    def test_asarray_always_computes_for_lazy(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """np.asarray() should always compute for lazy embeddings."""
        emb, dataset, _ = lazy_embeddings

        # Call asarray - should compute
        arr1 = np.asarray(emb)
        assert arr1.shape[0] == len(dataset)

        # Call again - should return cached result
        arr2 = np.asarray(emb)
        assert arr2.shape[0] == len(dataset)

        # Both calls should return valid arrays
        assert arr1.shape == arr2.shape
        np.testing.assert_array_equal(arr1, arr2)


class TestSaveMethod:
    """Test suite for the save() method."""

    def test_save_computes_and_saves(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """save() should compute embeddings before saving."""
        emb, dataset, save_path = lazy_embeddings

        # Initially not computed
        assert len(emb._cached_idx) == 0

        # Save should compute and write to disk
        emb.save(save_path)

        # Should have computed all embeddings
        assert len(emb._cached_idx) == len(dataset)

        # File should exist
        assert save_path.exists()

    def test_save_without_path_raises(self, in_memory_embeddings: tuple[Embeddings, SimpleDataset]):
        """save() without path should raise ValueError."""
        emb, _ = in_memory_embeddings

        with pytest.raises(ValueError, match="No path specified"):
            emb.save()

    def test_save_uses_configured_path(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """save() without argument should use configured path."""
        emb, dataset, configured_path = lazy_embeddings

        # Save without specifying path
        emb.save()

        # Should save to configured path
        assert configured_path.exists()

    def test_save_chain_with_compute(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path]):
        """save() should work in chain with compute()."""
        emb, _, save_path = lazy_embeddings

        # Chain compute and save
        emb.compute().save(save_path)

        # File should exist
        assert save_path.exists()

    def test_save_custom_path(self, lazy_embeddings: tuple[Embeddings, SimpleDataset, Path], tmp_path: Path):
        """save() with custom path should save to that path."""
        emb, _, _ = lazy_embeddings

        custom_path = tmp_path / "custom_output.npy"

        emb.save(custom_path)

        assert custom_path.exists()

    def test_save_in_memory_to_disk(self, in_memory_embeddings: tuple[Embeddings, SimpleDataset], tmp_path: Path):
        """In-memory embeddings can be saved to disk."""
        emb, dataset = in_memory_embeddings

        # Compute embeddings
        emb.compute()

        # Save to disk
        output_path = tmp_path / "in_memory_saved.npy"
        emb.save(output_path)

        assert output_path.exists()

        # Verify saved data
        loaded = np.load(output_path)
        assert loaded.shape[0] == len(dataset)


class TestFromArrayMethod:
    """Test suite for from_array() classmethod."""

    def test_from_array_creates_embeddings_only(self):
        """from_array() should create embeddings-only instance."""
        data = np.random.randn(100, 128).astype(np.float32)

        emb = Embeddings.from_array(data)

        # Should be embeddings-only
        assert emb._embeddings_only
        assert len(emb._cached_idx) == len(data)

    def test_from_array_preserves_data(self):
        """from_array() should preserve original data."""
        data = np.random.randn(50, 256).astype(np.float32)

        emb = Embeddings.from_array(data)

        np.testing.assert_array_equal(emb._embeddings, data)

    def test_from_array_replaces_load(self, tmp_path: Path):
        """from_array(np.load()) should replace old load() method."""
        save_path = tmp_path / "test.npy"

        # Save some data
        original_data = np.random.randn(75, 384).astype(np.float32)
        np.save(save_path, original_data)

        # Load using from_array
        loaded = np.load(save_path)
        emb = Embeddings.from_array(loaded)

        # Should match original
        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_from_array_with_memmap(self, tmp_path: Path):
        """from_array() should work with memmap arrays."""
        memmap_path = tmp_path / "memmap.npy"
        shape = (200, 128)

        # Create memmap
        data = np.random.randn(*shape).astype(np.float32)
        memmap_arr = np.memmap(memmap_path, dtype=np.float32, mode="w+", shape=shape)
        memmap_arr[:] = data
        memmap_arr.flush()

        # Create embeddings from memmap
        emb = Embeddings.from_array(memmap_arr)

        # Should preserve memmap
        assert isinstance(emb._embeddings, np.memmap)
        np.testing.assert_array_equal(emb._embeddings, data)


class TestIntegration:
    """Integration tests for complete workflows."""

    def test_full_workflow_in_memory(self, simple_dataset: SimpleDataset):
        """Test complete workflow with in-memory caching."""
        model = IdentityModel()

        # Create embeddings
        emb = Embeddings(simple_dataset, batch_size=16, model=model, device="cpu", path=None, verbose=False)

        # Access some embeddings
        sample = emb[0:10]
        assert sample.shape[0] == 10

        # Compute all
        emb.compute()
        assert len(emb._cached_idx) == len(simple_dataset)

        # Access via numpy
        arr = np.asarray(emb)
        assert arr.shape[0] == len(simple_dataset)

    def test_full_workflow_with_disk_save(self, simple_dataset: SimpleDataset, tmp_path: Path):
        """Test complete workflow with disk persistence."""
        model = IdentityModel()
        save_path = tmp_path / "embeddings.npy"

        # Create and compute embeddings
        emb = Embeddings(simple_dataset, batch_size=16, model=model, device="cpu", path=save_path, verbose=False)

        # Compute and save
        emb.compute().save()

        assert save_path.exists()

        # Load back
        loaded_arr = np.load(save_path)
        loaded_emb = Embeddings.from_array(loaded_arr)

        # Verify
        assert loaded_emb.shape[0] == len(simple_dataset)
        np.testing.assert_array_equal(loaded_emb[:], emb[:])


class TestLoadMethod:
    """Test suite for the load() classmethod."""

    def test_load_as_ndarray(self, tmp_path: Path):
        """load() without mmap_mode should load as in-memory ndarray."""
        save_path = tmp_path / "test.npy"

        # Save some data
        original_data = np.random.randn(100, 128).astype(np.float32)
        np.save(save_path, original_data)

        # Load as ndarray (default)
        emb = Embeddings.load(save_path)

        # Should be in-memory ndarray
        assert isinstance(emb._embeddings, np.ndarray)
        assert not isinstance(emb._embeddings, np.memmap)
        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_load_as_memmap(self, tmp_path: Path):
        """load() with mmap_mode should load as memmap."""
        save_path = tmp_path / "test.npy"

        # Save some data
        original_data = np.random.randn(200, 256).astype(np.float32)
        np.save(save_path, original_data)

        # Load as memmap
        emb = Embeddings.load(save_path, mmap_mode="r")

        # Should be memmap
        assert isinstance(emb._embeddings, np.memmap)
        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_load_different_mmap_modes(self, tmp_path: Path):
        """load() should support different mmap_mode values."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(50, 64).astype(np.float32)
        np.save(save_path, original_data)

        # This is a little silly
        modes: list[Literal["r", "r+", "c"]] = ["r", "r+", "c"]

        # Test different modes
        for mode in modes:
            emb = Embeddings.load(save_path, mmap_mode=mode)
            assert isinstance(emb._embeddings, np.memmap)
            np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_load_creates_embeddings_only_instance(self, tmp_path: Path):
        """load() should create embeddings-only instance."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(75, 128).astype(np.float32)
        np.save(save_path, original_data)

        emb = Embeddings.load(save_path)

        # Should be embeddings-only
        assert emb._embeddings_only
        assert len(emb._cached_idx) == len(original_data)

    def test_load_nonexistent_file_raises(self, tmp_path: Path):
        """load() with nonexistent file should raise FileNotFoundError."""
        nonexistent_path = tmp_path / "does_not_exist.npy"

        with pytest.raises(FileNotFoundError, match="File not found"):
            Embeddings.load(nonexistent_path)

    def test_load_with_string_path(self, tmp_path: Path):
        """load() should accept string paths."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(50, 128).astype(np.float32)
        np.save(save_path, original_data)

        # Load using string path
        emb = Embeddings.load(str(save_path))

        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_load_with_path_object(self, tmp_path: Path):
        """load() should accept Path objects."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(50, 128).astype(np.float32)
        np.save(save_path, original_data)

        # Load using Path object
        emb = Embeddings.load(save_path)

        np.testing.assert_array_equal(emb._embeddings, original_data)

    def test_load_preserves_dtype(self, tmp_path: Path):
        """load() should preserve the original dtype."""
        save_path = tmp_path / "test.npy"

        # Test with different dtypes
        for dtype in [np.float32, np.float64, np.float16]:
            data = np.random.randn(50, 64).astype(dtype)
            np.save(save_path, data)

            emb = Embeddings.load(save_path)
            assert emb._embeddings.dtype == dtype

    def test_load_preserves_shape(self, tmp_path: Path):
        """load() should preserve the original shape."""
        save_path = tmp_path / "test.npy"

        # Test with different shapes
        shapes = [(100, 128), (50, 256), (200, 64)]
        for shape in shapes:
            data = np.random.randn(*shape).astype(np.float32)
            np.save(save_path, data)

            emb = Embeddings.load(save_path)
            assert emb.shape == shape

    def test_load_then_access(self, tmp_path: Path):
        """Loaded embeddings should support indexing."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(100, 128).astype(np.float32)
        np.save(save_path, original_data)

        emb = Embeddings.load(save_path)

        # Test various access patterns
        assert emb[0].shape == (128,)
        assert emb[0:10].shape == (10, 128)
        assert emb[:].shape == (100, 128)

        # Verify data integrity
        np.testing.assert_array_equal(emb[0], original_data[0])
        np.testing.assert_array_equal(emb[:], original_data)

    def test_load_memmap_then_access(self, tmp_path: Path):
        """Loaded memmap embeddings should support indexing."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(100, 128).astype(np.float32)
        np.save(save_path, original_data)

        emb = Embeddings.load(save_path, mmap_mode="r")

        # Verify memmap is preserved and data is accessible
        assert isinstance(emb._embeddings, np.memmap)
        np.testing.assert_array_equal(emb[0], original_data[0])
        np.testing.assert_array_equal(emb[:], original_data)

    def test_save_then_load_roundtrip(self, simple_dataset: SimpleDataset, tmp_path: Path):
        """save() then load() should preserve embeddings."""
        model = IdentityModel()
        save_path = tmp_path / "roundtrip.npy"

        # Create, compute, and save embeddings
        original_emb = Embeddings(
            simple_dataset, batch_size=16, model=model, device="cpu", path=save_path, verbose=False
        )
        original_emb.compute().save()

        # Load back using load() method
        loaded_emb = Embeddings.load(save_path)

        # Verify data is identical
        assert loaded_emb.shape == original_emb.shape
        np.testing.assert_array_equal(loaded_emb[:], original_emb[:])

    def test_save_then_load_memmap_roundtrip(self, simple_dataset: SimpleDataset, tmp_path: Path):
        """save() then load(mmap_mode='r') should preserve embeddings as memmap."""
        model = IdentityModel()
        save_path = tmp_path / "roundtrip_memmap.npy"

        # Create, compute, and save embeddings
        original_emb = Embeddings(
            simple_dataset, batch_size=16, model=model, device="cpu", path=save_path, verbose=False
        )
        original_emb.compute().save()

        # Load back as memmap
        loaded_emb = Embeddings.load(save_path, mmap_mode="r")

        # Verify it's memmap and data is identical
        assert isinstance(loaded_emb._embeddings, np.memmap)
        assert loaded_emb.shape == original_emb.shape
        np.testing.assert_array_equal(loaded_emb[:], original_emb[:])

    def test_load_equivalent_to_from_array_with_np_load(self, tmp_path: Path):
        """load() should be equivalent to from_array(np.load())."""
        save_path = tmp_path / "test.npy"
        original_data = np.random.randn(100, 128).astype(np.float32)
        np.save(save_path, original_data)

        # Using load()
        emb1 = Embeddings.load(save_path)

        # Using from_array(np.load())
        emb2 = Embeddings.from_array(np.load(save_path))

        # Should be equivalent
        assert emb1._embeddings_only == emb2._embeddings_only
        assert emb1.shape == emb2.shape
        np.testing.assert_array_equal(emb1[:], emb2[:])


class TestShouldUseMemmap:
    """Test suite for _should_use_memmap() method with mocked system functionality."""

    def test_should_use_memmap_no_path_returns_false(self, simple_dataset: SimpleDataset):
        """_should_use_memmap should return False when path is None."""
        model = IdentityModel()

        # Create embeddings without path
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=None,  # No path
            verbose=False,
        )

        # Should return False regardless of estimated size
        embedding_shape = (128,)
        result = emb._should_use_memmap(embedding_shape)

        assert result is False

    def test_should_use_memmap_small_data_with_path(self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch):
        """_should_use_memmap should return False when estimated size is below threshold."""
        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return large available memory (10 GB)
        class MockVirtualMemory:
            available = 10 * 1024**3  # 10 GB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Create embeddings with path and default threshold (0.8)
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=False,
        )

        # Small embedding shape - should be well below threshold
        # 50 samples * 128 dims * 4 bytes = 25.6 KB << 8 GB (80% of 10 GB)
        embedding_shape = (128,)
        result = emb._should_use_memmap(embedding_shape)

        assert result is False

    def test_should_use_memmap_large_data_with_path(self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch):
        """_should_use_memmap should return True when estimated size exceeds threshold."""
        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return small available memory (100 MB)
        class MockVirtualMemory:
            available = 100 * 1024**2  # 100 MB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Create embeddings with path and default threshold (0.8)
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=False,
        )

        # Large embedding shape - should exceed threshold
        # 50 samples * 2000000 dims * 4 bytes = 400 MB > 80 MB (80% of 100 MB)
        embedding_shape = (2000000,)
        result = emb._should_use_memmap(embedding_shape)

        assert result is True

    def test_should_use_memmap_exact_threshold(self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch):
        """_should_use_memmap should handle exact threshold boundary."""
        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Available memory: 1000 bytes
        class MockVirtualMemory:
            available = 1000

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,  # Threshold at 800 bytes
            verbose=False,
        )

        # Calculate embedding shape that gives exactly 800 bytes
        # 50 samples * X dims * 4 bytes = 800 bytes
        # X = 800 / (50 * 4) = 4
        # Exactly at threshold (800 bytes): should NOT use memmap (> not >=)
        embedding_shape = (4,)
        result = emb._should_use_memmap(embedding_shape)
        assert result is False

        # Just above threshold: should use memmap
        embedding_shape_above = (5,)  # 50 * 5 * 4 = 1000 bytes > 800
        result_above = emb._should_use_memmap(embedding_shape_above)
        assert result_above is True

    def test_should_use_memmap_different_thresholds(self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch):
        """_should_use_memmap should respect different memory_threshold values."""
        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Available memory: 1 GB
        class MockVirtualMemory:
            available = 1 * 1024**3

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Embedding shape that gives ~500 MB
        # 50 samples * 2621440 dims * 4 bytes ≈ 500 MB
        embedding_shape = (2621440,)

        # Test with low threshold (0.3) - 300 MB threshold - should use memmap
        emb_low = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.3,
            verbose=False,
        )
        assert emb_low._should_use_memmap(embedding_shape) is True

        # Test with medium threshold (0.5) - 500 MB threshold - should NOT use memmap (exactly at)
        emb_med = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.5,
            verbose=False,
        )
        # Note: This may be True or False depending on exact calculation
        result_med = emb_med._should_use_memmap(embedding_shape)
        # Just verify it's a boolean - exact value depends on rounding
        assert isinstance(result_med, bool)

        # Test with high threshold (0.9) - 900 MB threshold - should NOT use memmap
        emb_high = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.9,
            verbose=False,
        )
        assert emb_high._should_use_memmap(embedding_shape) is False

    def test_should_use_memmap_verbose_logging(
        self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch, caplog
    ):
        """_should_use_memmap should log when using memmap if verbose=True."""
        import logging

        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return small available memory
        class MockVirtualMemory:
            available = 50 * 1024**2  # 50 MB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Create embeddings with verbose=True
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=True,
        )

        # Large embedding that will trigger memmap
        # 50 samples * 1000000 dims * 4 bytes = 200 MB > 40 MB (80% of 50 MB)
        embedding_shape = (1000000,)

        with caplog.at_level(logging.INFO):
            result = emb._should_use_memmap(embedding_shape)

        assert result is True

        # Check that log message was produced
        assert any("Using memory-mapped storage" in record.message for record in caplog.records)

    def test_should_use_memmap_no_logging_when_not_verbose(
        self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch, caplog
    ):
        """_should_use_memmap should not log when verbose=False."""
        import logging

        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return small available memory
        class MockVirtualMemory:
            available = 50 * 1024**2  # 50 MB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Create embeddings with verbose=False
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=False,
        )

        # Large embedding that will trigger memmap
        embedding_shape = (1000000,)

        with caplog.at_level(logging.INFO):
            result = emb._should_use_memmap(embedding_shape)

        assert result is True

        # Should NOT have any log messages
        assert not any("Using memory-mapped storage" in record.message for record in caplog.records)

    def test_should_use_memmap_no_logging_when_false(
        self, simple_dataset: SimpleDataset, tmp_path: Path, monkeypatch, caplog
    ):
        """_should_use_memmap should not log when returning False, even if verbose."""
        import logging

        model = IdentityModel()
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return large available memory
        class MockVirtualMemory:
            available = 10 * 1024**3  # 10 GB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        # Create embeddings with verbose=True
        emb = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=True,
        )

        # Small embedding that won't trigger memmap
        embedding_shape = (128,)

        with caplog.at_level(logging.INFO):
            result = emb._should_use_memmap(embedding_shape)

        assert result is False

        # Should NOT have any log messages since memmap wasn't used
        assert not any("Using memory-mapped storage" in record.message for record in caplog.records)


class TestInitializeStorage:
    """Test suite for _initialize_storage method."""

    def test_initialize_storage_creates_memmap(self, simple_dataset: SimpleDataset, tmp_path, monkeypatch):
        """Test _initialize_storage creates memmap when path is set and threshold exceeded (lines 296-299)"""
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return very small available memory to force memmap
        class MockVirtualMemory:
            available = 10 * 1024  # 10 KB - very small

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        model = IdentityModel()
        embs = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.01,  # Very low threshold (1%)
            verbose=False,
        )

        # Trigger initialization by accessing first embedding
        # This will initialize storage with memmap due to mocked memory constraints
        sample_embedding = np.random.randn(128).astype(np.float32)

        # Manually trigger initialization
        embs._initialize_storage(sample_embedding)

        # Should have created memmap
        assert isinstance(embs._embeddings, np.memmap)
        assert embs._use_memmap is True
        assert cache_path.exists()

    def test_initialize_storage_creates_in_memory_array(self, simple_dataset: SimpleDataset, tmp_path, monkeypatch):
        """Test _initialize_storage creates in-memory array when below threshold"""
        cache_path = tmp_path / "test.npy"

        # Mock psutil to return large available memory
        class MockVirtualMemory:
            available = 10 * 1024**3  # 10 GB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        model = IdentityModel()
        embs = Embeddings(
            simple_dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=False,
        )

        # Trigger initialization
        sample_embedding = np.random.randn(128).astype(np.float32)
        embs._initialize_storage(sample_embedding)

        # Should have created regular array, not memmap
        assert isinstance(embs._embeddings, np.ndarray)
        assert not isinstance(embs._embeddings, np.memmap)
        assert embs._use_memmap is False

    def test_initialize_storage_without_path(self, simple_dataset: SimpleDataset):
        """Test _initialize_storage creates in-memory array when no path is set"""
        model = IdentityModel()
        embs = Embeddings(simple_dataset, batch_size=16, model=model, device="cpu", path=None, verbose=False)

        # Trigger initialization
        sample_embedding = np.random.randn(128).astype(np.float32)
        embs._initialize_storage(sample_embedding)

        # Should have created regular array
        assert isinstance(embs._embeddings, np.ndarray)
        assert not isinstance(embs._embeddings, np.memmap)


class TestSaveMemmap:
    """Test suite for save() method with memmap."""

    def test_save_flushes_memmap(self, tmp_path, monkeypatch):
        """Test save() flushes memmap instead of using np.save (lines 486-490)"""
        cache_path = tmp_path / "test.npy"

        # Create embeddings that will use memmap
        dataset = SimpleDataset(size=50, image_shape=(3, 32, 32))

        # Mock psutil to force memmap usage
        class MockVirtualMemory:
            available = 10 * 1024  # 10 KB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        model = IdentityModel()
        embs = Embeddings(
            dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.01,  # Very low threshold
            verbose=False,
        )

        # Compute to create memmap
        embs.compute()

        # Verify it's memmap
        assert isinstance(embs._embeddings, np.memmap)

        # Mock the flush method to track if it was called
        flush_called = False
        original_flush = embs._embeddings.flush

        def mock_flush():
            nonlocal flush_called
            flush_called = True
            original_flush()

        embs._embeddings.flush = mock_flush

        # Save should flush, not call np.save
        embs.save()

        # Verify flush was called
        assert flush_called

    def test_save_verbose_logging_memmap(self, tmp_path, monkeypatch, caplog):
        """Test save() logs when flushing memmap with verbose=True (lines 489-490)"""
        import logging

        cache_path = tmp_path / "test.npy"
        dataset = SimpleDataset(size=50, image_shape=(3, 32, 32))

        # Mock psutil to force memmap usage
        class MockVirtualMemory:
            available = 10 * 1024  # 10 KB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        model = IdentityModel()
        embs = Embeddings(
            dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.01,  # Very low threshold
            verbose=True,
        )

        embs.compute()
        assert isinstance(embs._embeddings, np.memmap)

        with caplog.at_level(logging.DEBUG):
            embs.save()

        # Should log flushing message
        assert any("Flushed memmap embeddings" in record.message for record in caplog.records)

    def test_save_verbose_logging_in_memory(self, tmp_path, caplog):
        """Test save() logs when saving in-memory array with verbose=True (lines 493-495)"""
        import logging

        cache_path = tmp_path / "test.npy"
        dataset = SimpleDataset(size=10, image_shape=(3, 32, 32))

        model = IdentityModel()
        embs = Embeddings(
            dataset,
            batch_size=16,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.8,
            verbose=True,
        )

        embs.compute()
        # Should be in-memory
        assert not isinstance(embs._embeddings, np.memmap)

        with caplog.at_level(logging.DEBUG):
            embs.save()

        # Should log saving message
        assert any("Saved embeddings to" in record.message for record in caplog.records)


class TestBatchErrors:
    """Test suite for error cases in _batch method."""

    def test_batch_out_of_range_error(self, simple_dataset: SimpleDataset):
        """Test _batch raises IndexError for out of range indices (lines 567-570)"""
        model = IdentityModel()
        embs = Embeddings(simple_dataset, batch_size=16, model=model, device="cpu", verbose=False)

        # Try to access indices beyond dataset size
        out_of_range_indices = [0, 1, 100, 200]  # 100 and 200 are out of range

        with pytest.raises(IndexError, match="Indices.*are out of range for dataset of size"):
            # Consume the generator to trigger the error
            list(embs._batch(out_of_range_indices))

    def test_batch_memmap_flush(self, simple_dataset: SimpleDataset, tmp_path, monkeypatch):
        """Test _batch flushes memmap after writing (lines 582-583)"""
        cache_path = tmp_path / "test.npy"

        # Mock psutil to force memmap usage
        class MockVirtualMemory:
            available = 10 * 1024  # 10 KB

        monkeypatch.setattr("psutil.virtual_memory", lambda: MockVirtualMemory())

        model = IdentityModel()
        embs = Embeddings(
            simple_dataset,
            batch_size=5,
            model=model,
            device="cpu",
            path=cache_path,
            memory_threshold=0.01,  # Very low threshold
            verbose=False,
        )

        # Track flush calls
        flush_count = [0]  # Use list to allow modification in closure

        # Patch flush before accessing
        original_flush = None

        def track_flush():
            nonlocal original_flush
            flush_count[0] += 1
            if original_flush:
                original_flush()

        # Process first batch to create memmap
        indices = list(range(5))
        for batch_result in embs._batch(indices):
            if isinstance(embs._embeddings, np.memmap) and original_flush is None:
                original_flush = embs._embeddings.flush
                embs._embeddings.flush = track_flush
                break  # Exit after first batch

        # Now process more batches with monitoring
        indices = list(range(5, 10))
        for batch_result in embs._batch(indices):
            pass

        # Flush should have been called at least once during the second batch processing
        assert flush_count[0] > 0


class TestGetitemErrors:
    """Test suite for error cases in __getitem__ method."""

    def test_getitem_invalid_type_raises(self):
        """Test __getitem__ raises TypeError for invalid key types (lines 608-609)"""
        arr = np.random.randn(10, 128)
        embs = Embeddings.from_array(arr)

        # Invalid key type (dict is not a valid index type)
        with pytest.raises(TypeError, match="Invalid argument type"):
            embs[{"key": "value"}]  # type: ignore

    def test_getitem_sequence_invalid_element_raises(self):
        """Test __getitem__ raises TypeError for sequence with non-int elements (lines 620-621)"""
        arr = np.random.randn(10, 128)
        embs = Embeddings.from_array(arr)

        # Sequence with invalid element types
        with pytest.raises(TypeError, match="All indices in the sequence must be integers"):
            embs[[0, 1, "invalid", 3]]  # type: ignore

    def test_getitem_embeddings_only_empty_raises(self):
        """Test __getitem__ on embeddings-only with empty array raises (lines 626-627)"""
        # Create embeddings-only with empty array
        embs = Embeddings.from_array(np.empty((0,)))
        embs._cached_idx = set()  # Clear cached indices

        with pytest.raises(ValueError, match="Embeddings not initialized"):
            embs[0]

    def test_getitem_embeddings_only_out_of_cache_raises(self):
        """Test __getitem__ on embeddings-only accessing uncached index raises (lines 628-629)"""
        arr = np.random.randn(5, 128)
        embs = Embeddings.from_array(arr)

        # Manually remove some indices from cache to simulate partial cache
        embs._cached_idx = {0, 1, 2}  # Only first 3 are "cached"

        with pytest.raises(ValueError, match="Unable to generate new embeddings from a shallow instance"):
            # Try to access index 4 which is not in cached_idx
            embs[4]
