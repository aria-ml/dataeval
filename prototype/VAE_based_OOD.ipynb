{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from metadata_utils import InstanceMNIST\n",
    "from metadata_utils import collate_fn_2 as collate_fn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataeval.utils.data.datasets import MNIST, ShipDataset\n",
    "from dataeval.utils._array import as_numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from vae_models import VAEcf, vae_loss, ConvVAE\n",
    "from vae_models import normdot\n",
    "\n",
    "from ood_detector import OODdetector\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from ood_detector import prepare_naruto\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_list = [\n",
    "    \"identity\",\n",
    "    \"translate\",\n",
    "    \"shot_noise\",\n",
    "    \"motion_blur\",\n",
    "    \"scale\",\n",
    "    \"shear\",\n",
    "    \"rotate\",\n",
    "]\n",
    "\n",
    "mnist = InstanceMNIST(corruption_list, download=True, size=8000)\n",
    "mnist_val = InstanceMNIST(\"identity\", train=False, size=8000)\n",
    "mnist_all = InstanceMNIST(\"identity\", size=60000)\n",
    "\n",
    "\n",
    "refdata = mnist.identity\n",
    "valdata = mnist_val.identity\n",
    "shiftdata = mnist.translate\n",
    "spikydata = mnist.shot_noise\n",
    "blurdata = mnist.motion_blur\n",
    "scaledata = mnist.scale\n",
    "sheardata = mnist.shear\n",
    "rotatedata = mnist.rotate\n",
    "\n",
    "alltrain = mnist_all.identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training mnist dataset and use the first 2000\n",
    "train_ds = MNIST(\n",
    "    root=\"./data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    size=2000,\n",
    "    unit_interval=True,\n",
    "    channels=\"channels_first\",\n",
    ")\n",
    "val_ds = MNIST(\n",
    "    root=\"./data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    size=2000,\n",
    "    unit_interval=True,\n",
    "    channels=\"channels_first\",\n",
    ")\n",
    "\n",
    "# Split out the images and labels\n",
    "images, labels = train_ds._data, train_ds._targets\n",
    "val_images, val_labels = val_ds._data, val_ds._targets\n",
    "\n",
    "input_shape = images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metadata_tools import ks_compare\n",
    "\n",
    "big_batch_size = 2000\n",
    "collate_fn = collate_fn\n",
    "\n",
    "refbb = DataLoader(refdata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "\n",
    "valbb = DataLoader(valdata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr1bb = DataLoader(shiftdata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr2bb = DataLoader(spikydata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr3bb = DataLoader(blurdata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr4bb = DataLoader(scaledata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr5bb = DataLoader(sheardata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "corr6bb = DataLoader(rotatedata, collate_fn=collate_fn, batch_size=big_batch_size)\n",
    "\n",
    "trainload = DataLoader(alltrain, collate_fn=collate_fn, batch_size=60000)\n",
    "\n",
    "grab = lambda ds : next(iter(ds))[0]\n",
    "\n",
    "xtrain = grab(refbb)\n",
    "xval = grab(valbb)\n",
    "xcorr = grab(corr1bb)\n",
    "alltrain = grab(trainload)\n",
    "\n",
    "xnoise = torch.rand_like(xcorr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick = np.random.randint(0, 2000)\n",
    "plt.imshow(\n",
    "    torch.concatenate(\n",
    "        (xtrain[pick, 0, :, :], xcorr[pick, 0, :, :], xnoise[pick, 0, :, :]), 1\n",
    "    )\n",
    ")\n",
    "plt.title(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.show(xcorr)\n",
    "from vae_models import VAE\n",
    "\n",
    "olddet = OODdetector(VAE(latent_dim=20), xtrain, xval)\n",
    "\n",
    "olddet.load_VAE()\n",
    "\n",
    "methods = [\n",
    "    olddet.manifold_distance,\n",
    "    olddet.manifold_distance_full_svd,\n",
    "    olddet.manifold_distance_normalized,\n",
    "    olddet.manifold_distance_weighted,\n",
    "]\n",
    "for method in methods:\n",
    "    olddet.show_dists(xcorr, method=method)\n",
    "    plt.title(plt.gca().get_title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddet.show_interpolated_images(xcorr[0], use_self=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddet.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnmodel = ConvVAE(nx=28, ny=28, latent_dim=20, img_channels=1).cuda()\n",
    "mndet = OODdetector(mnmodel, refbb, valbb, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndet.train2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = grab(valbb)[0:10]\n",
    "\n",
    "mndet.show_interpolated_images(test_image, use_self=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm=False\n",
    "# plt.ecdf(psc:=olddet.p_xy(xcorr, normalize=norm))\n",
    "# plt.ecdf(psv:=olddet.p_xy(xval, normalize=norm))\n",
    "# xall, yall = plt.xlim(), plt.ylim()\n",
    "\n",
    "# sens=0.9\n",
    "# alpha = 0.02\n",
    "# plt.plot(xall, [sens, sens])\n",
    "# xpick = np.interp(sens,  np.linspace(0,1,len(xval)), np.sort(psc))\n",
    "# plt.plot([xpick, xpick], yall)\n",
    "# plt.title(f'val: {np.mean(psv < alpha):.2f}, test: {np.mean(psc < alpha):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm= True\n",
    "# plt.ecdf(psv:=olddet.one_nn_ecdf(xval, normalized=norm))\n",
    "# plt.ecdf(psc:=olddet.one_nn_ecdf(xcorr, normalized=norm))\n",
    "# xall, yall = plt.xlim(), plt.ylim()\n",
    "\n",
    "# sens=0.9\n",
    "# alpha = 0.1\n",
    "# plt.plot(xall, [sens, sens])\n",
    "# xpick = np.interp(sens,  np.linspace(0,1,len(xval)), np.sort(psc))\n",
    "# plt.plot([xpick, xpick], yall)\n",
    "# plt.title(f'val: {np.mean(psv < alpha):.2f}, test: {np.mean(psc < alpha):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm=False\n",
    "# plt.ecdf(psv:=newdet.one_nn_ecdf(xval, normalized=norm))\n",
    "# plt.ecdf(psc:=newdet.one_nn_ecdf(xcorr, normalized=norm))\n",
    "# xall, yall = plt.xlim(), plt.ylim()\n",
    "\n",
    "# sens=0.9\n",
    "# alpha = 0.1\n",
    "# plt.plot(xall, [sens, sens])\n",
    "# xpick = np.interp(sens,  np.linspace(0,1,len(xval)), np.sort(psc))\n",
    "# plt.plot([xpick, xpick], yall)\n",
    "# plt.title(f'val: {np.mean(psv < alpha):.2f}, test: {np.mean(psc < alpha):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=4\n",
    "# sens = 0.9\n",
    "# alpha = 0.01\n",
    "# plt.ecdf(psv:=olddet.p_xy(xval,k=k))\n",
    "# plt.ecdf(psc:=olddet.p_xy(xcorr, k=k))\n",
    "# xall, yall = plt.xlim(), plt.ylim()\n",
    "# plt.plot(xall, [sens, sens])\n",
    "# xpick = np.interp(sens,  np.linspace(0,1,2000), np.sort(psc))\n",
    "# plt.plot([xpick, xpick], yall)\n",
    "# plt.title(f'val: {np.mean(psv < alpha):.2f}, test: {np.mean(psc < alpha):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet = OODdetector(VAE(latent_dim=50), xtrain, xval)\n",
    "# newdet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulldet = OODdetector(VAE(latent_dim=20), training_data=alltrain, validation_data=xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulldet.train(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulldet.show_interpolated_images(xtrain[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = [fulldet.manifold_distance, fulldet.manifold_distance_full_svd, fulldet.manifold_distance_normalized, fulldet.manifold_distance_weighted]\n",
    "# for method in methods:\n",
    "#     fulldet.show_dists(xcorr, method=method)\n",
    "#     plt.title(plt.gca().get_title())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def test_ood(detector, FPfrac=None):\n",
    "    # Here are my null hypothesis tests for OOD\n",
    "    keys1 = [\"spread\", \"xy\", \"ID\", \"1NN\", \"normdist\"]\n",
    "    meth1 = [\n",
    "        detector.p_spread,\n",
    "        detector.p_xy,\n",
    "        detector.p_ID,\n",
    "        detector.one_nn_distance_pval,\n",
    "        detector.p_dist_normalized,\n",
    "    ]\n",
    "    val1results = [meth(detector.test_example) for meth in meth1]\n",
    "    val1dict = dict(zip(keys1, val1results))\n",
    "\n",
    "    FPfrac = 0.1 if FPfrac is None else FPfrac\n",
    "\n",
    "    corrnames = [\"shift\", \"spiky\", \"blur\", \"scale\", \"shear\", \"rotate\"]\n",
    "    corrlist = [corr1bb, corr2bb, corr3bb, corr4bb, corr5bb, corr6bb]\n",
    "\n",
    "    for icorr, corrloader in enumerate(corrlist):\n",
    "        for xcorr, _, _ in corrloader:\n",
    "            break\n",
    "        print(f\"==============={corrnames[icorr]}=========================\")\n",
    "        corr1results = [meth(xcorr) for meth in meth1]\n",
    "        corr1dict = dict(zip(keys1, corr1results))\n",
    "        rlist = []\n",
    "        for ncombo in range(1, len(keys1)):\n",
    "            klist = [k for k in combinations(keys1, ncombo)]\n",
    "            vlist = [v for v in combinations(val1results, ncombo)]\n",
    "            results = dict({})\n",
    "            for kc, vc in zip(klist, vlist):\n",
    "                pv, pc = np.ones(len(xval)), np.ones(len(xcorr))\n",
    "                rkey = \"\"\n",
    "                for k, v in zip(kc, vc):\n",
    "                    rkey = rkey + \" \" + k\n",
    "                    pv *= val1dict[k]\n",
    "                    pc *= corr1dict[k]\n",
    "                cutoff = np.interp(FPfrac, np.linspace(0, 1, len(pv)), np.sort(pv))\n",
    "                tp05 = np.interp(cutoff, np.sort(pc), np.linspace(0, 1, len(pc)))\n",
    "                results.update({rkey: tp05})\n",
    "            rlist.append(results)\n",
    "\n",
    "        for i, d in enumerate(rlist):\n",
    "            print(f\"combination of {i+1} tests:\")\n",
    "            for k, v in d.items():\n",
    "                print(f\"{k}: {v:.2f}\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood(mndet, FPfrac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ood(fulldet, FPfrac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allnoise = torch.rand(size=alltrain.shape)\n",
    "# valnoise = torch.rand(size=xval.shape)\n",
    "# noisedet = OODdetector(VAE(latent_dim=20), training_data=allnoise, validation_data=valnoise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 32605902. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisedet.train(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisedet.show_interpolated_images(xval[np.random.randint(0, 1000, 10)], use_self=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv = fulldet.p_dist_normalized(xval) *fulldet.p_xy(xval) # *olddet.p_ID(xval) #*olddet.p_xy(xval) #* olddet.p_xy(xval, k=k)* olddet.one_nn_ecdf(xval, normalized=True)\n",
    "# pc = fulldet.p_dist_normalized(xcorr)* fulldet.p_xy(xcorr)# *olddet.p_ID(xcorr) #*olddet.p_ID(xcorr)#* olddet.p_xy(xcorr, k=k)* olddet.one_nn_ecdf(xcorr, normalized=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k=5\n",
    "# vline = plt.ecdf(pv)\n",
    "# cline = plt.ecdf(pc)\n",
    "# plt.legend([vline, cline], ['val', 'corr'])\n",
    "# maxdiff, alpha = fulldet.cdf_max_diff(pc, pv)\n",
    "# plt.title(f'val: {np.mean(pv < alpha):.2f}, test: {np.mean(pc < alpha):.2f}');\n",
    "# yall = plt.ylim()\n",
    "# plt.plot([alpha, alpha], yall)\n",
    "# print(maxdiff)\n",
    "\n",
    "# FPfrac = 0.01\n",
    "# cutoff = np.interp(FPfrac, np.linspace(0, 1, len(pv)), np.sort(pv) )\n",
    "# tp05 = np.interp(cutoff, np.sort(pc), np.linspace(0, 1, len(pc)))\n",
    "# print(f'TP@FP01: {tp05:.2f}')\n",
    "# # plt.xlim([0,2*alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0 = np.expand_dims(olddet.p_spread(xcorr), 1)\n",
    "# p1 = np.expand_dims(olddet.p_xy(xcorr), 1)\n",
    "# p2 = np.expand_dims(olddet.p_ID(xcorr), 1)\n",
    "# p3 = np.expand_dims(olddet.one_nn_ecdf(xcorr), 1)\n",
    "# p4 = np.expand_dims(olddet.p_dist_normalized(xcorr), 1)\n",
    "\n",
    "# pmat = np.concatenate((p0, p1, p2, p3, p4), axis=1)\n",
    "# pmat0 = np.mean(pmat, axis=0, keepdims=True)\n",
    "# pmat -= pmat0\n",
    "# pmat.shape\n",
    "# cov = pmat.T @ pmat/(len(pmat)-1)\n",
    "\n",
    "# std_vec = np.sqrt(np.diag(cov))\n",
    "\n",
    "# std_inv = np.diag(1 / std_vec)\n",
    "# corr_matrix = std_inv @ cov @ std_inv\n",
    "\n",
    "# corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvalsv = olddet.one_nn_distance_pval(xval)\n",
    "# pvalsc = olddet.one_nn_distance_pval(xcorr)\n",
    "# plt.hist((np.log10(pvalsv), np.log10(pvalsc)), 100, density=True, cumulative= True );\n",
    "# alpha = 0.0005\n",
    "# print(np.mean(pvalsv < alpha), np.mean(pvalsc < alpha))\n",
    "# print(olddet.cdf_max_diff(pvalsv, pvalsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 20\n",
    "# plt.hist((olddet.p_ID(xval, k=k), olddet.p_ID(xcorr, k=k)), 50, cumulative=True, density=True);\n",
    "# alpha = 0.01\n",
    "# (np.mean(olddet.p_ID(xval, k=k)<alpha), np.mean(olddet.p_ID(xcorr, k=k) < alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(2, 20):\n",
    "#     plt.ecdf(np.log10(olddet.p_ID(xval, k=k)))\n",
    "#     plt.ecdf(np.log10(olddet.p_ID(xcorr, k=k)))\n",
    "#     plt.title(str(k))\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muv, logvarv = olddet.model.encode(xval[0].view((1,-1)))\n",
    "# stdv = torch.exp(0.5 * logvarv)\n",
    "# mun, logvarn = olddet.model.encode(naruto[0].view((1,-1)))\n",
    "# stdn = torch.exp(0.5 * logvarn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(stdv.flatten().detach())\n",
    "# plt.plot(stdn.flatten().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.set_learning_rate(1e-6)\n",
    "# newdet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# olddet.show_rk(xcorr, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# olddet.show_interpolated_images(xcorr[230:234])\n",
    "# # newdet.show_interpolated_images(xcorr[230:231], use_self=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in newdet.optimizer.param_groups:\n",
    "#         print(g['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rktrain = newdet.ood_knn(xtrain)\n",
    "# rkval = newdet.ood_knn(xval)\n",
    "# rkcorr = newdet.ood_knn(xcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdet.set_learning_rate(1e-5)\n",
    "newdet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.load_normalized_knn_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K=9\n",
    "# plt.hist((rktrain[:,K], rkval[:,K], rkcorr[:,K]), 50, cumulative=True, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K=8\n",
    "# plt.hist((rktrain[:,K], rkval[:,K], rkcorr[:,K]), 50, cumulative=True, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naruto = plt.imread('naruto_mnist.png')\n",
    "plt.imshow(naruto)\n",
    "plt.show()\n",
    "naruto = torch.tensor(naruto.reshape((1, 1, 28, 28)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulldet.show_interpolated_images(naruto, use_self=True)\n",
    "# fulldet.show_interpolated_images(naruto) # calls plt.show() which clears previous imshow\n",
    "# rkn = newdet.ood_knn(naruto)\n",
    "# print(rkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.show_interpolated_images(naruto, use_self=True)\n",
    "# newdet.show_interpolated_images(naruto) # calls plt.show() which clears previous imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.p_ID(naruto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(newdet.detect_OOD(xcorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rkv[0])\n",
    "# plt.plot(rkn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rkv = newdet.ood_knn(xval[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rkv.squeeze(), rkn.squeeze())\n",
    "# xall = plt.xlim()\n",
    "# plt.plot(xall, xall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # END OF MNIST -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisedet1 = OODdetector(VAE(latent_dim=50), torch.concatenate((xtrain, xnoise)), xval)\n",
    "# noisedet1.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # START CIFAR -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=1000, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=200, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "for Xcf_train, _ in trainloader:\n",
    "    # Xcf_train = (Xcf_train - Xcf_train.min())/(Xcf_train.max() - Xcf_train.min())\n",
    "    Xcf_train = Xcf_train.to(device)\n",
    "    break\n",
    "\n",
    "for Xcf_test, _ in testloader:\n",
    "    # Xcf_test = (Xcf_test - Xcf_test.min())/(Xcf_test.max() - Xcf_test.min())\n",
    "    Xcf_test = Xcf_test.to(device)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(Xcf_train.permute((0, 2, 3, 1)).cpu())\n",
    "\n",
    "print(X.shape)\n",
    "plt.imshow(X[333, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfmodel = VAEcf(latent_dim=8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae_models import recon_loss_cf, reg_loss_sphere\n",
    "\n",
    "cfdet = OODdetector(\n",
    "    cfmodel, Xcf_train, Xcf_test, criterion=(recon_loss_cf, reg_loss_sphere), beta=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfdet.beta = 0.1\n",
    "cfdet.set_learning_rate(1e-5)\n",
    "cfdet.train(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfmodel.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(cfdet, 'first_hsphere_LD8.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "62051\n",
    "60994\n",
    "59995\n",
    "59206\n",
    "58566\n",
    "\n",
    "39609\n",
    "37746\n",
    "36433\n",
    "33719\n",
    "32037\n",
    "31105\n",
    "30370\n",
    "29946\n",
    "29564\n",
    "29282\n",
    "29116\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = cfdet.model(Xcf_train)\n",
    "print(type(recon[0]), recon[0].device)\n",
    "out = recon[0].permute((0, 2, 3, 1)).detach().cpu()\n",
    "orig = Xcf_train.permute((0, 2, 3, 1)).detach().cpu()\n",
    "\n",
    "outscale = (out - out.min()) / (out.max() - out.min())\n",
    "out = torch.abs(out)\n",
    "pick = 545  # np.random.randint(0, len(orig))\n",
    "# pick =  np.random.randint(0, len(orig))\n",
    "plt.imshow(np.concatenate((orig[pick], out[pick]), axis=1))\n",
    "plt.title(pick)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(orig[pick].flatten(), out[pick].flatten(), \".\")\n",
    "plt.gca().set_aspect(1.0)\n",
    "xall = plt.xlim()\n",
    "plt.plot(xall, xall, \"k:\")\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"recon\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(orig[pick].flatten(), out[pick].flatten(), 50)\n",
    "plt.gca().set_aspect(1.0)\n",
    "plt.plot(xall, xall, \"w:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(orig.flatten(), out.flatten(), 30)\n",
    "plt.gca().set_aspect(1.0)\n",
    "xall = plt.xlim()\n",
    "plt.plot(xall, xall, \"w:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = np.random.randint(len(Xcf_test))\n",
    "cfdet.show_interpolated_images(Xcf_test[i0 : i0 + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig[pick].shape)\n",
    "plt.ecdf(orig[pick].flatten())\n",
    "plt.ecdf(out[pick].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae_models import ConvVAE\n",
    "\n",
    "optmodel = ConvVAE(nx=32, ny=32, latent_dim=200).cuda()\n",
    "optdet = OODdetector(optmodel, trainset, testset, batch_size=1000)#  criterion=optmodel.loss_function)\n",
    "# optdet.load_VAE(\"cfVAE20250225_35e.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = optdet.prepare_naruto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nr.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.training_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.set_learning_rate(1e-3)\n",
    "optdet.train2(num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood(optdet, FPfrac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ID = optdet.p_ID(Xcf_test)\n",
    "p_naruto = optdet.p_ID(optdet.prepare_naruto())\n",
    "plt.ecdf(p_ID)\n",
    "yall = plt.ylim()\n",
    "plt.plot([p_naruto, p_naruto], yall)\n",
    "plt.title(p_naruto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ecdf(optdet.one_nn_ecdf(Xcf_test))\n",
    "print(optdet.one_nn_ecdf(prepare_naruto((32,32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_dists(optdet.prepare_naruto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.prepare_naruto().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(optdet.prepare_naruto().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_rk(Xcf_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_dists(Xcf_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ecdf(p_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2use = Xcf_test\n",
    "recon = optdet.model(data2use)\n",
    "print(type(recon[0]), recon[0].device)\n",
    "out = recon[0].permute((0, 2, 3, 1)).detach().cpu()\n",
    "orig = data2use.permute((0, 2, 3, 1)).detach().cpu()\n",
    "\n",
    "outscale = (out - out.min()) / (out.max() - out.min())\n",
    "out = torch.abs(out)\n",
    "pick = np.random.randint(0, len(orig))\n",
    "# pick =  np.random.randint(0, len(orig))\n",
    "plt.imshow(np.concatenate((orig[pick], out[pick]), axis=1))\n",
    "plt.title(pick)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(orig[pick].flatten(), out[pick].flatten(), \".\")\n",
    "plt.gca().set_aspect(1.0)\n",
    "xall = plt.xlim()\n",
    "plt.plot(xall, xall, \"k:\")\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"recon\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(orig[pick].flatten(), out[pick].flatten(), 20)\n",
    "plt.gca().set_aspect(1.0)\n",
    "plt.plot(xall, xall, \"w:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_interpolated_images(Xcf_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.detect_OOD(Xcf_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_dists(Xcf_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nar = optdet.prepare_naruto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.manifold_distance(Xcf_test[33:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_dists(Xcf_test[33:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_interpolated_images(Xcf_train[pick : pick + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First cell is minimal example showing duplicate images bug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataeval.utils.data.datasets import ShipDataset\n",
    "\n",
    "# train_ship = ShipDataset(root=\"./data/\", download=True, size=1800, unit_interval=True, channels=\"channels_first\")\n",
    "# test_ship = ShipDataset(root=\"./data/\", download=True, size=200, slice_back=True, unit_interval=True, channels=\"channels_first\")\n",
    "\n",
    "# workaround from Ryan 7_Mar-2025\n",
    "train_ship = ShipDataset(root=\"./data/\", download=True, size=1800, unit_interval=True, channels=\"channels_first\")\n",
    "test_ship = ShipDataset(root=\"./data/\", download=True, size=2000, slice_back=True, unit_interval=True, channels=\"channels_first\", balance=True)\n",
    "test_ship._data = test_ship._data[-200:]\n",
    "test_ship._targets = test_ship._targets[-200:]\n",
    "\n",
    "trainbatch = next(iter(torch.utils.data.DataLoader(train_ship, batch_size=100)))[0]\n",
    "testbatch = next(iter(torch.utils.data.DataLoader(test_ship, batch_size=100)))[0]\n",
    "print(f'All odd-indexed image pairs in train and test are two copies of same image: {np.array([(trainbatch[2*i+1]==testbatch[2*i+1]).all() for i in range(50)]).all()}')\n",
    "print(f'Some odd-indexed image pairs in train and test are two copies of same image: {np.array([(trainbatch[2*i+1]==testbatch[2*i+1]).all() for i in range(50)]).any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipmodel = ConvVAE(nx=80, ny=80, latent_dim=50).cuda()\n",
    "shipdet = OODdetector(shipmodel, train_ship, test_ship, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdet.set_learning_rate(1e-3)\n",
    "shipdet.train2(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdet.manifold_distance(shipdet.prepare_naruto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdet.show_dists(shipdet.prepare_naruto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdet.show_dists(shipdet.training_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2use = torch.as_tensor(next(iter(shipdet.test_loader))[0]).to(torch.float).to(shipdet.device)\n",
    "recon = shipdet.model(data2use)\n",
    "print(type(recon[0]), recon[0].device)\n",
    "out = recon[0].permute((0, 2, 3, 1)).detach().cpu()\n",
    "orig = data2use.permute((0, 2, 3, 1)).detach().cpu()\n",
    "\n",
    "outscale = (out - out.min()) / (out.max() - out.min())\n",
    "out = torch.abs(out)\n",
    "pick = np.random.randint(0, len(orig))\n",
    "# pick =  np.random.randint(0, len(orig))\n",
    "plt.imshow(np.concatenate((orig[pick], out[pick]), axis=1))\n",
    "plt.title(pick)\n",
    "plt.show()\n",
    "\n",
    "plt.hist2d(orig[pick].flatten(), out[pick].flatten(), 20)\n",
    "plt.gca().set_aspect(1.0)\n",
    "xall = plt.xlim()\n",
    "plt.plot(xall, xall, \"w:\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(orig[pick].flatten(), out[pick].flatten(), \".\")\n",
    "plt.gca().set_aspect(1.0)\n",
    "plt.plot(xall, xall, \"k:\")\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"recon\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdet.show_interpolated_images(prepare_naruto((80, 80)), use_self=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.show_interpolated_images(prepare_naruto((32, 32)), use_self=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optdet.detect_OOD(prepare_naruto((32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood_detector import prepare_naruto\n",
    "shipdet.detect_OOD(prepare_naruto((80,80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(optdet.detect_OOD(optdet.training_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick = 545  # np.random.randint(0, len(orig))\n",
    "plt.imshow(np.concatenate((orig[pick], out[pick]), axis=1))\n",
    "plt.title(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfdet.show_interpolated_images(Xcf_train[pick : pick + 1], use_self=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = cfdet.manifold_distance(Xcf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = plt.ecdf(cfdet.manifold_distance(Xcf_test))\n",
    "rand = plt.ecdf(cfdet.manifold_distance(torch.randn_like(Xcf_test) + Xcf_test))\n",
    "plt.legend([test, rand], [\"test\", \"rando\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy = torch.randn_like(Xcf_test) * 0.1 + Xcf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(noisy[0].cpu().permute((1, 2, 0)))\n",
    "plt.title(str(cfdet.manifold_distance(noisy[0:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ov = OutlierVAE(Xcf_train[0:5], latent_dim=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet = OODdetector(ov, Xcf_train, Xcf_test, criterion=vae_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet.train(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet.set_learning_rate(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet.train(epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 8\n",
    "# X = Xcf_train[idx].reshape(1, 32, 32, 3)\n",
    "# X = torch.permute(X, (0,3,1,2))\n",
    "# X_recon, mu, logvar = cfdet.model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_recon.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.permute(X_recon*3.7, (0,2,3,1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(torch.permute(X_recon, (0,2,3,1)).detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfdet.show_dists(Xcf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xcf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet.show_interpolated_images(Xcf_test[0:1]*3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ov.embed(Xcf_train).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = ov.embed(Xcf_train)\n",
    "\n",
    "# # intrinsic_dimension(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ov(Xcf_train)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Probably should handle convtranspose2d artifacts....forget how atm -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon = ov(Xcf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = recon[0][11,:,:, :]\n",
    "# img = torch.permute(img, (1,2,0)).detach().numpy()\n",
    "# plt.imshow(img)\n",
    "# print(recon[0].min(), recon[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.random.uniform(0, 100, size=10000)\n",
    "# (np.floor(x) + 1.0 == np.ceil(x)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xcf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Xtrain, _, _ in valbb:\n",
    "    break\n",
    "\n",
    "try:\n",
    "    assert torch.sum(np.abs(Xtrain - xtrain)) > 0.0\n",
    "except AssertionError:\n",
    "    print(\"x and xval are the same, what happened?\")\n",
    "\n",
    "xval_pred, _, _ = model(xval)  # type: ignore\n",
    "recon = normdot(xval, xval_pred)  # type: ignore\n",
    "\n",
    "for xcorr, _, _ in corr1bb:\n",
    "    break\n",
    "xcorr_pred, _, _ = model(xcorr)  # type: ignore\n",
    "corr_recon = normdot(xcorr_pred, xcorr)  # type: ignore\n",
    "\n",
    "plt.hist((recon, corr_recon), 40, density=True, cumulative=True)\n",
    "plt.legend([\"control\", \"OOD\"])\n",
    "plt.plot(plt.xlim(), [0.9, 0.9], plt.xlim(), [0.01, 0.01])\n",
    "plt.title(\"VAE reconstruction error - normdot\")\n",
    "\n",
    "cutoff = 0.6\n",
    "\n",
    "for i in range(10):\n",
    "    is_ood_test = corr_recon < cutoff\n",
    "    is_ood_ctrl = recon < cutoff\n",
    "    print(\n",
    "        f\"cutoff: {cutoff:0.2f}, TP: {np.mean(is_ood_test): 0.3f}, FP: {np.mean(is_ood_ctrl):.3f}\"\n",
    "    )\n",
    "    cutoff += 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xval, _, _ in valbb:\n",
    "    break\n",
    "\n",
    "try:\n",
    "    assert torch.sum(np.abs(xval - xtrain)) > 0.0\n",
    "except AssertionError:\n",
    "    print(\"x and xval are the same, what happened?\")\n",
    "\n",
    "xval_pred, _, _ = model(xval)  # type: ignore\n",
    "recon = normdot(xval, xval_pred)  # type: ignore\n",
    "\n",
    "\n",
    "def detect_OOD(xcheck, xctrl, model):\n",
    "    xctrl_pred, _, _ = model(xctrl)  # type: ignore\n",
    "    recon = normdot(xctrl, xctrl_pred)  # type: ignore\n",
    "\n",
    "    xcheck_pred, _, _ = model(xcheck)  # type: ignore\n",
    "    check_recon = normdot(xcheck_pred, xcheck)  # type: ignore\n",
    "\n",
    "    min_nd = np.percentile(recon, 1)\n",
    "    is_ood = check_recon < min_nd\n",
    "\n",
    "    return is_ood\n",
    "\n",
    "    plt.hist((recon, check_recon), 40, density=True, cumulative=True)\n",
    "    plt.legend([\"control\", \"OOD\"])\n",
    "    plt.plot(plt.xlim(), [0.9, 0.9], plt.xlim(), [0.01, 0.01])\n",
    "    plt.title(\"VAE reconstruction error - normdot\")\n",
    "\n",
    "\n",
    "cutoff = 0.6\n",
    "\n",
    "for i in range(10):\n",
    "    is_ood_test = corr_recon < cutoff\n",
    "    is_ood_ctrl = recon < cutoff\n",
    "    print(\n",
    "        f\"cutoff: {cutoff:0.2f}, TP: {np.mean(is_ood_test): 0.3f}, FP: {np.mean(is_ood_ctrl):.3f}\"\n",
    "    )\n",
    "    cutoff += 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "np.mean(detect_OOD(xcorr, xval, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(detect_OOD(xval, xval, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_loss(xtrain, *model(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ov = OutlierVAE(xval, image_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfdet = OutlierVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.show_dists(xcorr, method=newdet.manifold_distance_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moddet = OODdetector(VAEmod(784, 400, 20), xtrain, xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moddet.manifold_distance(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moddet.manifold_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moddet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.model.embed(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.manifold_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_zeros = newdet.manifold_distance(newdet.training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(all_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.show_dists(newdet.training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # newdet.load_knn_model(8)\n",
    "# newdet.show_dists(xcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon = newdet.model(xcorr[0])[0].detach().numpy().reshape((28,28))\n",
    "# plt.imshow(np.concatenate((recon, xcorr[0].squeeze()), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcorr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mdim = 10\n",
    "# # data4knn = newdet.model.embed(newdet.validation_data).detach().reshape((newdet.validation_data.shape[0], -1))\n",
    "# # newdet.neighbors = NearestNeighbors(n_neighbors=mdim, algorithm='ball_tree').fit(data4knn)\n",
    "\n",
    "# dtrain = newdet.manifold_distance(xtrain)\n",
    "# dcorr = newdet.manifold_distance(xcorr)\n",
    "# dval = newdet.manifold_distance(xval)\n",
    "\n",
    "# plt.hist((dtrain, dval,  dcorr), 50, density=True, cumulative=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dval ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdet.manifold_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ROC_curve(xref, xcorr):\n",
    "#     xref, cref = ecdf(xref)\n",
    "#     xcorr, ccorr = ecdf(xcorr)\n",
    "\n",
    "#     x_all = np.sort(np.concatenate((xref, xcorr)))\n",
    "\n",
    "#     FP = 1.0 - np.interp(x_all, xref, cref)\n",
    "#     TP = 1.0 - np.interp(x_all, xcorr, ccorr)\n",
    "#     iord = np.argsort(FP)\n",
    "\n",
    "#     return FP[iord], TP[iord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP, TP = ROC_curve(recon, corr_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(*ROC_curve(recon, corr_recon))\n",
    "# plt.plot([0, 1], [0, 1], 'k:')\n",
    "# plt.gca().set_aspect(1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
