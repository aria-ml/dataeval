{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    !pip install -q daml[torch] torchmetrics torchvision\n",
    "    !export LC_ALL=\"en_US.UTF-8\"\n",
    "    !export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "    !export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "    !ldconfig /usr/lib64-nvidia\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q tabulate\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "\n",
    "from typing import Dict, Sequence, cast\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "from daml.metrics import Sufficiency\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(formatter={\"float\": lambda x: f\"{x:0.4f}\"})\n",
    "torch.manual_seed(0)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "# Download the mnist dataset and preview the images\n",
    "to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=to_tensor)\n",
    "test_ds = datasets.MNIST(\"./data\", train=False, download=True, transform=to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(6400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model = torch.compile(Net().to(device))\n",
    "\n",
    "# Type cast the model back to Net as torch.compile returns a Unknown\n",
    "# Nothing internally changes from the cast; we are simply signaling the type\n",
    "model = cast(Net, model)\n",
    "\n",
    "\n",
    "def custom_train(model: nn.Module, dataset: Dataset, indices: Sequence[int]):\n",
    "    # Defined only for this testing scenario\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    epochs = 10\n",
    "\n",
    "    # Define the dataloader for training\n",
    "    dataloader = DataLoader(Subset(dataset, indices), batch_size=16)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).to(device)\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = model(X)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, y)\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "            # Update weights/parameters\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def custom_eval(model: nn.Module, dataset: Dataset) -> Dict[str, float]:\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    result = 0\n",
    "\n",
    "    # Set model layers into evaluation mode\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "    # Tell PyTorch to not track gradients, greatly speeds up processing\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).to(device)\n",
    "            preds = model(X)\n",
    "            metric.update(preds, y)\n",
    "        result = metric.compute().cpu()\n",
    "    return {\"Accuracy\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified inputs\n",
    "\n",
    "# What we use to curve-fit the sufficiency model\n",
    "train_ds = Subset(train_ds, range(2000))\n",
    "test_ds = Subset(test_ds, range(500))\n",
    "\n",
    "# How much training data an evaluator agent has\n",
    "dataset_size = 600\n",
    "# The accuracy that an evaluator agent wants\n",
    "desired_accuracies = np.array([0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sufficiency evaluation is done here (cache this or substitute it with your own sufficiency study)\n",
    "\n",
    "# Instantiate sufficiency metric\n",
    "suff = Sufficiency(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    test_ds=test_ds,\n",
    "    train_fn=custom_train,\n",
    "    eval_fn=custom_eval,\n",
    "    runs=5,\n",
    "    substeps=10,\n",
    ")\n",
    "\n",
    "# Train & test model\n",
    "output = suff.evaluate(niter=50)\n",
    "\n",
    "projection = Sufficiency.project(output, [dataset_size])\n",
    "\n",
    "\n",
    "# Evaluate the learning curve to infer the needed amount of training data\n",
    "samples_needed = Sufficiency.inv_project({\"Accuracy\": desired_accuracies}, output)\n",
    "\n",
    "plot_output = Sufficiency.plot(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values we pull out of sufficiency\n",
    "# Whether the accuracy evaluated at the user's dataset size exceeds the user's desired accuracy\n",
    "is_sufficient = projection[\"Accuracy\"][-1] >= desired_accuracies[0]\n",
    "# The plot showing 1) the points internally generated to do the curve-fit\n",
    "# and 2) the curve fit\n",
    "figs = plot_output\n",
    "# The projected accuracy for the number of samples the user has\n",
    "proj_accuracy = projection[\"Accuracy\"][-1]\n",
    "# The estimated number of samples needed to achieve the accuracy that the user wants\n",
    "pred_nsamples = samples_needed[\"Accuracy\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that gradient will plot as a table\n",
    "suff_preds = {\n",
    "    \"sufficient\": is_sufficient,\n",
    "    \"Pred Performance\": proj_accuracy,\n",
    "    \"Pred nsamples\": pred_nsamples,\n",
    "    \"nsamples\": dataset_size,\n",
    "    \"desired_perf\": desired_accuracies[0] * 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient.slide_deck.shapes import Image, Placement, SubText, Table, Text, TextContent\n",
    "from gradient.slide_deck.slidedeck import (\n",
    "    DEFAULT_GRADIENT_PRESENTATION_TEMPLATE_PATH,\n",
    "    DefaultGradientSlideLayouts,\n",
    "    SlideDeck,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_drift_report_table(suff_preds: dict) -> pd.DataFrame:\n",
    "    drift_table = pd.DataFrame(\n",
    "        {\n",
    "            \"Is sufficient?\": [\"Yes\" if suff_preds[\"sufficient\"] else \"No\"],\n",
    "            # \"Test statistic\": [np.mean(preds[\"distance\"]) for preds in drift_preds.values()],\n",
    "            f\"Predicted performance for {suff_preds['nsamples']} samples\": [suff_preds[\"Pred Performance\"]],\n",
    "            f\"Predicted number of samples needed to achieve performance of {suff_preds['desired_perf']}%\": [\n",
    "                suff_preds[\"Pred nsamples\"]\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    return drift_table\n",
    "\n",
    "\n",
    "def generate_drift_report_slide_kwargs(suff_preds: dict) -> dict:\n",
    "    content = [\n",
    "        \"Operational dataset \",\n",
    "        SubText(f\"{'is' if is_sufficient else 'is not'}\", bold=True),\n",
    "        f\" sufficient for a desired model accuracy of {desired_accuracies[0]}\",\n",
    "    ]\n",
    "\n",
    "    kwargs = {\n",
    "        \"title\": \"Sufficiency: Summary\",\n",
    "        \"layout\": DefaultGradientSlideLayouts.CONTENT_DEFAULT,\n",
    "        \"placeholder_fillings\": [TextContent(lines=[Text(content=content)])],\n",
    "        \"additional_shapes\": [\n",
    "            Table(\n",
    "                dataframe=generate_drift_report_table(suff_preds).round(4),\n",
    "                fontsize=16,\n",
    "                left=2.0,\n",
    "                top=2.0,\n",
    "                width=9.0,\n",
    "                height=4.0,\n",
    "            ),\n",
    "        ],\n",
    "    }\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def generate_slide_from_fig(fig, working_directory, fig_title):\n",
    "    save_dir = os.path.join(working_directory, f\"{fig_title}.png\")\n",
    "    fig.savefig(save_dir)\n",
    "    kwargs = {\n",
    "        \"title\": fig_title,\n",
    "        \"layout\": DefaultGradientSlideLayouts.CONTENT_TITLE_ONLY,\n",
    "        \"additional_shapes\": [\n",
    "            Image(\n",
    "                path=save_dir,\n",
    "                placement=Placement.MANUAL,\n",
    "                left=1.0,\n",
    "                top=1.5,\n",
    "                width=5.0,\n",
    "                height=5.0,\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "example_directory = Path.cwd() / \"report_suff_example\"\n",
    "example_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and add to the slide deck\n",
    "deck = SlideDeck(presentation_template_path=DEFAULT_GRADIENT_PRESENTATION_TEMPLATE_PATH)\n",
    "\n",
    "deck.add_slide(**generate_drift_report_slide_kwargs(suff_preds))\n",
    "\n",
    "\n",
    "for i, fig in enumerate(figs):\n",
    "    fig_title = f\"Sufficiency Plot {i}\"\n",
    "\n",
    "    deck.add_slide(**generate_slide_from_fig(fig, example_directory, fig_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck.save(\n",
    "    output_directory=example_directory,\n",
    "    name=\"report_suff_example\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
