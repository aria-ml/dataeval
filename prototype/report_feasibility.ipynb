{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    !pip install -q daml[torch] torchmetrics torchvision\n",
    "    !export LC_ALL=\"en_US.UTF-8\"\n",
    "    !export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "    !export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "    !ldconfig /usr/lib64-nvidia\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q tabulate\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(formatter={\"float\": lambda x: f\"{x:0.4f}\"})\n",
    "torch.manual_seed(0)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "\n",
    "import tensorflow.keras.datasets as tfds\n",
    "\n",
    "from daml.metrics import BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "(images, labels), (test_images, test_labels) = tfds.mnist.load_data()\n",
    "\n",
    "images_split = {}\n",
    "labels_split = {}\n",
    "\n",
    "# Keep only 1, 4, and 9\n",
    "for label in (1, 4, 9):\n",
    "    subset_indices = np.where(labels == label)\n",
    "    images_split[label] = images[subset_indices][:2000]\n",
    "    labels_split[label] = labels[subset_indices][:2000]\n",
    "\n",
    "images_subset = np.concatenate(list(images_split.values()))\n",
    "labels_subset = np.concatenate(list(labels_split.values()))\n",
    "print(images_subset.shape)\n",
    "print(np.unique(labels_subset, return_counts=True))\n",
    "\n",
    "# Flatten the images\n",
    "images_flattened = images_subset.reshape((images_subset.shape[0], -1))\n",
    "print(\"Dataset shape:\", images_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BER metric\n",
    "metric = BER(images_flattened, labels_subset, method=\"MST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified inputs\n",
    "\n",
    "# What we use to curve-fit the sufficiency model\n",
    "# train_ds = Subset(train_ds, range(2000))\n",
    "# test_ds = Subset(test_ds, range(500))\n",
    "\n",
    "target_performance = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the BER metric for the MNIST data with digits 1, 4, 9.\n",
    "# One minus the value of this metric gives our estimate of the upper bound on accuracy.\n",
    "base_ber = metric.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values we pull out of sufficiency\n",
    "# Whether the accuracy evaluated at the user's dataset size exceeds the user's desired accuracy\n",
    "base_ber[\"max_accuracy\"] = 1 - base_ber[\"ber\"]\n",
    "dev_dict = {\"BER\": base_ber}\n",
    "\n",
    "shauns_output = {\"Development\": dev_dict}\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# The plot showing 1) the points internally generated to do the curve-fit\n",
    "# and 2) the curve fit\n",
    "# The projected accuracy for the number of samples the user has\n",
    "ber = round(dev_dict[\"BER\"][\"ber\"], 2)  # base_ber[\"ber\"]\n",
    "# The estimated number of samples needed to achieve the accuracy that the user wants\n",
    "ber_lower = round(dev_dict[\"BER\"][\"ber_lower\"], 2)\n",
    "max_accuracy = round(dev_dict[\"BER\"][\"max_accuracy\"], 2)\n",
    "\n",
    "is_feasible = max_accuracy >= target_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that gradient will plot as a table\n",
    "feas_preds = {\n",
    "    \"feasible\": is_feasible,\n",
    "    \"BER\": ber,\n",
    "    \"Lower BER\": ber_lower,\n",
    "    \"Max Accuracy\": max_accuracy,\n",
    "    \"Target Performance\": target_performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient.slide_deck.shapes import SubText, Table, Text, TextContent\n",
    "from gradient.slide_deck.slidedeck import (\n",
    "    DEFAULT_GRADIENT_PRESENTATION_TEMPLATE_PATH,\n",
    "    DefaultGradientSlideLayouts,\n",
    "    SlideDeck,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_feas_report_table(feas_preds: dict) -> pd.DataFrame:\n",
    "    drift_table = pd.DataFrame(\n",
    "        {\n",
    "            \"Is feasible?\": [\"Yes\" if feas_preds[\"feasible\"] else \"No\"],\n",
    "            # \"Test statistic\": [np.mean(preds[\"distance\"]) for preds in drift_preds.values()],\n",
    "            \"Bayes Error Rate\": [feas_preds[\"BER\"]],\n",
    "            \"Lower Bayes Error Rate\": [feas_preds[\"Lower BER\"]],\n",
    "            \"Maximum Accuracy\": [feas_preds[\"Max Accuracy\"]],\n",
    "        }\n",
    "    )\n",
    "    return drift_table\n",
    "\n",
    "\n",
    "def generate_feas_report_slide_kwargs(feas_preds: dict) -> dict:\n",
    "    content = [\n",
    "        f\"Accuracy of {feas_preds['Target Performance']*100}% \",\n",
    "        SubText(f\"{'is' if is_feasible else 'is not'}\", bold=True),\n",
    "        \" feasible for the dataset\",\n",
    "    ]\n",
    "\n",
    "    kwargs = {\n",
    "        \"title\": \"Feasibility: Summary\",\n",
    "        \"layout\": DefaultGradientSlideLayouts.CONTENT_DEFAULT,\n",
    "        \"placeholder_fillings\": [TextContent(lines=[Text(content=content)])],\n",
    "        \"additional_shapes\": [\n",
    "            Table(\n",
    "                dataframe=generate_feas_report_table(feas_preds).round(4),\n",
    "                fontsize=16,\n",
    "                left=2.0,\n",
    "                top=2.0,\n",
    "                width=9.0,\n",
    "                height=4.0,\n",
    "            ),\n",
    "        ],\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "example_directory = Path.cwd() / \"report_feas_example\"\n",
    "example_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and add to the slide deck\n",
    "deck = SlideDeck(presentation_template_path=DEFAULT_GRADIENT_PRESENTATION_TEMPLATE_PATH)\n",
    "\n",
    "deck.add_slide(**generate_feas_report_slide_kwargs(feas_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck.save(\n",
    "    output_directory=example_directory,\n",
    "    name=\"report_feas_example\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
