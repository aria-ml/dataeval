{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._dynamo.eval_frame.DisableContext at 0x7f8a4d2d4150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Dict, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import nannyml as nml\n",
    "from IPython.display import display\n",
    "import loss_estimation\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(formatter={\"float\": lambda x: f\"{x:0.4f}\"})\n",
    "torch.manual_seed(0)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "torch._dynamo.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the mnist dataset\n",
    "to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=to_tensor)\n",
    "test_ds = datasets.MNIST(\"./data\", train=False, download=True, transform=to_tensor)\n",
    "\n",
    "class_names = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the operator that will be used to generate a corrupted MNIST dataset, by adding random noise.\n",
    "\n",
    "class Corrupt(v2.Transform):\n",
    "    def _transform(self, inpt, params):\n",
    "        return self.contrast(inpt)\n",
    "\n",
    "    def contrast(self, sample):\n",
    "        x = sample\n",
    "        c = 0.3\n",
    "\n",
    "        # x = np.array(x) / 255.0\n",
    "        x = x.float() / 255.0\n",
    "        rands = torch.normal(x, std=c)\n",
    "        x = torch.clip(rands, 0, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "c_to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True), Corrupt()])\n",
    "c_contrast = v2.Compose([Corrupt()])\n",
    "\n",
    "# Sets up the corrupted test dataset, using the random-noise transform specified above\n",
    "c_test_ds = datasets.MNIST(\"./data\", train=False, download=True, transform=c_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a subset of 2000 training images and 500 test images,\n",
    "# so that the notebook cells can be evaluated quickly.\n",
    "train_ds = Subset(train_ds, range(2000))\n",
    "test_ds = Subset(test_ds, range(500))\n",
    "c_test_ds = Subset(c_test_ds, range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(6400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model = torch.compile(Net().to(device))\n",
    "\n",
    "# Type cast the model back to Net as torch.compile returns a Unknown\n",
    "# Nothing internally changes from the cast; we are simply signaling the type\n",
    "model = cast(Net, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the function we will use to train the model.\n",
    "def custom_train(model: nn.Module, dataset: Dataset):\n",
    "    # Defined only for this testing scenario\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    epochs = 10\n",
    "\n",
    "    # Define the dataloader for training\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).to(device)\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = model(X)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, y)\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "            # Update weights/parameters\n",
    "            optimizer.step()\n",
    "\n",
    "def reset_parameters(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Re-initializes each layer in the model using\n",
    "    the layer's defined weight_init function\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        # Check if the current module has reset_parameters\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()  # type: ignore\n",
    "\n",
    "    # Applies fn recursively to every submodule see:\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "    return model.apply(fn=weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /tmp/ipykernel_23914/4158063905.py line 12 \n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING]   File \"/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Quadro P2000 with Max-Q Design which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-09-05 17:00:21,754] torch._dynamo.convert_frame: [WARNING] \n",
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Reset the network weights to \"create\" an untrained model\n",
    "model = reset_parameters(model)\n",
    "# Run the model with each substep of data\n",
    "# train on subset of train data\n",
    "train_kwargs = {}\n",
    "eval_kwargs = {}\n",
    "custom_train(\n",
    "    model,\n",
    "    train_ds,\n",
    "    **train_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataeval/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "estimator = loss_estimation.LossEstimator(\"CBPE\", \"classification_multiclass\")\n",
    "results = estimator.evaluate(model, test_ds, c_test_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reference_Metric': 0.8066528514612994, 'Op_Predicted_Metric': 0.13486985345575161, 'Has_Drifted': True}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def custom_eval(model: nn.Module, dataset: Dataset) -> Dict[str, list]:\n",
    "    # metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    # result = 0\n",
    "    # batch_dicts = []\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "    # dict_out = {\"conf\": np.zeros(0), \"preds\": np.zeros(0), \"ground_truth\": np.zeros(0)}\n",
    "    dict_out = {\"y_pred\": np.zeros(0, dtype=int), \"y\": np.zeros(0, dtype=int)}\n",
    "    for i in range(10):\n",
    "        dict_out[f\"y_pred_proba_{i}\"] = np.zeros(0)\n",
    "\n",
    "    # Set model layers into evaluation mode\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "    # Tell PyTorch to not track gradients, greatly speeds up processing\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).int()\n",
    "            output = model(X).cpu()\n",
    "            processed_output = torch.max(output, dim=1)\n",
    "            confs = processed_output[0]\n",
    "            preds = np.int64(processed_output[1])\n",
    "\n",
    "            # batch_dict = {\"conf\": confs, \"preds\": preds, \"ground_truth\": y}\n",
    "            # dict_out[\"conf\"] = np.concatenate((dict_out[\"conf\"], confs))\n",
    "            dict_out[\"y_pred\"] = np.concatenate((dict_out[\"y_pred\"], preds), dtype=int)\n",
    "            dict_out[\"y\"] = np.concatenate((dict_out[\"y\"], y), dtype=int)\n",
    "            for i in range(10):\n",
    "                key = f\"y_pred_proba_{i}\"\n",
    "                dict_out[key] = np.concatenate((dict_out[key], output[:, i]))\n",
    "\n",
    "            metric.update(output, y)\n",
    "        result = metric.compute().cpu()\n",
    "    return {\"Accuracy\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted accuracy on corrupted MNIST: 0.13486985345575161\n",
      "Actual accuracy on corrupted MNIST: 0.09399999678134918\n",
      "Percentage point difference between true and predicted accuracy: 4.086986064910889 %\n"
     ]
    }
   ],
   "source": [
    "c_evaluated = custom_eval(model, c_test_ds, **eval_kwargs)\n",
    "\n",
    "pred_accuracy = results['Op_Predicted_Metric']\n",
    "true_accuracy = c_evaluated[\"Accuracy\"].float()\n",
    "percent_diff = np.abs(pred_accuracy - true_accuracy)* 100\n",
    "\n",
    "print(f'Predicted accuracy on corrupted MNIST: {pred_accuracy}')\n",
    "print(f'Actual accuracy on corrupted MNIST: {true_accuracy}')\n",
    "print(f'Percentage point difference between true and predicted accuracy: {percent_diff} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
