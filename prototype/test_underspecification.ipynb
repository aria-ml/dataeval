{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, tv_tensors\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "import torch\n",
    "\n",
    "class FMOWDataset(datasets.VisionDataset):\n",
    "    def __init__(self, root, label_df, transforms=None):\n",
    "        root = Path(root)\n",
    "        super().__init__(root=root, transforms=transforms)\n",
    "        self.label_df = label_df\n",
    "        self.categories = sorted(self.label_df[\"category\"].unique())\n",
    "        self.class_ids = {cat:idx for idx,cat in enumerate(self.categories)}\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        class_names = []\n",
    "        boxes = []\n",
    "        path = self.label_df.loc[idx, \"img_path\"]\n",
    "        image = Image.open(f\"{self.root}/{path}.jpg\").convert(\"RGB\")\n",
    "        with open(f\"{self.root}/{path}.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            for target in metadata[\"bounding_boxes\"]:\n",
    "                class_names.append(self.class_ids[target[\"category\"]])\n",
    "                box = target[\"box\"]\n",
    "                boxes.append([box[0], box[1], box[0]+box[2]-1, box[1]+box[3]-1])\n",
    "        target = {\n",
    "            \"boxes\": tv_tensors.BoundingBoxes(data=boxes, format=\"XYXY\", canvas_size=image.size), # type: ignore\n",
    "            \"labels\": torch.tensor(class_names)\n",
    "        }\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2, InterpolationMode\n",
    "import torch\n",
    "validation_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "stratified_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToDtype(torch.float32, scale=True)   \n",
    "])\n",
    "shifted_transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.SanitizeBoundingBoxes(), \n",
    "    v2.Resize(size=int(torch.randint(56, 448,(1,)))),\n",
    "    v2.Resize(size=448,interpolation=InterpolationMode.NEAREST),\n",
    "    v2.ToDtype(torch.float32, scale=True), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper class to compute model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from torchvision.ops import box_iou\n",
    "import numpy as np\n",
    "\n",
    "class ClassificationROCAUC:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def __call__(self, pred_confs, targets):\n",
    "        return roc_auc_score(targets, pred_confs)\n",
    "    \n",
    "class ObjectDetectorROCAUC:\n",
    "    def __init__(self, iou_threshold):\n",
    "        self.iou_threshold = iou_threshold\n",
    "\n",
    "    def __call__(self, pred_batches, target_batches):\n",
    "        num_tgts = 0\n",
    "        correct = []\n",
    "        scores = []\n",
    "        for pred_batch, target_batch in zip(pred_batches, target_batches):\n",
    "            for pred, target in zip(pred_batch, target_batch):\n",
    "                pred[\"boxes\"] = pred[\"boxes\"].cpu()\n",
    "                pred[\"labels\"] = pred[\"labels\"].cpu()\n",
    "                pred[\"scores\"] = pred[\"scores\"].cpu()\n",
    "                target[\"boxes\"] = target[\"boxes\"].cpu()\n",
    "                target[\"labels\"] = target[\"labels\"].cpu()\n",
    "                N = target[\"boxes\"].shape[0]\n",
    "                class_correct = pred[\"labels\"][:, None] == target[\"labels\"][None]\n",
    "                pred_tgt_iou = box_iou(pred[\"boxes\"], target[\"boxes\"])\n",
    "                scores.append(pred[\"scores\"].repeat(N,1).T.flatten().numpy())\n",
    "                num_tgts += N\n",
    "                box_correct = pred_tgt_iou > self.iou_threshold\n",
    "                correct.append((class_correct & box_correct).flatten().float().numpy())\n",
    "        scores = np.concatenate(scores)\n",
    "        correct = np.concatenate(correct)\n",
    "        return roc_auc_score(correct, scores)\n",
    "\n",
    "class ObjectDetectorAccuracy:\n",
    "    def __init__(self, iou_threshold):\n",
    "        self.iou_threshold = iou_threshold\n",
    "\n",
    "    def __call__(self, pred_batches, target_batches):\n",
    "        target_labels = []\n",
    "        pred_labels = []\n",
    "        \"\"\"\n",
    "        We want to feed the metric calculator the following:\n",
    "\n",
    "        Multiclass:\n",
    "        1 dummy prediction per missed detection (no prediction intersects target with high enough iou)\n",
    "        1 prediction per true detection corresponding to class prediction with highest confidence\n",
    "        1 dummy target for each false positive (a prediction that does not intersect any target with high enough iou)\n",
    "\n",
    "        Multilabel:\n",
    "        num_class dummy predictions per missed detection \n",
    "        num_class predictions per true detection\n",
    "        1 dummy target per false positive\n",
    "        \"\"\"\n",
    "        for pred_batch, target_batch in zip(pred_batches, target_batches):\n",
    "            for pred, target in zip(pred_batch, target_batch):\n",
    "                pred[\"boxes\"] = pred[\"boxes\"].cpu()\n",
    "                pred[\"labels\"] = pred[\"labels\"].cpu()\n",
    "                pred[\"scores\"] = pred[\"scores\"].cpu()\n",
    "                target[\"boxes\"] = target[\"boxes\"].cpu()\n",
    "                target[\"labels\"] = target[\"labels\"].cpu()\n",
    "                M = pred[\"boxes\"].shape[0]\n",
    "                N = target[\"boxes\"].shape[0]\n",
    "                pred_tgt_iou = box_iou(pred[\"boxes\"], target[\"boxes\"]) # MxN\n",
    "                abv_th = pred_tgt_iou > self.iou_threshold\n",
    "                \"\"\" \n",
    "                Determine number of missed detections\n",
    "                \"\"\"\n",
    "                missed_detections = ~abv_th.any(dim=0) # (1,N)\n",
    "                md_targets = target[\"labels\"][missed_detections] # (num_missed_detections,)\n",
    "                md_preds = -1 * torch.ones_like(md_targets) # dummy predictions\n",
    "                \"\"\"\n",
    "                Determine number of false positives\n",
    "                \"\"\"\n",
    "                false_positives = ~abv_th.any(dim=1) # (M,1)\n",
    "                fp_preds = pred[\"labels\"][false_positives] # (num_false_positives,)\n",
    "                fp_targets = -1 * torch.ones_like(fp_preds) # dummy targets\n",
    "                \"\"\"\n",
    "                Multiclass implementation (one class prediction per box)\n",
    "                \"\"\"\n",
    "                pred_grid = pred[\"labels\"].repeat(N,1).T\n",
    "                pred_grid = pred_grid[abv_th]\n",
    "                pred_class = torch.cat([md_preds, pred_grid, fp_preds])\n",
    "                tgt_grid = target[\"labels\"].repeat(M,1)\n",
    "                tgt_grid = tgt_grid[abv_th]\n",
    "                tgt_class = torch.cat([md_targets, tgt_grid, fp_targets])\n",
    "                pred_labels.append(pred_class.cpu().numpy())\n",
    "                target_labels.append(tgt_class.cpu().numpy())\n",
    "        pred_labels = np.concatenate(pred_labels)\n",
    "        target_labels = np.concatenate(target_labels)\n",
    "        return accuracy_score(target_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Model Class and find the weight files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from pathlib import Path\n",
    "nclasses = 10\n",
    "model_class = models.get_model(name=\"fasterrcnn_resnet50_fpn\", num_classes=nclasses, img_size_min=448, img_size_max=768)\n",
    "rundir = Path(\"/home/jmcmillan/mlqp-phase-ii-base/stress_tests/runs/rcnn_v1\")\n",
    "weight_files = list(rundir.rglob(\"*.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "val_df:pd.DataFrame = pd.read_csv(\"/data/fmow-rgb-chipped/shifted_dfs/val_df.csv\")\n",
    "val_df = val_df.groupby(\"category\").sample(frac=0.5).reset_index()\n",
    "val_dataset = FMOWDataset(root=\"/data/fmow-rgb-chipped\", label_df=val_df, transforms=validation_transform)\n",
    "nw = 0\n",
    "pers = nw > 0\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, pin_memory=True, num_workers=nw, collate_fn=lambda batch: tuple(zip(*batch)),persistent_workers=pers)\n",
    "model_class.eval()\n",
    "for vimg, vtgt in val_loader:\n",
    "    o = model_class(vimg)\n",
    "    break\n",
    "test_df:pd.DataFrame = pd.read_csv(\"/data/fmow-rgb-chipped/shifted_dfs/test_df.csv\")\n",
    "test_df = test_df.groupby(\"category\").sample(frac=0.5).reset_index()\n",
    "test_dataset = FMOWDataset(root=\"/data/fmow-rgb-chipped\", label_df=test_df, transforms=shifted_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, pin_memory=True, num_workers=nw, collate_fn=lambda batch: tuple(zip(*batch)),persistent_workers=pers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Metric Class and Metric Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Models: 100%|██████████| 20/20 [1:11:17<00:00, 213.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import underspecification\n",
    "from torchvision import models\n",
    "from pathlib import Path\n",
    "iou_threshold=0.3\n",
    "acc_metric = ObjectDetectorAccuracy(iou_threshold=iou_threshold)\n",
    "roc_metric = ObjectDetectorROCAUC(iou_threshold=iou_threshold)\n",
    "metric_save = underspecification.MetricEvaluator(model_class,weight_files,val_loader, test_loader, roc_metric, device=0)\n",
    "metric_save.calculate_metrics(metric_filename=\"shifted_rocauc.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, instantiate StressTester Class and perform stress test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import underspecification\n",
    "\n",
    "val_metric_path = \"/home/jmcmillan/mlqp-phase-ii-base/stress_tests/runs/rcnn_v1/val_shifted_rocauc.npy\"\n",
    "test_metric_path = \"/home/jmcmillan/mlqp-phase-ii-base/stress_tests/runs/rcnn_v1/test_shifted_rocauc.npy\"\n",
    "figname = \"spearman_shifted_rocauc_interval.png\"\n",
    "roc_stress_tester = underspecification.MetricStressTester(val_metric_path, test_metric_path, figure_savename=figname)\n",
    "roc_stress_tester.calculate_underspecification()\n",
    "roc_stress_tester.plot_confidence_interval(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlqp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
