#!/bin/bash -e
set -o pipefail

function showHelp() {
cat << EOF
Usage:
  build [options] <tasks(s)> <python version(s)>

Options:
      --build-base  only build base dependency images
      --build-task  only build task images
  -h, --help        display this help information
  -q, --quiet       do not print output to console during container execution
      --gpu         enable gpu support on task execution
      --push        push all built images to repository

Default:
  run unit tests and type check for 3.9-3.11 as well as lint and docs

Python Versions:
  3.9-3.11 are supported

Tasks:
  unit    run unit tests
  type    run typecheck
  lint    run static code analysis
  deps    run minimum dependency tests
  docs    generate documentation
  qdocs   generate documentation using cached notebooks
  doctest run documentation tests

Note:
  docs, qdocs and doctest are always performed on python 3.11
EOF
exit $1
}

options=$(getopt -l "help,quiet,gpu,build-base,build-task,push" -o "hq" -n "build" -- "$@")
eval set -- "$options"
while true; do
    case "$1" in
        -h|--help)       showHelp;;
        -q|--quiet)      export quiet="--quiet";;
        --gpu)           export gpuflag="--gpus all";;
        --build-base)    build_base=1;;
        --build-task)    build_task=1;;
        --push)          if [[ ! $CI ]]; then echo "Only CI pipelines should be pushing."; exit 1; else export push_to_repo=1; fi;;
        --)              shift; break;;
    esac
    shift
done

if [[ -f .settings ]]; then
    if [[ $(cat .settings | grep save-build-images) ]]; then
        export save_build_images="true"
    fi
fi

# declare lookup maps
declare -A supported_pvers=([3.9]=1 [3.10]=1 [3.11]=1)
declare -A supported_tasks=([unit]=1 [type]=1 [lint]=1 [deps]=1)
declare -A supported_docs=([docs]=1 [qdocs]=1 [doctest]=1)

# generate python and task lists
declare -A pvers; declare -A tasks;
count=0; c_pvers=0; c_tasks=0; c_docs=0;

# validate args
for arg do
    if [[ $arg == -* ]]; then continue; fi
    if [[ ${supported_pvers["$arg"]} ]]; then pvers[$arg]=1; ((++c_pvers)); fi
    if [[ ${supported_tasks["$arg"]} ]]; then tasks[$arg]=1; ((++c_tasks)); fi
    if [[ ${supported_docs["$arg"]} ]]; then tasks[$arg]=1; ((++c_docs)); fi
    ((++count))
done

# show help if arg count mismatch
if [[ $((c_pvers + c_tasks + c_docs)) != $count ]]; then showHelp 1; fi

# set all python versions if none specified
if [[ $count == 0 || ($c_pvers == 0 && $c_tasks != 0) ]]; then pvers=([3.9]=1 [3.10]=1 [3.11]=1); fi

# for build_task we should run these specific tasks
if [[ $build_task ]]; then tasks=([unit]=1 [type]=1 [lint]=1 [deps]=1); fi

# set defaults if not specified
if [[ ! $build_base && ! $build_task ]]; then
    if [[ $count == 0 || ($c_tasks == 0 && $c_pvers != 0) ]]; then tasks[unit]=1; tasks[type]=1; fi
fi

# generate "task-python_version" jobs
declare -A jobs;
for task in "${!tasks[@]}"; do
    case "$task" in
        docs|qdocs|doctest) jobs["$task-3.11"]=1;;
        *) for python_version in "${!pvers[@]}"; do jobs["$task-$python_version"]=1; done;;
    esac
done

export builder_name="daml"
if [[ -z $(docker builder ls --format '{{.Name}}' | grep $builder_name) ]]; then
    echo "builder instance named $builder_name doesn't exist, creating it now..."
    docker builder create \
        --driver docker-container \
        --bootstrap \
        --name $builder_name
fi

function build_image() {
    target=$1
    python_version=$2
    no_cache_layers=${@:3}

    # create cache array
    cache=()
    if [[ $target != base && $target != pyenv ]]; then
        if [[ ${BRANCH_CACHE} ]]; then
            cache+=("${BRANCH_CACHE}${target}-${python_version}")
        fi
        if [[ ! ${BRANCH_CACHE} || ! $(docker manifest inspect ${cache[-1]} 2> /dev/null) ]]; then
            cache+=("${MAIN_CACHE}:${target}-${python_version}")
        fi
    fi
    if [[ $target != pyenv ]]; then
        if [[ ${BRANCH_CACHE} ]]; then
            cache+=("${BRANCH_CACHE}base-${python_version}")
        fi
        if [[ ! ${BRANCH_CACHE} || ! $(docker manifest inspect ${cache[-1]} 2> /dev/null) ]]; then
            cache+=("${MAIN_CACHE}:base-${python_version}")
        fi
    fi
    if [[ ${BRANCH_CACHE} ]]; then
        cache+=("${BRANCH_CACHE}pyenv-${python_version}")
    fi
    if [[ ! ${BRANCH_CACHE} || ! $(docker manifest inspect ${cache[-1]} 2> /dev/null) ]]; then
        cache+=("${MAIN_CACHE}:pyenv-${python_version}")
    fi

    # set cache_from and cache_to args
    cache_from_arg=$(echo ${cache[*]} | xargs -n1 sh -c 'echo --cache-from type=registry,ref=$0')
    if [[ $push_to_repo ]]; then
        # Writing to the cache means that you must be able to push to the registry, therefore
        # don't want to force users to login to the registry just to build.
        cache_to_arg="--cache-to type=registry,image-manifest=true,ref=${cache[0]}"
    else
        cache_to_arg=""
    fi

    # set no_cache_filter_arg
    if [[ $no_cache_layers ]]; then
        no_cache_filter_arg="--no-cache-filter $(tr ' ' ',' <<< $no_cache_layers)"
    fi

    # There are only 2 scenarios where we want to push an actual image up to the registry
    # one is for the pyenv image if it does not exist, and the other is for task images to
    # be loaded for playback of results.

    # build image_tag for pyenv (if not exist) or for task images (not pyenv, not base)
    if [[ $target == pyenv && ! $(docker manifest inspect "${PYENV_IMAGE}:${python_version}" 2> /dev/null) ]]; then
        image_tag="${PYENV_IMAGE}:${python_version}"
    elif [[ $target != pyenv && $target != base ]]; then
        image_tag="${TASK_IMAGE}${target}-${python_version}"
    else
        image_tag=""
    fi

    # build output_arg as appropriate if image needs to be pushed, otherwise just populate the registry cache
    if [[ $image_tag ]]; then
        output_arg="--output type=image,name=${image_tag}"
        if [[ $push_to_repo ]]; then
            output_arg+=",push=true"
        fi
    else
        output_arg="--output type=cacheonly"
    fi

    if [[ $target != pyenv && $target != base && ($save_build_images || -z $push_to_repo) ]]; then
        # By default the docker-container driver doesn't load images to the
        # local docker images store, these args will cause it to do so.
        load_arg="--tag ${image_tag} --load"
    fi

    docker_build_cmd="docker buildx build $quiet \
        $load_arg \
        --builder $builder_name \
        --build-arg python_version=$python_version \
        $no_cache_filter_arg \
        $cache_from_arg \
        $cache_to_arg \
        $output_arg \
        --target $target \
        ."
    
    if [[ ! $quiet ]]; then
        echo "========================================"
        echo "Building $target-$python_version..."
        echo $docker_build_cmd
        time $docker_build_cmd
        echo "========================================"
    else
        $docker_build_cmd &> /dev/null
    fi
}

function build_and_run() {
    IFS=- read -r task python_version <<< $1

    container_name="run-${task}-${python_version}"
    if [[ $CI_PIPELINE_ID ]]; then
        container_name="${container_name}-${CI_PIPELINE_ID}"
    fi

    # If the image was pushed, then we need to be sure to pull the updated image
    if [[ $push_to_repo ]]; then
        pull_arg="--pull always"
    fi

    image_tag="${TASK_IMAGE}${task}-${python_version}"

    # NOTE: If you ./build --push at the same time as a pipeline in the same
    # branch that is running you can potentially overwrite a results image that
    # will be read from in that pipeline run.
    if [[ ! $(docker manifest inspect $image_tag 2> /dev/null) ]]; then
        build_image $task $python_version
    fi

    echo "======================================================================"
    echo "Output from ${container_name}"
    echo "----------------"
    set +e
    docker run --interactive $pull_arg --name $container_name $gpuflag $image_tag
    exitcode=$?
    set -e
    echo "----------------"
    echo "${container_name} exit code: ${exitcode}"
    echo "======================================================================"

    mkdir -p output
    docker cp $container_name:/daml/output/ .

    if [[ $exitcode != 0 ]]; then
        exit $exitcode
    fi
}

export -f build_image
export -f build_and_run

# In CI pipelines use commit branch name or merge request source branch name
# These are mutually exclusive when set
# https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
if [[ $CI ]]; then
    branch_name=$CI_COMMIT_BRANCH$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME
    main_branch=$CI_DEFAULT_BRANCH
else
    branch_name=$(git rev-parse --abbrev-ref HEAD)
    main_branch="main"
fi

namespace="harbor.jatic.net/daml"
if [[ $branch_name == $main_branch ]]; then
    repository="main"
else
    repository="dev"
    tag_prefix="${branch_name/[^a-zA-Z0-9]/-}-"
fi

# construct image and cache names
export PYENV_IMAGE="${namespace}/pyenv"
export TASK_IMAGE="${namespace}/${repository}:${tag_prefix}"

export MAIN_CACHE="${namespace}/cache"
if [[ $tag_prefix ]]; then
    export BRANCH_CACHE="${namespace}/cache:${tag_prefix}"
fi

if [[ ! $quiet ]]; then
    keep_order="--keep-order"
fi

start=$(date +%s)

for python_version in ${!pvers[@]}; do
    # In the CI pipeline, build_base and build_task are staged separately to allow docs to kick
    # off quicker. These checks allow us to run either base or task exclusively. Removing this
    # optimization would mean we could just combine both and remove the conditional checks.
    if [[ ! $CI || $build_base ]]; then
        build_image pyenv $python_version
        build_image base $python_version
    fi
    if [[ ! $CI || $build_task ]]; then
        echo "Building [${!tasks[@]}]-$python_version..."
        python_version=$python_version parallel $keep_order --lb "build_image {} $python_version" ::: ${!tasks[@]}
    fi
done

if [[ $build_base || $build_task ]]; then
    exit $?
fi

end=$(date +%s)
diff=$(( $end - $start ))
echo "------"
echo "Image build preparation completed in $diff seconds"
echo "------"

# execute jobs
echo "Running ${!jobs[@]}..."
case ${#jobs[@]} in
    0)  showHelp 1;;
    1)  build_and_run ${!jobs[@]};;
    *)  parallel $keep_order --lb --tag 'set -o pipefail; build_and_run' ::: ${!jobs[@]};;
esac
